{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week4_pytorch_tuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNOMJ9GjIjyPES9JPy16Sf+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5cff260761f94caa977d05bd2bdb6cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0e884a1d69b5476bb3490af05217747a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a8fcd9aff02a4607b6fbd0680e479531",
              "IPY_MODEL_1bf686c0260d47d6b48be4b5aa961a95"
            ]
          }
        },
        "0e884a1d69b5476bb3490af05217747a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a8fcd9aff02a4607b6fbd0680e479531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a97bb5b62b1f42cd816afe8242023176",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9912422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9912422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fe64fbe1258d4f0987ade4a922396bea"
          }
        },
        "1bf686c0260d47d6b48be4b5aa961a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_213daecc473f40b98809a3cc9f58bcd6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9913344/? [00:00&lt;00:00, 11063288.72it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_907b3afbfe8441a69c65c455b832e80d"
          }
        },
        "a97bb5b62b1f42cd816afe8242023176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fe64fbe1258d4f0987ade4a922396bea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "213daecc473f40b98809a3cc9f58bcd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "907b3afbfe8441a69c65c455b832e80d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "225c9b73996f43fab7a866a67c1ff9f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1edce11b6c5a40b59631cdfc73c01501",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_151204098fcc46acae5bca98f6d90126",
              "IPY_MODEL_e8c11f1f1fcc43e7ae737022b3a20ac0"
            ]
          }
        },
        "1edce11b6c5a40b59631cdfc73c01501": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "151204098fcc46acae5bca98f6d90126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c4b59fba17094e0ab2f77094da8a0ca3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb5444d6fdab4096a895835dd7830417"
          }
        },
        "e8c11f1f1fcc43e7ae737022b3a20ac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ddf041b8aaef437b902e62df4da6a0b5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29696/? [01:19&lt;00:00, 375.00it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f0afcedf8e44caab4a27508d0129288"
          }
        },
        "c4b59fba17094e0ab2f77094da8a0ca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb5444d6fdab4096a895835dd7830417": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ddf041b8aaef437b902e62df4da6a0b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f0afcedf8e44caab4a27508d0129288": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f8e0290036a47ee844271c83ac2d1fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d37a7fb61dda48ca8db18929c28878a7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_278499e42f8140fea90c94b6fe08f4ad",
              "IPY_MODEL_2a55016bdd5a44279e8b3cf0403c6a55"
            ]
          }
        },
        "d37a7fb61dda48ca8db18929c28878a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "278499e42f8140fea90c94b6fe08f4ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_192736de2eaa479cb5141a9eb2299ada",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1648877,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1648877,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f4342d27c7c54115be3c5141a156b79d"
          }
        },
        "2a55016bdd5a44279e8b3cf0403c6a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_249e9bb7698a47019eda5783c5385055",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1649664/? [00:00&lt;00:00, 1861941.46it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5ba26beb692148a1a2d8c7762e3db5f3"
          }
        },
        "192736de2eaa479cb5141a9eb2299ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f4342d27c7c54115be3c5141a156b79d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "249e9bb7698a47019eda5783c5385055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5ba26beb692148a1a2d8c7762e3db5f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2479445cfb5e44fc9835e7690670f6a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_13852165992b449383f3532ef33baf63",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ea5cef1e1bd447b3ae46d0408a580a94",
              "IPY_MODEL_68e83959a5c44918b80b199791029887"
            ]
          }
        },
        "13852165992b449383f3532ef33baf63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea5cef1e1bd447b3ae46d0408a580a94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c76067d82d53469695c8998a59c2f871",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4542,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4542,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b68446713dd49319b0e8b0e5eeadcd1"
          }
        },
        "68e83959a5c44918b80b199791029887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3c65b358faa543ef85f6a101892e23d6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5120/? [00:00&lt;00:00, 15112.50it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_00f0afa0100f46feba389784a3183d08"
          }
        },
        "c76067d82d53469695c8998a59c2f871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b68446713dd49319b0e8b0e5eeadcd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c65b358faa543ef85f6a101892e23d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "00f0afa0100f46feba389784a3183d08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venomouscyanide/dl_sain/blob/master/week4/week4_pytorch_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMR_uBLmtsKW"
      },
      "source": [
        "import itertools\n",
        "import time\n",
        "from typing import List, Any, Dict\n",
        "\n",
        "# third party\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.sgd import SGD\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torchvision.transforms import ToTensor"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCEAwaaXGYzn",
        "outputId": "b7538ca0-48ec-4f46-9e06-04746564d2fd"
      },
      "source": [
        "# Use Nvidia CUDA if available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cpu device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdXccCYTGbmW"
      },
      "source": [
        "class TorchMLP(nn.Module):\n",
        "    def __init__(self, size: List[int], loss_func: str, hidden_act_function: str, output_act_function: str,\n",
        "                 output_act_function_kwargs: Dict[Any, Any],\n",
        "                 optimizer: str, learning_rate: float, lmda_wt_decay: float, p_to_be_zeroed: float, batch_size: int,\n",
        "                 momentum: float, training_size: int = 60000,\n",
        "                 testing_size: int = 10000, seed: int = 42, dropout_on_input: bool = False):\n",
        "        super().__init__()\n",
        "        self.size = size\n",
        "        self.loss_func = loss_func\n",
        "        self.hidden_act_function = hidden_act_function\n",
        "        self.output_act_function = output_act_function\n",
        "        self.output_act_function_kwargs = output_act_function_kwargs\n",
        "        self.optimizer = optimizer\n",
        "        self.learning_rate = learning_rate\n",
        "        self.lmda_wt_decay = lmda_wt_decay\n",
        "        self.p_to_be_zeroed = p_to_be_zeroed\n",
        "        self.dropout_on_input = dropout_on_input\n",
        "        self.flatten = nn.Flatten()\n",
        "        nn_stack = self._form_nn_stack()\n",
        "        self.mlp = nn.Sequential(*nn_stack)\n",
        "        self.momentum = momentum\n",
        "        optimizer_params = self._get_optimizer_params()\n",
        "        self.optimizer = getattr(torch.optim, self.optimizer)(**optimizer_params)\n",
        "        self.loss_function = getattr(nn, self.loss_func)()\n",
        "        self.batch_size = batch_size\n",
        "        self.training_size = training_size\n",
        "        self.testing_size = testing_size\n",
        "        self.seed = seed\n",
        "        \n",
        "    def _form_nn_stack(self):\n",
        "        nn_stack = []\n",
        "        # hidden layers\n",
        "        for layer in range(len(self.size) - 2):\n",
        "            nn_stack.append(nn.Linear(self.size[layer], self.size[layer + 1]))\n",
        "            if (layer == 0 and self.dropout_on_input and self.p_to_be_zeroed > 0) or \\\n",
        "                    (layer > 0 and self.p_to_be_zeroed > 0):\n",
        "                nn_stack.append(nn.Dropout(self.p_to_be_zeroed))\n",
        "            nn_stack.append(getattr(nn, self.hidden_act_function)())\n",
        "        # output layer\n",
        "        nn_stack.append(nn.Linear(self.size[-2], self.size[-1]))\n",
        "        nn_stack.append(getattr(nn, self.output_act_function)(**self.output_act_function_kwargs))\n",
        "        return nn_stack\n",
        "\n",
        "    def _get_optimizer_params(self):\n",
        "        opt_params = {\n",
        "            \"params\": self.parameters(),\n",
        "            \"lr\": self.learning_rate,\n",
        "            \"weight_decay\": self.lmda_wt_decay,\n",
        "            \"momentum\": self.momentum,\n",
        "        }\n",
        "        return opt_params\n",
        "\n",
        "    def forward(self, data: torch.Tensor) -> torch.Tensor:\n",
        "        data = self.flatten(data)\n",
        "        logits = self.mlp(data)\n",
        "        return logits\n",
        "\n",
        "    def train_model(self, training_loader: DataLoader, verbose: int = True):\n",
        "        torch.manual_seed(self.seed)\n",
        "        for input, labels in itertools.islice(training_loader, self.training_size // self.batch_size):\n",
        "            prediction = self(input.to(device))\n",
        "            labels = labels.to(device)\n",
        "            if self.loss_function._get_name() == 'MSELoss':\n",
        "                labels = torch.nn.functional.one_hot(labels, 10).float()\n",
        "            loss = self.loss_function(prediction, labels)\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "        if verbose:\n",
        "            self.evaluate(training_loader, self.training_size, verbose=verbose)\n",
        "\n",
        "    def evaluate(self, data_loader: DataLoader, dataset_size: int, data_type: str = \"training\",\n",
        "                 verbose: bool = True) -> float:\n",
        "        correct_classifications = 0\n",
        "        with torch.no_grad():\n",
        "            torch.manual_seed(self.seed)\n",
        "            for input, labels in itertools.islice(data_loader, dataset_size // self.batch_size):\n",
        "                prediction = self(input.to(device))\n",
        "                labels = labels.to(device)\n",
        "                correct_classifications += (prediction.argmax(1) == labels).type(torch.float).sum().item()\n",
        "        accuracy = round((correct_classifications / dataset_size) * 100, 2)\n",
        "        if verbose:\n",
        "            print(f'Accuracy on {data_type} data {accuracy}%')\n",
        "        return accuracy\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTaJsBvxGmyk"
      },
      "source": [
        "def one_hot_encode(y):\n",
        "    return torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1).reshape(1, 10)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP6kb5XYGrJh"
      },
      "source": [
        "class EvalData:\n",
        "    def __init__(self):\n",
        "        self.data = pd.DataFrame(\n",
        "            columns=[\"size\", \"epochs\", \"hidden_act_function\", \"output_act_function\", \"loss_func\",\n",
        "                     \"optimizer\", \"learning_rate\", \"weight_decay\", \"batch_size\", \"momentum\",\n",
        "                     \"testing_dataset_type\", \"training_size\", \"testing_size\",\n",
        "                     \"p_to_be_zeroed\", \"dropout_on_input_layer\",\n",
        "                     \"best_accuracy\", \"avg_accuracy\",\n",
        "                     \"avg_time_taken\"])\n",
        "\n",
        "    def add_record(self, data_dict: Dict):\n",
        "        self.data = self.data.append(data_dict, ignore_index=True)\n",
        "        print(f\"Added record to eval DF. Total records so far: {self.data.shape[0]}\")\n",
        "\n",
        "    def get(self, rearrange: bool) -> pd.DataFrame:\n",
        "        if rearrange:\n",
        "            # push \"best_accuracy\", \"avg_accuracy\", \"avg_time_taken\" cols to the front and sort by \"avg_accuracy\"\n",
        "            curr_cols = self.data.columns.tolist()\n",
        "            updated_order = curr_cols[-3:] + curr_cols[:-3]\n",
        "            self.data = self.data[updated_order]\n",
        "        return self.data.sort_values(by=\"avg_accuracy\", ascending=False)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijGi5k3UWcog"
      },
      "source": [
        "class HyperTuner:\n",
        "    def tune(self, config: Dict, verbose: bool = True) -> pd.DataFrame:\n",
        "        eval_data = EvalData()\n",
        "        train_data = MNIST(root='mnist_torch_data', train=True, download=True, transform=ToTensor())\n",
        "        test_data = MNIST(root='mnist_torch_data', train=False, download=True, transform=ToTensor())\n",
        "\n",
        "        all_combinations = list(itertools.product(*config.values()))\n",
        "        print(f\"Total combinations for exp: {len(all_combinations)}\")\n",
        "        for combination in all_combinations:\n",
        "            # reconstruct the dict using the combination\n",
        "            combination_dict = {k: v for k, v in zip(config.keys(), combination)}\n",
        "            accuracies = np.array([])\n",
        "            time_consumed = np.array([])\n",
        "\n",
        "            for seed in [28, 35, 42]:\n",
        "                batch_size = combination_dict[\"batch_size\"]\n",
        "\n",
        "                torch.manual_seed(seed)\n",
        "                training_subset, validation_subset = random_split(train_data, lengths=[50000, 10000])\n",
        "                training_loader = DataLoader(training_subset, batch_size=batch_size, shuffle=True)\n",
        "                validation_loader = DataLoader(validation_subset, batch_size=batch_size, shuffle=True)\n",
        "                testing_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "                testing_dataset_type = combination_dict[\"testing_dataset_type\"]\n",
        "                testing_loader = validation_loader if testing_dataset_type == \"validation\" else testing_loader\n",
        "                output_act_fn = combination_dict[\"output_act_function\"]\n",
        "\n",
        "                model = TorchMLP(\n",
        "                    size=combination_dict[\"size\"],\n",
        "                    loss_func=combination_dict[\"loss_func\"],\n",
        "                    hidden_act_function=combination_dict[\"hidden_act_function\"],\n",
        "                    output_act_function=combination_dict[\"output_act_function\"],\n",
        "                    output_act_function_kwargs={\"dim\": 1} if output_act_fn in [\"Softmax\", \"LogSoftmax\"] else {},\n",
        "                    optimizer=combination_dict[\"optimizer\"],\n",
        "                    learning_rate=combination_dict[\"learning_rate\"],\n",
        "                    lmda_wt_decay=combination_dict[\"weight_decay\"],\n",
        "                    p_to_be_zeroed=combination_dict[\"p_to_be_zeroed\"],\n",
        "                    batch_size=batch_size,\n",
        "                    momentum=combination_dict[\"momentum\"],\n",
        "                    training_size=combination_dict[\"training_size\"],\n",
        "                    testing_size=combination_dict[\"testing_size\"],\n",
        "                    seed=seed,\n",
        "                    dropout_on_input=combination_dict[\"dropout_on_input_layer\"],\n",
        "                ).to(device)\n",
        "\n",
        "                num_epochs = combination_dict[\"epochs\"]\n",
        "                time_epoch_start = time.time()\n",
        "                for epoch in range(num_epochs):\n",
        "                    if verbose:\n",
        "                        print(f\"Training for epoch: {epoch}\")\n",
        "                    model.train_model(training_loader, verbose)\n",
        "                    accuracy = model.evaluate(testing_loader, model.testing_size, \"testing\", verbose)\n",
        "                    accuracies = np.append(accuracies, accuracy)\n",
        "                time_for_seed = time.time() - time_epoch_start\n",
        "                time_consumed = np.append(time_consumed, time_for_seed)\n",
        "\n",
        "            avg_time = np.mean(time_consumed)\n",
        "            last_5_accuracies_of_three_seeds = np.concatenate((accuracies[epoch - 5: epoch], accuracies[epoch * 2 - 5: epoch * 2], accuracies[epoch * 3 - 5: epoch * 3]))\n",
        "            avg_accuracy = np.mean(last_5_accuracies_of_three_seeds)\n",
        "            best_accuracy = np.max(accuracies)\n",
        "            combination_dict.update({\n",
        "                \"best_accuracy\": best_accuracy,\n",
        "                \"avg_accuracy\": avg_accuracy,\n",
        "                \"avg_time_taken\": avg_time\n",
        "            })\n",
        "\n",
        "            eval_data.add_record(combination_dict)\n",
        "\n",
        "            if verbose:\n",
        "                print(eval_data.get(rearrange=False))\n",
        "        return eval_data.get(rearrange=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L45uYtzwaNyr"
      },
      "source": [
        "Find best activation function using MSELoss using different learning rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi9diYXlWg-N"
      },
      "source": [
        "class TestingConfig:\n",
        "    CONFIG = {\n",
        "        \"size\": [[784, 30, 10]], \n",
        "        \"epochs\": [25],  \n",
        "        \"hidden_act_function\": [\"Sigmoid\", \"ReLU\", \"Tanh\"],  \n",
        "        \"output_act_function\": [\"Sigmoid\", \"ReLU\", \"Tanh\"],  \n",
        "        \"loss_func\": [\"MSELoss\"],  \n",
        "        \"optimizer\": [\"SGD\"],  \n",
        "        \"learning_rate\": [0.01, 0.1, 1], \n",
        "        \"weight_decay\": [0.0],  \n",
        "        \"batch_size\": [10],  \n",
        "        \"testing_dataset_type\": [\"validation\"],  \n",
        "        \"training_size\": [5000],  \n",
        "        \"testing_size\": [2000],  \n",
        "        \"p_to_be_zeroed\": [0.0],  \n",
        "        \"dropout_on_input_layer\": [False],  \n",
        "    }\n",
        "eval_data = HyperTuner().tune(TestingConfig.CONFIG, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tNoektOQlmAh",
        "outputId": "8f40a9c8-9c24-4693-e17e-38d15af16464"
      },
      "source": [
        "eval_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>best_accuracy</th>\n",
              "      <th>avg_accuracy</th>\n",
              "      <th>avg_time_taken</th>\n",
              "      <th>size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>hidden_act_function</th>\n",
              "      <th>output_act_function</th>\n",
              "      <th>loss_func</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>testing_dataset_type</th>\n",
              "      <th>training_size</th>\n",
              "      <th>testing_size</th>\n",
              "      <th>p_to_be_zeroed</th>\n",
              "      <th>dropout_on_input_layer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>92.95</td>\n",
              "      <td>91.385333</td>\n",
              "      <td>37.135675</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>92.65</td>\n",
              "      <td>91.064667</td>\n",
              "      <td>36.975883</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>91.50</td>\n",
              "      <td>90.421333</td>\n",
              "      <td>37.064687</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>92.60</td>\n",
              "      <td>90.273333</td>\n",
              "      <td>37.660565</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>92.05</td>\n",
              "      <td>90.099333</td>\n",
              "      <td>37.112951</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>93.90</td>\n",
              "      <td>89.464667</td>\n",
              "      <td>37.613673</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>90.80</td>\n",
              "      <td>88.983333</td>\n",
              "      <td>36.760986</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>91.35</td>\n",
              "      <td>88.768000</td>\n",
              "      <td>36.856509</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>92.95</td>\n",
              "      <td>88.038000</td>\n",
              "      <td>37.147289</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>91.95</td>\n",
              "      <td>86.140000</td>\n",
              "      <td>37.207622</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>88.00</td>\n",
              "      <td>83.752667</td>\n",
              "      <td>37.101876</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>86.05</td>\n",
              "      <td>82.604667</td>\n",
              "      <td>36.916880</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>90.85</td>\n",
              "      <td>81.799333</td>\n",
              "      <td>37.293462</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>92.55</td>\n",
              "      <td>81.788000</td>\n",
              "      <td>37.111323</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>87.75</td>\n",
              "      <td>80.851333</td>\n",
              "      <td>37.092673</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>92.40</td>\n",
              "      <td>80.284667</td>\n",
              "      <td>37.184641</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>90.35</td>\n",
              "      <td>78.712000</td>\n",
              "      <td>36.972815</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>88.50</td>\n",
              "      <td>71.943333</td>\n",
              "      <td>37.218168</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>79.45</td>\n",
              "      <td>68.358000</td>\n",
              "      <td>37.008124</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>88.50</td>\n",
              "      <td>65.868667</td>\n",
              "      <td>37.017042</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>72.60</td>\n",
              "      <td>48.033333</td>\n",
              "      <td>37.048058</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>55.85</td>\n",
              "      <td>45.444667</td>\n",
              "      <td>37.901576</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>61.90</td>\n",
              "      <td>41.646667</td>\n",
              "      <td>37.122712</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>58.00</td>\n",
              "      <td>41.127333</td>\n",
              "      <td>36.860821</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>51.60</td>\n",
              "      <td>36.790667</td>\n",
              "      <td>37.356333</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>65.25</td>\n",
              "      <td>21.386667</td>\n",
              "      <td>37.272692</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31.15</td>\n",
              "      <td>17.587333</td>\n",
              "      <td>37.292660</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    best_accuracy  avg_accuracy  ...  p_to_be_zeroed dropout_on_input_layer\n",
              "11          92.95     91.385333  ...             0.0                  False\n",
              "20          92.65     91.064667  ...             0.0                  False\n",
              "17          91.50     90.421333  ...             0.0                  False\n",
              "8           92.60     90.273333  ...             0.0                  False\n",
              "16          92.05     90.099333  ...             0.0                  False\n",
              "14          93.90     89.464667  ...             0.0                  False\n",
              "26          90.80     88.983333  ...             0.0                  False\n",
              "25          91.35     88.768000  ...             0.0                  False\n",
              "23          92.95     88.038000  ...             0.0                  False\n",
              "2           91.95     86.140000  ...             0.0                  False\n",
              "7           88.00     83.752667  ...             0.0                  False\n",
              "24          86.05     82.604667  ...             0.0                  False\n",
              "10          90.85     81.799333  ...             0.0                  False\n",
              "13          92.55     81.788000  ...             0.0                  False\n",
              "15          87.75     80.851333  ...             0.0                  False\n",
              "22          92.40     80.284667  ...             0.0                  False\n",
              "19          90.35     78.712000  ...             0.0                  False\n",
              "21          88.50     71.943333  ...             0.0                  False\n",
              "6           79.45     68.358000  ...             0.0                  False\n",
              "12          88.50     65.868667  ...             0.0                  False\n",
              "1           72.60     48.033333  ...             0.0                  False\n",
              "4           55.85     45.444667  ...             0.0                  False\n",
              "9           61.90     41.646667  ...             0.0                  False\n",
              "18          58.00     41.127333  ...             0.0                  False\n",
              "3           51.60     36.790667  ...             0.0                  False\n",
              "5           65.25     21.386667  ...             0.0                  False\n",
              "0           31.15     17.587333  ...             0.0                  False\n",
              "\n",
              "[27 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ0yUPJq9Aww"
      },
      "source": [
        "Relu hidden and Softmax output seems to work best at a learning rate of 1.\n",
        "<br>\n",
        "Fix ReLU as the hidden layer. Try with different learning rates for Relu, Tanh and Sigmoid functions as output activations and loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oForb5k09Pao",
        "outputId": "34d8e0aa-cab8-4949-fc56-c4d3f1a3ecf2"
      },
      "source": [
        "class TestingConfig:\n",
        "    CONFIG = {\n",
        "        \"size\": [[784, 30, 10]], \n",
        "        \"epochs\": [25],  \n",
        "        \"hidden_act_function\": [\"ReLU\"],  \n",
        "        \"output_act_function\": [\"Sigmoid\", \"ReLU\", \"Tanh\", \"Softmax\"],  \n",
        "        \"loss_func\": [\"MSELoss\", \"CrossEntropyLoss\"],  \n",
        "        \"optimizer\": [\"SGD\"],  \n",
        "        \"learning_rate\": [0.01, 1, 3, 5], \n",
        "        \"weight_decay\": [0.0],  \n",
        "        \"batch_size\": [10],  \n",
        "        \"testing_dataset_type\": [\"validation\"],  \n",
        "        \"training_size\": [5000],  \n",
        "        \"testing_size\": [2000],  \n",
        "        \"p_to_be_zeroed\": [0.0],  \n",
        "        \"dropout_on_input_layer\": [False],  \n",
        "    }\n",
        "eval_data = HyperTuner().tune(TestingConfig.CONFIG, False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total combinations for exp: 32\n",
            "Added record to eval DF. Total records so far: 1\n",
            "Added record to eval DF. Total records so far: 2\n",
            "Added record to eval DF. Total records so far: 3\n",
            "Added record to eval DF. Total records so far: 4\n",
            "Added record to eval DF. Total records so far: 5\n",
            "Added record to eval DF. Total records so far: 6\n",
            "Added record to eval DF. Total records so far: 7\n",
            "Added record to eval DF. Total records so far: 8\n",
            "Added record to eval DF. Total records so far: 9\n",
            "Added record to eval DF. Total records so far: 10\n",
            "Added record to eval DF. Total records so far: 11\n",
            "Added record to eval DF. Total records so far: 12\n",
            "Added record to eval DF. Total records so far: 13\n",
            "Added record to eval DF. Total records so far: 14\n",
            "Added record to eval DF. Total records so far: 15\n",
            "Added record to eval DF. Total records so far: 16\n",
            "Added record to eval DF. Total records so far: 17\n",
            "Added record to eval DF. Total records so far: 18\n",
            "Added record to eval DF. Total records so far: 19\n",
            "Added record to eval DF. Total records so far: 20\n",
            "Added record to eval DF. Total records so far: 21\n",
            "Added record to eval DF. Total records so far: 22\n",
            "Added record to eval DF. Total records so far: 23\n",
            "Added record to eval DF. Total records so far: 24\n",
            "Added record to eval DF. Total records so far: 25\n",
            "Added record to eval DF. Total records so far: 26\n",
            "Added record to eval DF. Total records so far: 27\n",
            "Added record to eval DF. Total records so far: 28\n",
            "Added record to eval DF. Total records so far: 29\n",
            "Added record to eval DF. Total records so far: 30\n",
            "Added record to eval DF. Total records so far: 31\n",
            "Added record to eval DF. Total records so far: 32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yIEV_ZofNcaF",
        "outputId": "43bdb9b6-72f1-46b4-b8bf-3cb405306cea"
      },
      "source": [
        "eval_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>best_accuracy</th>\n",
              "      <th>avg_accuracy</th>\n",
              "      <th>avg_time_taken</th>\n",
              "      <th>size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>hidden_act_function</th>\n",
              "      <th>output_act_function</th>\n",
              "      <th>loss_func</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>testing_dataset_type</th>\n",
              "      <th>training_size</th>\n",
              "      <th>testing_size</th>\n",
              "      <th>p_to_be_zeroed</th>\n",
              "      <th>dropout_on_input_layer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>93.70</td>\n",
              "      <td>92.070000</td>\n",
              "      <td>37.466634</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>93.65</td>\n",
              "      <td>91.826000</td>\n",
              "      <td>37.385592</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>93.75</td>\n",
              "      <td>91.802000</td>\n",
              "      <td>37.312673</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>93.00</td>\n",
              "      <td>91.405333</td>\n",
              "      <td>37.305377</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>92.95</td>\n",
              "      <td>91.385333</td>\n",
              "      <td>37.356164</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>93.70</td>\n",
              "      <td>90.724000</td>\n",
              "      <td>36.034096</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>93.35</td>\n",
              "      <td>90.690667</td>\n",
              "      <td>37.357460</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>91.50</td>\n",
              "      <td>90.421333</td>\n",
              "      <td>37.027907</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>93.90</td>\n",
              "      <td>89.464667</td>\n",
              "      <td>37.054228</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>91.30</td>\n",
              "      <td>88.831333</td>\n",
              "      <td>35.774298</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>92.40</td>\n",
              "      <td>85.390000</td>\n",
              "      <td>36.111077</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>89.80</td>\n",
              "      <td>83.394000</td>\n",
              "      <td>36.000744</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>87.75</td>\n",
              "      <td>80.851333</td>\n",
              "      <td>37.124978</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>85.55</td>\n",
              "      <td>78.140667</td>\n",
              "      <td>36.055415</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>91.20</td>\n",
              "      <td>73.510000</td>\n",
              "      <td>35.807217</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>87.80</td>\n",
              "      <td>73.441333</td>\n",
              "      <td>35.928692</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>85.85</td>\n",
              "      <td>72.872000</td>\n",
              "      <td>36.038154</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>82.70</td>\n",
              "      <td>66.702000</td>\n",
              "      <td>35.939912</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>88.50</td>\n",
              "      <td>65.868667</td>\n",
              "      <td>37.122212</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>75.90</td>\n",
              "      <td>58.252000</td>\n",
              "      <td>36.046644</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>65.85</td>\n",
              "      <td>51.494667</td>\n",
              "      <td>35.903177</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>79.05</td>\n",
              "      <td>49.541333</td>\n",
              "      <td>37.022171</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>61.90</td>\n",
              "      <td>41.646667</td>\n",
              "      <td>37.573920</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>63.60</td>\n",
              "      <td>39.778000</td>\n",
              "      <td>37.273498</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>28.30</td>\n",
              "      <td>19.899333</td>\n",
              "      <td>37.120564</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>42.05</td>\n",
              "      <td>18.182667</td>\n",
              "      <td>36.321121</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>21.40</td>\n",
              "      <td>13.772667</td>\n",
              "      <td>36.007175</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>17.20</td>\n",
              "      <td>10.607333</td>\n",
              "      <td>37.080404</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>11.40</td>\n",
              "      <td>10.382000</td>\n",
              "      <td>35.845683</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Tanh</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>10.40</td>\n",
              "      <td>10.167333</td>\n",
              "      <td>35.734058</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>10.40</td>\n",
              "      <td>10.166667</td>\n",
              "      <td>35.928069</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>10.40</td>\n",
              "      <td>10.166667</td>\n",
              "      <td>36.922442</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>5000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    best_accuracy  avg_accuracy  ...  p_to_be_zeroed dropout_on_input_layer\n",
              "2           93.70     92.070000  ...             0.0                  False\n",
              "3           93.65     91.826000  ...             0.0                  False\n",
              "26          93.75     91.802000  ...             0.0                  False\n",
              "25          93.00     91.405333  ...             0.0                  False\n",
              "1           92.95     91.385333  ...             0.0                  False\n",
              "5           93.70     90.724000  ...             0.0                  False\n",
              "27          93.35     90.690667  ...             0.0                  False\n",
              "17          91.50     90.421333  ...             0.0                  False\n",
              "9           93.90     89.464667  ...             0.0                  False\n",
              "20          91.30     88.831333  ...             0.0                  False\n",
              "29          92.40     85.390000  ...             0.0                  False\n",
              "6           89.80     83.394000  ...             0.0                  False\n",
              "16          87.75     80.851333  ...             0.0                  False\n",
              "4           85.55     78.140667  ...             0.0                  False\n",
              "12          91.20     73.510000  ...             0.0                  False\n",
              "21          87.80     73.441333  ...             0.0                  False\n",
              "30          85.85     72.872000  ...             0.0                  False\n",
              "28          82.70     66.702000  ...             0.0                  False\n",
              "8           88.50     65.868667  ...             0.0                  False\n",
              "7           75.90     58.252000  ...             0.0                  False\n",
              "31          65.85     51.494667  ...             0.0                  False\n",
              "18          79.05     49.541333  ...             0.0                  False\n",
              "0           61.90     41.646667  ...             0.0                  False\n",
              "24          63.60     39.778000  ...             0.0                  False\n",
              "10          28.30     19.899333  ...             0.0                  False\n",
              "22          42.05     18.182667  ...             0.0                  False\n",
              "13          21.40     13.772667  ...             0.0                  False\n",
              "19          17.20     10.607333  ...             0.0                  False\n",
              "23          11.40     10.382000  ...             0.0                  False\n",
              "15          10.40     10.167333  ...             0.0                  False\n",
              "14          10.40     10.166667  ...             0.0                  False\n",
              "11          10.40     10.166667  ...             0.0                  False\n",
              "\n",
              "[32 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3FG-YbdOWpI"
      },
      "source": [
        "Remove tanh, from output function. MSE still seems to be the best with a combination of (ReLU and Sigmoid) \n",
        "<br>\n",
        "Add more epochs and training data size to confirm which output function to take and learning rate as well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jg-unINbN54E",
        "outputId": "21b2177b-51ec-4d08-83c5-f278a42ca2a2"
      },
      "source": [
        "class TestingConfig:\n",
        "    CONFIG = {\n",
        "        \"size\": [[784, 30, 10]], \n",
        "        \"epochs\": [25, 50],  \n",
        "        \"hidden_act_function\": [\"ReLU\"],  \n",
        "        \"output_act_function\": [\"Sigmoid\", \"ReLU\", \"Softmax\"],  \n",
        "        \"loss_func\": [\"MSELoss\", \"CrossEntropyLoss\"],  \n",
        "        \"optimizer\": [\"SGD\"],  \n",
        "        \"learning_rate\": [0.01, 0.1, 1, 5], \n",
        "        \"weight_decay\": [0.0],  \n",
        "        \"batch_size\": [10],  \n",
        "        \"testing_dataset_type\": [\"validation\"],  \n",
        "        \"training_size\": [10000],  \n",
        "        \"testing_size\": [2000],  \n",
        "        \"p_to_be_zeroed\": [0.0],  \n",
        "        \"dropout_on_input_layer\": [False],  \n",
        "    }\n",
        "eval_data = HyperTuner().tune(TestingConfig.CONFIG, False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total combinations for exp: 48\n",
            "Added record to eval DF. Total records so far: 1\n",
            "Added record to eval DF. Total records so far: 2\n",
            "Added record to eval DF. Total records so far: 3\n",
            "Added record to eval DF. Total records so far: 4\n",
            "Added record to eval DF. Total records so far: 5\n",
            "Added record to eval DF. Total records so far: 6\n",
            "Added record to eval DF. Total records so far: 7\n",
            "Added record to eval DF. Total records so far: 8\n",
            "Added record to eval DF. Total records so far: 9\n",
            "Added record to eval DF. Total records so far: 10\n",
            "Added record to eval DF. Total records so far: 11\n",
            "Added record to eval DF. Total records so far: 12\n",
            "Added record to eval DF. Total records so far: 13\n",
            "Added record to eval DF. Total records so far: 14\n",
            "Added record to eval DF. Total records so far: 15\n",
            "Added record to eval DF. Total records so far: 16\n",
            "Added record to eval DF. Total records so far: 17\n",
            "Added record to eval DF. Total records so far: 18\n",
            "Added record to eval DF. Total records so far: 19\n",
            "Added record to eval DF. Total records so far: 20\n",
            "Added record to eval DF. Total records so far: 21\n",
            "Added record to eval DF. Total records so far: 22\n",
            "Added record to eval DF. Total records so far: 23\n",
            "Added record to eval DF. Total records so far: 24\n",
            "Added record to eval DF. Total records so far: 25\n",
            "Added record to eval DF. Total records so far: 26\n",
            "Added record to eval DF. Total records so far: 27\n",
            "Added record to eval DF. Total records so far: 28\n",
            "Added record to eval DF. Total records so far: 29\n",
            "Added record to eval DF. Total records so far: 30\n",
            "Added record to eval DF. Total records so far: 31\n",
            "Added record to eval DF. Total records so far: 32\n",
            "Added record to eval DF. Total records so far: 33\n",
            "Added record to eval DF. Total records so far: 34\n",
            "Added record to eval DF. Total records so far: 35\n",
            "Added record to eval DF. Total records so far: 36\n",
            "Added record to eval DF. Total records so far: 37\n",
            "Added record to eval DF. Total records so far: 38\n",
            "Added record to eval DF. Total records so far: 39\n",
            "Added record to eval DF. Total records so far: 40\n",
            "Added record to eval DF. Total records so far: 41\n",
            "Added record to eval DF. Total records so far: 42\n",
            "Added record to eval DF. Total records so far: 43\n",
            "Added record to eval DF. Total records so far: 44\n",
            "Added record to eval DF. Total records so far: 45\n",
            "Added record to eval DF. Total records so far: 46\n",
            "Added record to eval DF. Total records so far: 47\n",
            "Added record to eval DF. Total records so far: 48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tSzoEz9LZYSu",
        "outputId": "7f76f5b4-0748-4cb5-d2f0-d9e688e0cec5"
      },
      "source": [
        "eval_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>best_accuracy</th>\n",
              "      <th>avg_accuracy</th>\n",
              "      <th>avg_time_taken</th>\n",
              "      <th>size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>hidden_act_function</th>\n",
              "      <th>output_act_function</th>\n",
              "      <th>loss_func</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>testing_dataset_type</th>\n",
              "      <th>training_size</th>\n",
              "      <th>testing_size</th>\n",
              "      <th>p_to_be_zeroed</th>\n",
              "      <th>dropout_on_input_layer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>95.50</td>\n",
              "      <td>94.031000</td>\n",
              "      <td>112.802789</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>95.05</td>\n",
              "      <td>93.844667</td>\n",
              "      <td>110.338788</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>94.80</td>\n",
              "      <td>93.723667</td>\n",
              "      <td>112.778563</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>95.20</td>\n",
              "      <td>93.674667</td>\n",
              "      <td>111.357000</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>95.20</td>\n",
              "      <td>93.500000</td>\n",
              "      <td>55.335983</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>95.55</td>\n",
              "      <td>93.349000</td>\n",
              "      <td>108.933675</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>94.60</td>\n",
              "      <td>93.336000</td>\n",
              "      <td>55.869598</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>94.70</td>\n",
              "      <td>93.230000</td>\n",
              "      <td>55.601242</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>94.90</td>\n",
              "      <td>93.178000</td>\n",
              "      <td>55.683721</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>94.80</td>\n",
              "      <td>92.615333</td>\n",
              "      <td>55.162861</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>94.50</td>\n",
              "      <td>92.486333</td>\n",
              "      <td>108.950362</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>94.35</td>\n",
              "      <td>92.372000</td>\n",
              "      <td>112.825989</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>93.70</td>\n",
              "      <td>91.333333</td>\n",
              "      <td>54.229689</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>93.90</td>\n",
              "      <td>91.279333</td>\n",
              "      <td>55.341181</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>94.05</td>\n",
              "      <td>91.247333</td>\n",
              "      <td>56.543278</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>94.35</td>\n",
              "      <td>91.212667</td>\n",
              "      <td>112.476868</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>93.30</td>\n",
              "      <td>90.800667</td>\n",
              "      <td>111.146468</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>93.45</td>\n",
              "      <td>89.916333</td>\n",
              "      <td>113.867033</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>92.50</td>\n",
              "      <td>88.806000</td>\n",
              "      <td>55.840778</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>95.70</td>\n",
              "      <td>88.539667</td>\n",
              "      <td>111.876339</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>92.55</td>\n",
              "      <td>87.348000</td>\n",
              "      <td>56.585101</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>93.95</td>\n",
              "      <td>87.044667</td>\n",
              "      <td>110.927470</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>95.35</td>\n",
              "      <td>86.320000</td>\n",
              "      <td>55.488245</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>92.60</td>\n",
              "      <td>86.066667</td>\n",
              "      <td>57.627705</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>90.10</td>\n",
              "      <td>85.687667</td>\n",
              "      <td>110.393568</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>86.95</td>\n",
              "      <td>85.274000</td>\n",
              "      <td>108.537619</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>86.20</td>\n",
              "      <td>84.400000</td>\n",
              "      <td>54.710578</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>88.10</td>\n",
              "      <td>82.708000</td>\n",
              "      <td>54.982385</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>91.90</td>\n",
              "      <td>80.872000</td>\n",
              "      <td>109.768149</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>93.60</td>\n",
              "      <td>77.374667</td>\n",
              "      <td>110.088997</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>92.75</td>\n",
              "      <td>75.974667</td>\n",
              "      <td>54.415277</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>84.90</td>\n",
              "      <td>74.299333</td>\n",
              "      <td>54.983105</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>89.55</td>\n",
              "      <td>72.427333</td>\n",
              "      <td>112.544950</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>91.55</td>\n",
              "      <td>71.494333</td>\n",
              "      <td>109.845934</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>90.00</td>\n",
              "      <td>69.587333</td>\n",
              "      <td>54.629269</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>88.10</td>\n",
              "      <td>69.131000</td>\n",
              "      <td>111.558125</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>77.40</td>\n",
              "      <td>63.095333</td>\n",
              "      <td>110.104963</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>77.40</td>\n",
              "      <td>62.390667</td>\n",
              "      <td>54.336624</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>84.75</td>\n",
              "      <td>57.124000</td>\n",
              "      <td>55.570678</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>70.75</td>\n",
              "      <td>54.634667</td>\n",
              "      <td>109.542386</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75.95</td>\n",
              "      <td>54.588000</td>\n",
              "      <td>55.764312</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>70.75</td>\n",
              "      <td>54.078667</td>\n",
              "      <td>54.699206</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>21.40</td>\n",
              "      <td>13.779333</td>\n",
              "      <td>54.292474</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>21.40</td>\n",
              "      <td>13.777333</td>\n",
              "      <td>109.353269</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>10.40</td>\n",
              "      <td>10.167333</td>\n",
              "      <td>54.054333</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>10.40</td>\n",
              "      <td>10.167000</td>\n",
              "      <td>108.574844</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>10.40</td>\n",
              "      <td>10.166667</td>\n",
              "      <td>111.120121</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>10.40</td>\n",
              "      <td>10.166667</td>\n",
              "      <td>56.135737</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    best_accuracy  avg_accuracy  ...  p_to_be_zeroed dropout_on_input_layer\n",
              "42          95.50     94.031000  ...             0.0                  False\n",
              "26          95.05     93.844667  ...             0.0                  False\n",
              "27          94.80     93.723667  ...             0.0                  False\n",
              "34          95.20     93.674667  ...             0.0                  False\n",
              "10          95.20     93.500000  ...             0.0                  False\n",
              "30          95.55     93.349000  ...             0.0                  False\n",
              "3           94.60     93.336000  ...             0.0                  False\n",
              "2           94.70     93.230000  ...             0.0                  False\n",
              "18          94.90     93.178000  ...             0.0                  False\n",
              "6           94.80     92.615333  ...             0.0                  False\n",
              "45          94.50     92.486333  ...             0.0                  False\n",
              "29          94.35     92.372000  ...             0.0                  False\n",
              "21          93.70     91.333333  ...             0.0                  False\n",
              "5           93.90     91.279333  ...             0.0                  False\n",
              "19          94.05     91.247333  ...             0.0                  False\n",
              "43          94.35     91.212667  ...             0.0                  False\n",
              "41          93.30     90.800667  ...             0.0                  False\n",
              "25          93.45     89.916333  ...             0.0                  False\n",
              "17          92.50     88.806000  ...             0.0                  False\n",
              "33          95.70     88.539667  ...             0.0                  False\n",
              "1           92.55     87.348000  ...             0.0                  False\n",
              "46          93.95     87.044667  ...             0.0                  False\n",
              "9           95.35     86.320000  ...             0.0                  False\n",
              "22          92.60     86.066667  ...             0.0                  False\n",
              "28          90.10     85.687667  ...             0.0                  False\n",
              "37          86.95     85.274000  ...             0.0                  False\n",
              "13          86.20     84.400000  ...             0.0                  False\n",
              "4           88.10     82.708000  ...             0.0                  False\n",
              "44          91.90     80.872000  ...             0.0                  False\n",
              "36          93.60     77.374667  ...             0.0                  False\n",
              "12          92.75     75.974667  ...             0.0                  False\n",
              "20          84.90     74.299333  ...             0.0                  False\n",
              "40          89.55     72.427333  ...             0.0                  False\n",
              "32          91.55     71.494333  ...             0.0                  False\n",
              "8           90.00     69.587333  ...             0.0                  False\n",
              "24          88.10     69.131000  ...             0.0                  False\n",
              "31          77.40     63.095333  ...             0.0                  False\n",
              "7           77.40     62.390667  ...             0.0                  False\n",
              "16          84.75     57.124000  ...             0.0                  False\n",
              "47          70.75     54.634667  ...             0.0                  False\n",
              "0           75.95     54.588000  ...             0.0                  False\n",
              "23          70.75     54.078667  ...             0.0                  False\n",
              "14          21.40     13.779333  ...             0.0                  False\n",
              "38          21.40     13.777333  ...             0.0                  False\n",
              "15          10.40     10.167333  ...             0.0                  False\n",
              "39          10.40     10.167000  ...             0.0                  False\n",
              "35          10.40     10.166667  ...             0.0                  False\n",
              "11          10.40     10.166667  ...             0.0                  False\n",
              "\n",
              "[48 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFqCbKstef9L"
      },
      "source": [
        "Softmax + CrossEntropyLoss performs really bad here.\n",
        " <br>\n",
        "If using Softmax Activation; loss function cannot be CrossEntropyLoss\n",
        "We can use LogSoftmax at output layer + NLLLoss instead? https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9PbkgoYfcQz",
        "outputId": "d0d0c2ca-204d-4f3d-c1ab-d9046f8e8e9f"
      },
      "source": [
        "class TestingConfig:\n",
        "    CONFIG = {\n",
        "        \"size\": [[784, 30, 10]], \n",
        "        \"epochs\": [50],  \n",
        "        \"hidden_act_function\": [\"ReLU\"],  \n",
        "        \"output_act_function\": [\"LogSoftmax\"],  \n",
        "        \"loss_func\": [\"NLLLoss\"],  \n",
        "        \"optimizer\": [\"SGD\"],  \n",
        "        \"learning_rate\": [1], \n",
        "        \"weight_decay\": [0.0],  \n",
        "        \"batch_size\": [10],  \n",
        "        \"testing_dataset_type\": [\"validation\"],  \n",
        "        \"training_size\": [10000],  \n",
        "        \"testing_size\": [2000],  \n",
        "        \"p_to_be_zeroed\": [0.0],  \n",
        "        \"dropout_on_input_layer\": [False],  \n",
        "    }\n",
        "eval_data = HyperTuner().tune(TestingConfig.CONFIG, False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total combinations for exp: 1\n",
            "Added record to eval DF. Total records so far: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "W8Qmwqm1gjyU",
        "outputId": "1933ac82-3313-4c16-e801-2e172236f38b"
      },
      "source": [
        "eval_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>best_accuracy</th>\n",
              "      <th>avg_accuracy</th>\n",
              "      <th>avg_time_taken</th>\n",
              "      <th>size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>hidden_act_function</th>\n",
              "      <th>output_act_function</th>\n",
              "      <th>loss_func</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>testing_dataset_type</th>\n",
              "      <th>training_size</th>\n",
              "      <th>testing_size</th>\n",
              "      <th>p_to_be_zeroed</th>\n",
              "      <th>dropout_on_input_layer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28.5</td>\n",
              "      <td>14.027333</td>\n",
              "      <td>107.508718</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>LogSoftmax</td>\n",
              "      <td>NLLLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   best_accuracy  avg_accuracy  ...  p_to_be_zeroed dropout_on_input_layer\n",
              "0           28.5     14.027333  ...             0.0                  False\n",
              "\n",
              "[1 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qs_QFIshj3Y"
      },
      "source": [
        "ReLU + ReLU using CrossEntropyLoss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0fpsIhMzhfE2",
        "outputId": "59cbc81c-4810-497c-fdb8-5b3838e0b61f"
      },
      "source": [
        "class TestingConfig:\n",
        "    CONFIG = {\n",
        "        \"size\": [[784, 30, 10]], \n",
        "        \"epochs\": [100],  \n",
        "        \"hidden_act_function\": [\"ReLU\"],  \n",
        "        \"output_act_function\": [\"Softmax\"],  \n",
        "        \"loss_func\": [\"MSELoss\"],  \n",
        "        \"optimizer\": [\"SGD\"],  \n",
        "        \"learning_rate\": [1], \n",
        "        \"weight_decay\": [0.0],  \n",
        "        \"batch_size\": [10],  \n",
        "        \"testing_dataset_type\": [\"validation\"],  \n",
        "        \"training_size\": [10000],  \n",
        "        \"testing_size\": [2000],  \n",
        "        \"p_to_be_zeroed\": [0.0],  \n",
        "        \"dropout_on_input_layer\": [False],  \n",
        "    }\n",
        "eval_data = HyperTuner().tune(TestingConfig.CONFIG, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total combinations for exp: 1\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 88.22%\n",
            "Accuracy on testing data 88.45%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 91.3%\n",
            "Accuracy on testing data 91.25%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 92.77%\n",
            "Accuracy on testing data 92.2%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 92.9%\n",
            "Accuracy on testing data 92.2%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 93.94%\n",
            "Accuracy on testing data 92.5%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 94.66%\n",
            "Accuracy on testing data 92.8%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 94.73%\n",
            "Accuracy on testing data 93.0%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 95.64%\n",
            "Accuracy on testing data 93.6%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 95.53%\n",
            "Accuracy on testing data 93.25%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 96.5%\n",
            "Accuracy on testing data 93.7%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 96.13%\n",
            "Accuracy on testing data 93.4%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 96.73%\n",
            "Accuracy on testing data 93.9%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 96.94%\n",
            "Accuracy on testing data 93.85%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 97.11%\n",
            "Accuracy on testing data 94.3%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 97.55%\n",
            "Accuracy on testing data 94.3%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 97.08%\n",
            "Accuracy on testing data 93.9%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 97.58%\n",
            "Accuracy on testing data 94.4%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 97.93%\n",
            "Accuracy on testing data 94.65%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 97.63%\n",
            "Accuracy on testing data 93.85%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 98.08%\n",
            "Accuracy on testing data 94.4%\n",
            "Training for epoch: 20\n",
            "Accuracy on training data 98.44%\n",
            "Accuracy on testing data 94.7%\n",
            "Training for epoch: 21\n",
            "Accuracy on training data 98.32%\n",
            "Accuracy on testing data 94.45%\n",
            "Training for epoch: 22\n",
            "Accuracy on training data 98.37%\n",
            "Accuracy on testing data 94.9%\n",
            "Training for epoch: 23\n",
            "Accuracy on training data 98.65%\n",
            "Accuracy on testing data 94.75%\n",
            "Training for epoch: 24\n",
            "Accuracy on training data 98.69%\n",
            "Accuracy on testing data 94.8%\n",
            "Training for epoch: 25\n",
            "Accuracy on training data 98.78%\n",
            "Accuracy on testing data 95.1%\n",
            "Training for epoch: 26\n",
            "Accuracy on training data 98.74%\n",
            "Accuracy on testing data 95.0%\n",
            "Training for epoch: 27\n",
            "Accuracy on training data 98.79%\n",
            "Accuracy on testing data 94.85%\n",
            "Training for epoch: 28\n",
            "Accuracy on training data 98.86%\n",
            "Accuracy on testing data 95.15%\n",
            "Training for epoch: 29\n",
            "Accuracy on training data 98.87%\n",
            "Accuracy on testing data 95.2%\n",
            "Training for epoch: 30\n",
            "Accuracy on training data 98.9%\n",
            "Accuracy on testing data 95.15%\n",
            "Training for epoch: 31\n",
            "Accuracy on training data 98.88%\n",
            "Accuracy on testing data 95.25%\n",
            "Training for epoch: 32\n",
            "Accuracy on training data 98.93%\n",
            "Accuracy on testing data 95.4%\n",
            "Training for epoch: 33\n",
            "Accuracy on training data 98.98%\n",
            "Accuracy on testing data 95.4%\n",
            "Training for epoch: 34\n",
            "Accuracy on training data 98.99%\n",
            "Accuracy on testing data 95.45%\n",
            "Training for epoch: 35\n",
            "Accuracy on training data 99.03%\n",
            "Accuracy on testing data 95.35%\n",
            "Training for epoch: 36\n",
            "Accuracy on training data 99.06%\n",
            "Accuracy on testing data 95.4%\n",
            "Training for epoch: 37\n",
            "Accuracy on training data 99.09%\n",
            "Accuracy on testing data 95.35%\n",
            "Training for epoch: 38\n",
            "Accuracy on training data 99.14%\n",
            "Accuracy on testing data 95.5%\n",
            "Training for epoch: 39\n",
            "Accuracy on training data 99.14%\n",
            "Accuracy on testing data 95.25%\n",
            "Training for epoch: 40\n",
            "Accuracy on training data 99.12%\n",
            "Accuracy on testing data 95.35%\n",
            "Training for epoch: 41\n",
            "Accuracy on training data 99.13%\n",
            "Accuracy on testing data 95.0%\n",
            "Training for epoch: 42\n",
            "Accuracy on training data 99.16%\n",
            "Accuracy on testing data 95.25%\n",
            "Training for epoch: 43\n",
            "Accuracy on training data 99.16%\n",
            "Accuracy on testing data 95.1%\n",
            "Training for epoch: 44\n",
            "Accuracy on training data 99.17%\n",
            "Accuracy on testing data 95.4%\n",
            "Training for epoch: 45\n",
            "Accuracy on training data 99.18%\n",
            "Accuracy on testing data 95.15%\n",
            "Training for epoch: 46\n",
            "Accuracy on training data 99.17%\n",
            "Accuracy on testing data 95.25%\n",
            "Training for epoch: 47\n",
            "Accuracy on training data 99.18%\n",
            "Accuracy on testing data 95.15%\n",
            "Training for epoch: 48\n",
            "Accuracy on training data 99.17%\n",
            "Accuracy on testing data 95.25%\n",
            "Training for epoch: 49\n",
            "Accuracy on training data 99.17%\n",
            "Accuracy on testing data 95.2%\n",
            "Training for epoch: 50\n",
            "Accuracy on training data 99.18%\n",
            "Accuracy on testing data 95.1%\n",
            "Training for epoch: 51\n",
            "Accuracy on training data 99.18%\n",
            "Accuracy on testing data 95.05%\n",
            "Training for epoch: 52\n",
            "Accuracy on training data 99.17%\n",
            "Accuracy on testing data 95.05%\n",
            "Training for epoch: 53\n",
            "Accuracy on training data 99.19%\n",
            "Accuracy on testing data 95.1%\n",
            "Training for epoch: 54\n",
            "Accuracy on training data 99.19%\n",
            "Accuracy on testing data 95.1%\n",
            "Training for epoch: 55\n",
            "Accuracy on training data 99.21%\n",
            "Accuracy on testing data 95.1%\n",
            "Training for epoch: 56\n",
            "Accuracy on training data 99.19%\n",
            "Accuracy on testing data 94.65%\n",
            "Training for epoch: 57\n",
            "Accuracy on training data 99.23%\n",
            "Accuracy on testing data 95.1%\n",
            "Training for epoch: 58\n",
            "Accuracy on training data 99.23%\n",
            "Accuracy on testing data 94.95%\n",
            "Training for epoch: 59\n",
            "Accuracy on training data 99.24%\n",
            "Accuracy on testing data 95.1%\n",
            "Training for epoch: 60\n",
            "Accuracy on training data 99.23%\n",
            "Accuracy on testing data 95.0%\n",
            "Training for epoch: 61\n",
            "Accuracy on training data 99.25%\n",
            "Accuracy on testing data 95.05%\n",
            "Training for epoch: 62\n",
            "Accuracy on training data 99.24%\n",
            "Accuracy on testing data 95.15%\n",
            "Training for epoch: 63\n",
            "Accuracy on training data 99.25%\n",
            "Accuracy on testing data 95.05%\n",
            "Training for epoch: 64\n",
            "Accuracy on training data 99.24%\n",
            "Accuracy on testing data 94.8%\n",
            "Training for epoch: 65\n",
            "Accuracy on training data 99.25%\n",
            "Accuracy on testing data 95.0%\n",
            "Training for epoch: 66\n",
            "Accuracy on training data 99.25%\n",
            "Accuracy on testing data 94.85%\n",
            "Training for epoch: 67\n",
            "Accuracy on training data 99.25%\n",
            "Accuracy on testing data 95.2%\n",
            "Training for epoch: 68\n",
            "Accuracy on training data 99.26%\n",
            "Accuracy on testing data 95.0%\n",
            "Training for epoch: 69\n",
            "Accuracy on training data 99.27%\n",
            "Accuracy on testing data 94.95%\n",
            "Training for epoch: 70\n",
            "Accuracy on training data 99.28%\n",
            "Accuracy on testing data 95.05%\n",
            "Training for epoch: 71\n",
            "Accuracy on training data 99.28%\n",
            "Accuracy on testing data 95.1%\n",
            "Training for epoch: 72\n",
            "Accuracy on training data 99.28%\n",
            "Accuracy on testing data 95.2%\n",
            "Training for epoch: 73\n",
            "Accuracy on training data 99.28%\n",
            "Accuracy on testing data 95.05%\n",
            "Training for epoch: 74\n",
            "Accuracy on training data 99.29%\n",
            "Accuracy on testing data 95.2%\n",
            "Training for epoch: 75\n",
            "Accuracy on training data 99.29%\n",
            "Accuracy on testing data 95.1%\n",
            "Training for epoch: 76\n",
            "Accuracy on training data 99.29%\n",
            "Accuracy on testing data 95.15%\n",
            "Training for epoch: 77\n",
            "Accuracy on training data 99.29%\n",
            "Accuracy on testing data 94.75%\n",
            "Training for epoch: 78\n",
            "Accuracy on training data 99.29%\n",
            "Accuracy on testing data 95.0%\n",
            "Training for epoch: 79\n",
            "Accuracy on training data 99.29%\n",
            "Accuracy on testing data 95.05%\n",
            "Training for epoch: 80\n",
            "Accuracy on training data 99.3%\n",
            "Accuracy on testing data 95.05%\n",
            "Training for epoch: 81\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-c47a20f827c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;34m\"dropout_on_input_layer\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     }\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0meval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHyperTuner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTestingConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-89aeaf3ba056>\u001b[0m in \u001b[0;36mtune\u001b[0;34m(self, config, verbose)\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training for epoch: {epoch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"testing\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                     \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-0445ee2cf95f>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, training_loader, verbose)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'MSELoss'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-0445ee2cf95f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FVxKwgei4ix"
      },
      "source": [
        "class TestingConfig:\n",
        "    CONFIG = {\n",
        "        \"size\": [[784, 30, 10]], \n",
        "        \"epochs\": [50],  \n",
        "        \"hidden_act_function\": [\"ReLU\"],  \n",
        "        \"output_act_function\": [\"Softmax\"],  \n",
        "        \"loss_func\": [\"MSELoss\"],  \n",
        "        \"optimizer\": [\"SGD\"],  \n",
        "        \"learning_rate\": [1], \n",
        "        \"weight_decay\": [0.0, 0.1, 0.5, 1, 5],  \n",
        "        \"batch_size\": [10],  \n",
        "        \"testing_dataset_type\": [\"validation\"],  \n",
        "        \"training_size\": [5000],  \n",
        "        \"testing_size\": [2000],  \n",
        "        \"p_to_be_zeroed\": [0.0],  \n",
        "        \"dropout_on_input_layer\": [False],  \n",
        "    }\n",
        "eval_data = HyperTuner().tune(TestingConfig.CONFIG, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "ayhguAyHuoZ8",
        "outputId": "251efea3-4f4a-44ef-9b6d-f825e504ee7c"
      },
      "source": [
        "eval_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hidden_act_function</th>\n",
              "      <th>output_act_function</th>\n",
              "      <th>loss_func</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>testing_dataset_type</th>\n",
              "      <th>training_size</th>\n",
              "      <th>testing_size</th>\n",
              "      <th>p_to_be_zeroed</th>\n",
              "      <th>dropout_on_input_layer</th>\n",
              "      <th>best_accuracy</th>\n",
              "      <th>avg_accuracy</th>\n",
              "      <th>avg_time_taken</th>\n",
              "      <th>size</th>\n",
              "      <th>epochs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>95.50</td>\n",
              "      <td>94.031000</td>\n",
              "      <td>186.375182</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>11.75</td>\n",
              "      <td>10.866667</td>\n",
              "      <td>187.869351</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>11.75</td>\n",
              "      <td>10.233333</td>\n",
              "      <td>239.849532</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ReLU</td>\n",
              "      <td>Softmax</td>\n",
              "      <td>MSELoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>10.40</td>\n",
              "      <td>10.166667</td>\n",
              "      <td>188.426046</td>\n",
              "      <td>[784, 30, 10]</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  hidden_act_function output_act_function  ...           size epochs\n",
              "0                ReLU             Softmax  ...  [784, 30, 10]     50\n",
              "2                ReLU             Softmax  ...  [784, 30, 10]     50\n",
              "1                ReLU             Softmax  ...  [784, 30, 10]     50\n",
              "3                ReLU             Softmax  ...  [784, 30, 10]     50\n",
              "\n",
              "[4 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oLmFm7EkyP12",
        "outputId": "ac1ecc05-6fb1-42be-e2da-8160b3b051fc"
      },
      "source": [
        "class TestingConfig:\n",
        "    CONFIG = {\n",
        "        \"size\": [[784, 30, 10], [784, 100, 10], [784, 100, 100, 10]], \n",
        "        \"epochs\": [50],  \n",
        "        \"hidden_act_function\": [\"ReLU\"],  \n",
        "        \"output_act_function\": [\"ReLU\"],  \n",
        "        \"loss_func\": [\"CrossEntropyLoss\"],  \n",
        "        \"optimizer\": [\"SGD\"],  \n",
        "        \"learning_rate\": [0.01], \n",
        "        \"weight_decay\": [0.0],  \n",
        "        \"batch_size\": [10],  \n",
        "        \"testing_dataset_type\": [\"validation\"],  \n",
        "        \"training_size\": [10000],  \n",
        "        \"testing_size\": [2000],  \n",
        "        \"p_to_be_zeroed\": [0.0],  \n",
        "        \"dropout_on_input_layer\": [False],  \n",
        "    }\n",
        "eval_data = HyperTuner().tune(TestingConfig.CONFIG, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total combinations for exp: 3\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 56.98%\n",
            "Accuracy on testing data 56.9%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 71.78%\n",
            "Accuracy on testing data 71.55%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 75.86%\n",
            "Accuracy on testing data 75.75%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 77.94%\n",
            "Accuracy on testing data 78.0%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 79.27%\n",
            "Accuracy on testing data 78.85%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 80.19%\n",
            "Accuracy on testing data 80.1%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 80.86%\n",
            "Accuracy on testing data 80.8%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 81.65%\n",
            "Accuracy on testing data 81.45%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 82.2%\n",
            "Accuracy on testing data 81.7%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 82.56%\n",
            "Accuracy on testing data 81.8%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 82.86%\n",
            "Accuracy on testing data 82.1%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 83.18%\n",
            "Accuracy on testing data 82.35%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 83.46%\n",
            "Accuracy on testing data 82.2%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 83.8%\n",
            "Accuracy on testing data 82.35%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 84.02%\n",
            "Accuracy on testing data 82.6%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 84.18%\n",
            "Accuracy on testing data 82.65%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 84.36%\n",
            "Accuracy on testing data 82.85%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 84.54%\n",
            "Accuracy on testing data 83.0%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 84.76%\n",
            "Accuracy on testing data 83.3%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 84.98%\n",
            "Accuracy on testing data 83.5%\n",
            "Training for epoch: 20\n",
            "Accuracy on training data 85.16%\n",
            "Accuracy on testing data 83.55%\n",
            "Training for epoch: 21\n",
            "Accuracy on training data 85.38%\n",
            "Accuracy on testing data 83.6%\n",
            "Training for epoch: 22\n",
            "Accuracy on training data 85.5%\n",
            "Accuracy on testing data 83.6%\n",
            "Training for epoch: 23\n",
            "Accuracy on training data 85.57%\n",
            "Accuracy on testing data 83.7%\n",
            "Training for epoch: 24\n",
            "Accuracy on training data 85.75%\n",
            "Accuracy on testing data 83.8%\n",
            "Training for epoch: 25\n",
            "Accuracy on training data 85.87%\n",
            "Accuracy on testing data 83.85%\n",
            "Training for epoch: 26\n",
            "Accuracy on training data 86.06%\n",
            "Accuracy on testing data 83.95%\n",
            "Training for epoch: 27\n",
            "Accuracy on training data 86.16%\n",
            "Accuracy on testing data 84.1%\n",
            "Training for epoch: 28\n",
            "Accuracy on training data 86.23%\n",
            "Accuracy on testing data 84.15%\n",
            "Training for epoch: 29\n",
            "Accuracy on training data 86.35%\n",
            "Accuracy on testing data 84.25%\n",
            "Training for epoch: 30\n",
            "Accuracy on training data 86.47%\n",
            "Accuracy on testing data 84.3%\n",
            "Training for epoch: 31\n",
            "Accuracy on training data 86.56%\n",
            "Accuracy on testing data 84.35%\n",
            "Training for epoch: 32\n",
            "Accuracy on training data 86.64%\n",
            "Accuracy on testing data 84.4%\n",
            "Training for epoch: 33\n",
            "Accuracy on training data 86.79%\n",
            "Accuracy on testing data 84.3%\n",
            "Training for epoch: 34\n",
            "Accuracy on training data 86.89%\n",
            "Accuracy on testing data 84.35%\n",
            "Training for epoch: 35\n",
            "Accuracy on training data 87.01%\n",
            "Accuracy on testing data 84.4%\n",
            "Training for epoch: 36\n",
            "Accuracy on training data 87.08%\n",
            "Accuracy on testing data 84.4%\n",
            "Training for epoch: 37\n",
            "Accuracy on training data 87.18%\n",
            "Accuracy on testing data 84.3%\n",
            "Training for epoch: 38\n",
            "Accuracy on training data 87.24%\n",
            "Accuracy on testing data 84.3%\n",
            "Training for epoch: 39\n",
            "Accuracy on training data 87.32%\n",
            "Accuracy on testing data 84.45%\n",
            "Training for epoch: 40\n",
            "Accuracy on training data 87.4%\n",
            "Accuracy on testing data 84.35%\n",
            "Training for epoch: 41\n",
            "Accuracy on training data 87.46%\n",
            "Accuracy on testing data 84.4%\n",
            "Training for epoch: 42\n",
            "Accuracy on training data 87.55%\n",
            "Accuracy on testing data 84.45%\n",
            "Training for epoch: 43\n",
            "Accuracy on training data 87.6%\n",
            "Accuracy on testing data 84.5%\n",
            "Training for epoch: 44\n",
            "Accuracy on training data 87.66%\n",
            "Accuracy on testing data 84.65%\n",
            "Training for epoch: 45\n",
            "Accuracy on training data 87.74%\n",
            "Accuracy on testing data 84.7%\n",
            "Training for epoch: 46\n",
            "Accuracy on training data 87.78%\n",
            "Accuracy on testing data 84.8%\n",
            "Training for epoch: 47\n",
            "Accuracy on training data 87.83%\n",
            "Accuracy on testing data 84.85%\n",
            "Training for epoch: 48\n",
            "Accuracy on training data 87.9%\n",
            "Accuracy on testing data 84.85%\n",
            "Training for epoch: 49\n",
            "Accuracy on training data 87.92%\n",
            "Accuracy on testing data 84.85%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 46.76%\n",
            "Accuracy on testing data 48.9%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 47.77%\n",
            "Accuracy on testing data 49.35%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 50.67%\n",
            "Accuracy on testing data 52.35%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 54.14%\n",
            "Accuracy on testing data 55.8%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 54.83%\n",
            "Accuracy on testing data 56.1%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 55.34%\n",
            "Accuracy on testing data 56.55%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 55.61%\n",
            "Accuracy on testing data 56.65%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 55.77%\n",
            "Accuracy on testing data 56.85%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 55.94%\n",
            "Accuracy on testing data 57.05%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 56.06%\n",
            "Accuracy on testing data 57.2%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 56.19%\n",
            "Accuracy on testing data 57.3%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 56.29%\n",
            "Accuracy on testing data 57.4%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 56.37%\n",
            "Accuracy on testing data 57.5%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 56.5%\n",
            "Accuracy on testing data 57.6%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 56.53%\n",
            "Accuracy on testing data 57.65%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 56.62%\n",
            "Accuracy on testing data 57.7%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 56.72%\n",
            "Accuracy on testing data 57.7%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 56.75%\n",
            "Accuracy on testing data 57.7%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 56.85%\n",
            "Accuracy on testing data 57.7%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 56.93%\n",
            "Accuracy on testing data 57.8%\n",
            "Training for epoch: 20\n",
            "Accuracy on training data 56.99%\n",
            "Accuracy on testing data 57.85%\n",
            "Training for epoch: 21\n",
            "Accuracy on training data 57.06%\n",
            "Accuracy on testing data 57.9%\n",
            "Training for epoch: 22\n",
            "Accuracy on training data 57.18%\n",
            "Accuracy on testing data 57.95%\n",
            "Training for epoch: 23\n",
            "Accuracy on training data 57.24%\n",
            "Accuracy on testing data 58.0%\n",
            "Training for epoch: 24\n",
            "Accuracy on training data 57.28%\n",
            "Accuracy on testing data 58.0%\n",
            "Training for epoch: 25\n",
            "Accuracy on training data 57.37%\n",
            "Accuracy on testing data 58.15%\n",
            "Training for epoch: 26\n",
            "Accuracy on training data 57.39%\n",
            "Accuracy on testing data 58.25%\n",
            "Training for epoch: 27\n",
            "Accuracy on training data 57.47%\n",
            "Accuracy on testing data 58.3%\n",
            "Training for epoch: 28\n",
            "Accuracy on training data 57.56%\n",
            "Accuracy on testing data 58.35%\n",
            "Training for epoch: 29\n",
            "Accuracy on training data 57.58%\n",
            "Accuracy on testing data 58.4%\n",
            "Training for epoch: 30\n",
            "Accuracy on training data 57.64%\n",
            "Accuracy on testing data 58.45%\n",
            "Training for epoch: 31\n",
            "Accuracy on training data 57.68%\n",
            "Accuracy on testing data 58.5%\n",
            "Training for epoch: 32\n",
            "Accuracy on training data 57.75%\n",
            "Accuracy on testing data 58.55%\n",
            "Training for epoch: 33\n",
            "Accuracy on training data 57.82%\n",
            "Accuracy on testing data 58.65%\n",
            "Training for epoch: 34\n",
            "Accuracy on training data 57.87%\n",
            "Accuracy on testing data 58.65%\n",
            "Training for epoch: 35\n",
            "Accuracy on training data 57.9%\n",
            "Accuracy on testing data 58.7%\n",
            "Training for epoch: 36\n",
            "Accuracy on training data 57.92%\n",
            "Accuracy on testing data 58.75%\n",
            "Training for epoch: 37\n",
            "Accuracy on training data 57.96%\n",
            "Accuracy on testing data 58.8%\n",
            "Training for epoch: 38\n",
            "Accuracy on training data 58.02%\n",
            "Accuracy on testing data 58.75%\n",
            "Training for epoch: 39\n",
            "Accuracy on training data 58.06%\n",
            "Accuracy on testing data 58.75%\n",
            "Training for epoch: 40\n",
            "Accuracy on training data 58.06%\n",
            "Accuracy on testing data 58.9%\n",
            "Training for epoch: 41\n",
            "Accuracy on training data 58.16%\n",
            "Accuracy on testing data 58.85%\n",
            "Training for epoch: 42\n",
            "Accuracy on training data 58.2%\n",
            "Accuracy on testing data 58.85%\n",
            "Training for epoch: 43\n",
            "Accuracy on training data 58.25%\n",
            "Accuracy on testing data 58.9%\n",
            "Training for epoch: 44\n",
            "Accuracy on training data 58.31%\n",
            "Accuracy on testing data 58.85%\n",
            "Training for epoch: 45\n",
            "Accuracy on training data 58.35%\n",
            "Accuracy on testing data 58.85%\n",
            "Training for epoch: 46\n",
            "Accuracy on training data 58.37%\n",
            "Accuracy on testing data 58.9%\n",
            "Training for epoch: 47\n",
            "Accuracy on training data 58.4%\n",
            "Accuracy on testing data 58.9%\n",
            "Training for epoch: 48\n",
            "Accuracy on training data 58.4%\n",
            "Accuracy on testing data 58.85%\n",
            "Training for epoch: 49\n",
            "Accuracy on training data 58.44%\n",
            "Accuracy on testing data 58.85%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 84.71%\n",
            "Accuracy on testing data 84.7%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 88.76%\n",
            "Accuracy on testing data 88.4%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 89.98%\n",
            "Accuracy on testing data 89.05%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 90.88%\n",
            "Accuracy on testing data 89.6%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 91.4%\n",
            "Accuracy on testing data 89.65%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 91.82%\n",
            "Accuracy on testing data 89.8%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 92.27%\n",
            "Accuracy on testing data 90.15%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 92.61%\n",
            "Accuracy on testing data 90.75%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 92.77%\n",
            "Accuracy on testing data 91.0%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 92.99%\n",
            "Accuracy on testing data 91.15%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 93.27%\n",
            "Accuracy on testing data 91.2%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 93.57%\n",
            "Accuracy on testing data 91.45%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 93.79%\n",
            "Accuracy on testing data 91.65%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 93.96%\n",
            "Accuracy on testing data 91.7%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 94.13%\n",
            "Accuracy on testing data 91.6%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 94.36%\n",
            "Accuracy on testing data 91.45%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 94.54%\n",
            "Accuracy on testing data 91.65%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 94.69%\n",
            "Accuracy on testing data 91.65%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 94.91%\n",
            "Accuracy on testing data 91.95%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 95.13%\n",
            "Accuracy on testing data 92.25%\n",
            "Training for epoch: 20\n",
            "Accuracy on training data 95.2%\n",
            "Accuracy on testing data 92.25%\n",
            "Training for epoch: 21\n",
            "Accuracy on training data 95.34%\n",
            "Accuracy on testing data 92.45%\n",
            "Training for epoch: 22\n",
            "Accuracy on training data 95.49%\n",
            "Accuracy on testing data 92.6%\n",
            "Training for epoch: 23\n",
            "Accuracy on training data 95.66%\n",
            "Accuracy on testing data 92.65%\n",
            "Training for epoch: 24\n",
            "Accuracy on training data 95.8%\n",
            "Accuracy on testing data 92.75%\n",
            "Training for epoch: 25\n",
            "Accuracy on training data 96.02%\n",
            "Accuracy on testing data 92.75%\n",
            "Training for epoch: 26\n",
            "Accuracy on training data 96.19%\n",
            "Accuracy on testing data 92.85%\n",
            "Training for epoch: 27\n",
            "Accuracy on training data 96.33%\n",
            "Accuracy on testing data 92.95%\n",
            "Training for epoch: 28\n",
            "Accuracy on training data 96.47%\n",
            "Accuracy on testing data 93.0%\n",
            "Training for epoch: 29\n",
            "Accuracy on training data 96.57%\n",
            "Accuracy on testing data 93.0%\n",
            "Training for epoch: 30\n",
            "Accuracy on training data 96.67%\n",
            "Accuracy on testing data 93.0%\n",
            "Training for epoch: 31\n",
            "Accuracy on training data 96.74%\n",
            "Accuracy on testing data 93.05%\n",
            "Training for epoch: 32\n",
            "Accuracy on training data 96.9%\n",
            "Accuracy on testing data 93.05%\n",
            "Training for epoch: 33\n",
            "Accuracy on training data 96.93%\n",
            "Accuracy on testing data 93.1%\n",
            "Training for epoch: 34\n",
            "Accuracy on training data 97.06%\n",
            "Accuracy on testing data 93.1%\n",
            "Training for epoch: 35\n",
            "Accuracy on training data 97.19%\n",
            "Accuracy on testing data 93.3%\n",
            "Training for epoch: 36\n",
            "Accuracy on training data 97.28%\n",
            "Accuracy on testing data 93.3%\n",
            "Training for epoch: 37\n",
            "Accuracy on training data 97.36%\n",
            "Accuracy on testing data 93.2%\n",
            "Training for epoch: 38\n",
            "Accuracy on training data 97.47%\n",
            "Accuracy on testing data 93.3%\n",
            "Training for epoch: 39\n",
            "Accuracy on training data 97.58%\n",
            "Accuracy on testing data 93.35%\n",
            "Training for epoch: 40\n",
            "Accuracy on training data 97.6%\n",
            "Accuracy on testing data 93.3%\n",
            "Training for epoch: 41\n",
            "Accuracy on training data 97.67%\n",
            "Accuracy on testing data 93.45%\n",
            "Training for epoch: 42\n",
            "Accuracy on training data 97.74%\n",
            "Accuracy on testing data 93.5%\n",
            "Training for epoch: 43\n",
            "Accuracy on training data 97.77%\n",
            "Accuracy on testing data 93.45%\n",
            "Training for epoch: 44\n",
            "Accuracy on training data 97.81%\n",
            "Accuracy on testing data 93.45%\n",
            "Training for epoch: 45\n",
            "Accuracy on training data 97.89%\n",
            "Accuracy on testing data 93.5%\n",
            "Training for epoch: 46\n",
            "Accuracy on training data 97.98%\n",
            "Accuracy on testing data 93.5%\n",
            "Training for epoch: 47\n",
            "Accuracy on training data 98.0%\n",
            "Accuracy on testing data 93.5%\n",
            "Training for epoch: 48\n",
            "Accuracy on training data 98.07%\n",
            "Accuracy on testing data 93.6%\n",
            "Training for epoch: 49\n",
            "Accuracy on training data 98.16%\n",
            "Accuracy on testing data 93.6%\n",
            "Added record to eval DF. Total records so far: 1\n",
            "            size epochs  ... avg_accuracy avg_time_taken\n",
            "0  [784, 30, 10]     50  ...    77.374667      176.20048\n",
            "\n",
            "[1 rows x 17 columns]\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 71.37%\n",
            "Accuracy on testing data 71.5%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 73.66%\n",
            "Accuracy on testing data 73.5%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 74.43%\n",
            "Accuracy on testing data 73.8%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 74.94%\n",
            "Accuracy on testing data 74.1%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 75.26%\n",
            "Accuracy on testing data 74.35%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 75.45%\n",
            "Accuracy on testing data 74.55%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 75.7%\n",
            "Accuracy on testing data 74.75%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 75.91%\n",
            "Accuracy on testing data 74.95%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 76.12%\n",
            "Accuracy on testing data 75.0%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 76.31%\n",
            "Accuracy on testing data 75.15%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 76.41%\n",
            "Accuracy on testing data 75.25%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 76.55%\n",
            "Accuracy on testing data 75.25%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 76.71%\n",
            "Accuracy on testing data 75.35%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 76.81%\n",
            "Accuracy on testing data 75.35%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 76.93%\n",
            "Accuracy on testing data 75.3%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 77.03%\n",
            "Accuracy on testing data 75.25%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 77.1%\n",
            "Accuracy on testing data 75.4%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 77.21%\n",
            "Accuracy on testing data 75.4%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 77.32%\n",
            "Accuracy on testing data 75.5%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 77.45%\n",
            "Accuracy on testing data 75.5%\n",
            "Training for epoch: 20\n",
            "Accuracy on training data 77.52%\n",
            "Accuracy on testing data 75.65%\n",
            "Training for epoch: 21\n",
            "Accuracy on training data 77.62%\n",
            "Accuracy on testing data 75.8%\n",
            "Training for epoch: 22\n",
            "Accuracy on training data 77.71%\n",
            "Accuracy on testing data 75.85%\n",
            "Training for epoch: 23\n",
            "Accuracy on training data 77.74%\n",
            "Accuracy on testing data 75.95%\n",
            "Training for epoch: 24\n",
            "Accuracy on training data 77.79%\n",
            "Accuracy on testing data 76.0%\n",
            "Training for epoch: 25\n",
            "Accuracy on training data 77.91%\n",
            "Accuracy on testing data 76.1%\n",
            "Training for epoch: 26\n",
            "Accuracy on training data 77.98%\n",
            "Accuracy on testing data 76.1%\n",
            "Training for epoch: 27\n",
            "Accuracy on training data 77.99%\n",
            "Accuracy on testing data 76.15%\n",
            "Training for epoch: 28\n",
            "Accuracy on training data 78.04%\n",
            "Accuracy on testing data 76.15%\n",
            "Training for epoch: 29\n",
            "Accuracy on training data 78.15%\n",
            "Accuracy on testing data 76.15%\n",
            "Training for epoch: 30\n",
            "Accuracy on training data 78.19%\n",
            "Accuracy on testing data 76.1%\n",
            "Training for epoch: 31\n",
            "Accuracy on training data 78.24%\n",
            "Accuracy on testing data 76.15%\n",
            "Training for epoch: 32\n",
            "Accuracy on training data 78.3%\n",
            "Accuracy on testing data 76.2%\n",
            "Training for epoch: 33\n",
            "Accuracy on training data 78.33%\n",
            "Accuracy on testing data 76.25%\n",
            "Training for epoch: 34\n",
            "Accuracy on training data 78.36%\n",
            "Accuracy on testing data 76.4%\n",
            "Training for epoch: 35\n",
            "Accuracy on training data 78.4%\n",
            "Accuracy on testing data 76.45%\n",
            "Training for epoch: 36\n",
            "Accuracy on training data 78.5%\n",
            "Accuracy on testing data 76.55%\n",
            "Training for epoch: 37\n",
            "Accuracy on training data 78.55%\n",
            "Accuracy on testing data 76.55%\n",
            "Training for epoch: 38\n",
            "Accuracy on training data 78.61%\n",
            "Accuracy on testing data 76.55%\n",
            "Training for epoch: 39\n",
            "Accuracy on training data 78.64%\n",
            "Accuracy on testing data 76.6%\n",
            "Training for epoch: 40\n",
            "Accuracy on training data 78.7%\n",
            "Accuracy on testing data 76.6%\n",
            "Training for epoch: 41\n",
            "Accuracy on training data 78.73%\n",
            "Accuracy on testing data 76.65%\n",
            "Training for epoch: 42\n",
            "Accuracy on training data 78.79%\n",
            "Accuracy on testing data 76.7%\n",
            "Training for epoch: 43\n",
            "Accuracy on training data 78.83%\n",
            "Accuracy on testing data 76.7%\n",
            "Training for epoch: 44\n",
            "Accuracy on training data 78.86%\n",
            "Accuracy on testing data 76.7%\n",
            "Training for epoch: 45\n",
            "Accuracy on training data 78.88%\n",
            "Accuracy on testing data 76.7%\n",
            "Training for epoch: 46\n",
            "Accuracy on training data 78.9%\n",
            "Accuracy on testing data 76.7%\n",
            "Training for epoch: 47\n",
            "Accuracy on training data 78.93%\n",
            "Accuracy on testing data 76.75%\n",
            "Training for epoch: 48\n",
            "Accuracy on training data 78.94%\n",
            "Accuracy on testing data 76.85%\n",
            "Training for epoch: 49\n",
            "Accuracy on training data 78.98%\n",
            "Accuracy on testing data 76.85%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 70.89%\n",
            "Accuracy on testing data 70.6%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 73.39%\n",
            "Accuracy on testing data 72.35%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 74.42%\n",
            "Accuracy on testing data 73.8%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 74.89%\n",
            "Accuracy on testing data 74.2%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 81.63%\n",
            "Accuracy on testing data 80.8%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 82.27%\n",
            "Accuracy on testing data 81.4%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 82.65%\n",
            "Accuracy on testing data 81.75%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 83.07%\n",
            "Accuracy on testing data 82.15%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 83.51%\n",
            "Accuracy on testing data 82.6%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 83.79%\n",
            "Accuracy on testing data 82.7%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 84.18%\n",
            "Accuracy on testing data 82.8%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 84.44%\n",
            "Accuracy on testing data 83.0%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 84.68%\n",
            "Accuracy on testing data 83.2%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 84.9%\n",
            "Accuracy on testing data 83.35%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 85.15%\n",
            "Accuracy on testing data 83.6%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 85.36%\n",
            "Accuracy on testing data 83.7%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 85.62%\n",
            "Accuracy on testing data 83.75%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 85.75%\n",
            "Accuracy on testing data 84.0%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 85.89%\n",
            "Accuracy on testing data 84.05%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 86.1%\n",
            "Accuracy on testing data 84.25%\n",
            "Training for epoch: 20\n",
            "Accuracy on training data 86.29%\n",
            "Accuracy on testing data 84.25%\n",
            "Training for epoch: 21\n",
            "Accuracy on training data 86.49%\n",
            "Accuracy on testing data 84.45%\n",
            "Training for epoch: 22\n",
            "Accuracy on training data 86.74%\n",
            "Accuracy on testing data 84.5%\n",
            "Training for epoch: 23\n",
            "Accuracy on training data 86.79%\n",
            "Accuracy on testing data 84.45%\n",
            "Training for epoch: 24\n",
            "Accuracy on training data 86.96%\n",
            "Accuracy on testing data 84.55%\n",
            "Training for epoch: 25\n",
            "Accuracy on training data 87.04%\n",
            "Accuracy on testing data 84.6%\n",
            "Training for epoch: 26\n",
            "Accuracy on training data 96.44%\n",
            "Accuracy on testing data 94.15%\n",
            "Training for epoch: 27\n",
            "Accuracy on training data 96.73%\n",
            "Accuracy on testing data 94.6%\n",
            "Training for epoch: 28\n",
            "Accuracy on training data 96.92%\n",
            "Accuracy on testing data 94.6%\n",
            "Training for epoch: 29\n",
            "Accuracy on training data 97.11%\n",
            "Accuracy on testing data 94.75%\n",
            "Training for epoch: 30\n",
            "Accuracy on training data 97.25%\n",
            "Accuracy on testing data 94.75%\n",
            "Training for epoch: 31\n",
            "Accuracy on training data 97.36%\n",
            "Accuracy on testing data 94.75%\n",
            "Training for epoch: 32\n",
            "Accuracy on training data 97.45%\n",
            "Accuracy on testing data 94.8%\n",
            "Training for epoch: 33\n",
            "Accuracy on training data 97.56%\n",
            "Accuracy on testing data 94.7%\n",
            "Training for epoch: 34\n",
            "Accuracy on training data 97.68%\n",
            "Accuracy on testing data 94.65%\n",
            "Training for epoch: 35\n",
            "Accuracy on training data 97.79%\n",
            "Accuracy on testing data 94.65%\n",
            "Training for epoch: 36\n",
            "Accuracy on training data 97.82%\n",
            "Accuracy on testing data 94.6%\n",
            "Training for epoch: 37\n",
            "Accuracy on training data 97.91%\n",
            "Accuracy on testing data 94.55%\n",
            "Training for epoch: 38\n",
            "Accuracy on training data 97.97%\n",
            "Accuracy on testing data 94.6%\n",
            "Training for epoch: 39\n",
            "Accuracy on training data 98.04%\n",
            "Accuracy on testing data 94.55%\n",
            "Training for epoch: 40\n",
            "Accuracy on training data 98.14%\n",
            "Accuracy on testing data 94.7%\n",
            "Training for epoch: 41\n",
            "Accuracy on training data 98.26%\n",
            "Accuracy on testing data 94.8%\n",
            "Training for epoch: 42\n",
            "Accuracy on training data 98.36%\n",
            "Accuracy on testing data 94.9%\n",
            "Training for epoch: 43\n",
            "Accuracy on training data 98.46%\n",
            "Accuracy on testing data 94.85%\n",
            "Training for epoch: 44\n",
            "Accuracy on training data 98.57%\n",
            "Accuracy on testing data 94.9%\n",
            "Training for epoch: 45\n",
            "Accuracy on training data 98.64%\n",
            "Accuracy on testing data 94.9%\n",
            "Training for epoch: 46\n",
            "Accuracy on training data 98.71%\n",
            "Accuracy on testing data 95.0%\n",
            "Training for epoch: 47\n",
            "Accuracy on training data 98.76%\n",
            "Accuracy on testing data 95.1%\n",
            "Training for epoch: 48\n",
            "Accuracy on training data 98.85%\n",
            "Accuracy on testing data 95.1%\n",
            "Training for epoch: 49\n",
            "Accuracy on training data 98.87%\n",
            "Accuracy on testing data 95.15%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 86.12%\n",
            "Accuracy on testing data 86.3%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 89.23%\n",
            "Accuracy on testing data 88.4%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 90.28%\n",
            "Accuracy on testing data 89.15%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 91.21%\n",
            "Accuracy on testing data 89.6%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 91.58%\n",
            "Accuracy on testing data 90.05%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 91.98%\n",
            "Accuracy on testing data 90.4%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 92.41%\n",
            "Accuracy on testing data 90.65%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 92.73%\n",
            "Accuracy on testing data 90.95%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 93.15%\n",
            "Accuracy on testing data 91.1%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 93.46%\n",
            "Accuracy on testing data 91.6%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 93.69%\n",
            "Accuracy on testing data 91.8%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 93.91%\n",
            "Accuracy on testing data 92.0%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 94.09%\n",
            "Accuracy on testing data 92.1%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 94.35%\n",
            "Accuracy on testing data 92.35%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 94.71%\n",
            "Accuracy on testing data 92.25%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 94.9%\n",
            "Accuracy on testing data 92.35%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 95.17%\n",
            "Accuracy on testing data 92.4%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 95.35%\n",
            "Accuracy on testing data 92.55%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 95.55%\n",
            "Accuracy on testing data 92.6%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 95.84%\n",
            "Accuracy on testing data 92.8%\n",
            "Training for epoch: 20\n",
            "Accuracy on training data 96.04%\n",
            "Accuracy on testing data 92.9%\n",
            "Training for epoch: 21\n",
            "Accuracy on training data 96.22%\n",
            "Accuracy on testing data 93.0%\n",
            "Training for epoch: 22\n",
            "Accuracy on training data 96.4%\n",
            "Accuracy on testing data 93.4%\n",
            "Training for epoch: 23\n",
            "Accuracy on training data 96.61%\n",
            "Accuracy on testing data 93.4%\n",
            "Training for epoch: 24\n",
            "Accuracy on training data 96.8%\n",
            "Accuracy on testing data 93.45%\n",
            "Training for epoch: 25\n",
            "Accuracy on training data 97.01%\n",
            "Accuracy on testing data 93.45%\n",
            "Training for epoch: 26\n",
            "Accuracy on training data 97.12%\n",
            "Accuracy on testing data 93.55%\n",
            "Training for epoch: 27\n",
            "Accuracy on training data 97.23%\n",
            "Accuracy on testing data 93.65%\n",
            "Training for epoch: 28\n",
            "Accuracy on training data 97.34%\n",
            "Accuracy on testing data 93.65%\n",
            "Training for epoch: 29\n",
            "Accuracy on training data 97.47%\n",
            "Accuracy on testing data 93.7%\n",
            "Training for epoch: 30\n",
            "Accuracy on training data 97.6%\n",
            "Accuracy on testing data 93.85%\n",
            "Training for epoch: 31\n",
            "Accuracy on training data 97.76%\n",
            "Accuracy on testing data 93.9%\n",
            "Training for epoch: 32\n",
            "Accuracy on training data 97.85%\n",
            "Accuracy on testing data 93.95%\n",
            "Training for epoch: 33\n",
            "Accuracy on training data 97.98%\n",
            "Accuracy on testing data 94.05%\n",
            "Training for epoch: 34\n",
            "Accuracy on training data 98.08%\n",
            "Accuracy on testing data 94.1%\n",
            "Training for epoch: 35\n",
            "Accuracy on training data 98.15%\n",
            "Accuracy on testing data 94.1%\n",
            "Training for epoch: 36\n",
            "Accuracy on training data 98.25%\n",
            "Accuracy on testing data 94.25%\n",
            "Training for epoch: 37\n",
            "Accuracy on training data 98.32%\n",
            "Accuracy on testing data 94.2%\n",
            "Training for epoch: 38\n",
            "Accuracy on training data 98.42%\n",
            "Accuracy on testing data 94.4%\n",
            "Training for epoch: 39\n",
            "Accuracy on training data 98.5%\n",
            "Accuracy on testing data 94.4%\n",
            "Training for epoch: 40\n",
            "Accuracy on training data 98.54%\n",
            "Accuracy on testing data 94.45%\n",
            "Training for epoch: 41\n",
            "Accuracy on training data 98.64%\n",
            "Accuracy on testing data 94.45%\n",
            "Training for epoch: 42\n",
            "Accuracy on training data 98.7%\n",
            "Accuracy on testing data 94.5%\n",
            "Training for epoch: 43\n",
            "Accuracy on training data 98.78%\n",
            "Accuracy on testing data 94.5%\n",
            "Training for epoch: 44\n",
            "Accuracy on training data 98.86%\n",
            "Accuracy on testing data 94.6%\n",
            "Training for epoch: 45\n",
            "Accuracy on training data 98.9%\n",
            "Accuracy on testing data 94.65%\n",
            "Training for epoch: 46\n",
            "Accuracy on training data 98.97%\n",
            "Accuracy on testing data 94.8%\n",
            "Training for epoch: 47\n",
            "Accuracy on training data 99.0%\n",
            "Accuracy on testing data 94.75%\n",
            "Training for epoch: 48\n",
            "Accuracy on training data 99.08%\n",
            "Accuracy on testing data 94.75%\n",
            "Training for epoch: 49\n",
            "Accuracy on training data 99.13%\n",
            "Accuracy on testing data 94.8%\n",
            "Added record to eval DF. Total records so far: 2\n",
            "             size epochs  ... avg_accuracy avg_time_taken\n",
            "1  [784, 100, 10]     50  ...    85.520333     192.845041\n",
            "0   [784, 30, 10]     50  ...    77.374667     176.200480\n",
            "\n",
            "[2 rows x 17 columns]\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 49.2%\n",
            "Accuracy on testing data 48.85%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 59.69%\n",
            "Accuracy on testing data 60.1%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 75.03%\n",
            "Accuracy on testing data 75.0%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 78.5%\n",
            "Accuracy on testing data 78.75%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 79.96%\n",
            "Accuracy on testing data 80.25%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 81.0%\n",
            "Accuracy on testing data 81.15%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 81.73%\n",
            "Accuracy on testing data 81.55%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 82.29%\n",
            "Accuracy on testing data 82.3%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 82.73%\n",
            "Accuracy on testing data 82.6%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 83.29%\n",
            "Accuracy on testing data 83.05%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 83.31%\n",
            "Accuracy on testing data 82.9%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 83.59%\n",
            "Accuracy on testing data 83.15%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 83.88%\n",
            "Accuracy on testing data 83.4%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 84.27%\n",
            "Accuracy on testing data 83.45%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 84.48%\n",
            "Accuracy on testing data 83.5%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 84.68%\n",
            "Accuracy on testing data 83.8%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 85.04%\n",
            "Accuracy on testing data 83.95%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 85.27%\n",
            "Accuracy on testing data 84.1%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 85.55%\n",
            "Accuracy on testing data 84.1%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 85.77%\n",
            "Accuracy on testing data 84.3%\n",
            "Training for epoch: 20\n",
            "Accuracy on training data 86.01%\n",
            "Accuracy on testing data 84.35%\n",
            "Training for epoch: 21\n",
            "Accuracy on training data 86.25%\n",
            "Accuracy on testing data 84.6%\n",
            "Training for epoch: 22\n",
            "Accuracy on training data 86.47%\n",
            "Accuracy on testing data 84.6%\n",
            "Training for epoch: 23\n",
            "Accuracy on training data 86.62%\n",
            "Accuracy on testing data 84.6%\n",
            "Training for epoch: 24\n",
            "Accuracy on training data 86.77%\n",
            "Accuracy on testing data 84.7%\n",
            "Training for epoch: 25\n",
            "Accuracy on training data 86.95%\n",
            "Accuracy on testing data 84.95%\n",
            "Training for epoch: 26\n",
            "Accuracy on training data 87.07%\n",
            "Accuracy on testing data 85.0%\n",
            "Training for epoch: 27\n",
            "Accuracy on training data 87.31%\n",
            "Accuracy on testing data 85.0%\n",
            "Training for epoch: 28\n",
            "Accuracy on training data 87.44%\n",
            "Accuracy on testing data 85.2%\n",
            "Training for epoch: 29\n",
            "Accuracy on training data 87.59%\n",
            "Accuracy on testing data 85.25%\n",
            "Training for epoch: 30\n",
            "Accuracy on training data 87.7%\n",
            "Accuracy on testing data 85.4%\n",
            "Training for epoch: 31\n",
            "Accuracy on training data 87.82%\n",
            "Accuracy on testing data 85.45%\n",
            "Training for epoch: 32\n",
            "Accuracy on training data 87.91%\n",
            "Accuracy on testing data 85.45%\n",
            "Training for epoch: 33\n",
            "Accuracy on training data 87.95%\n",
            "Accuracy on testing data 85.5%\n",
            "Training for epoch: 34\n",
            "Accuracy on training data 88.08%\n",
            "Accuracy on testing data 85.7%\n",
            "Training for epoch: 35\n",
            "Accuracy on training data 88.17%\n",
            "Accuracy on testing data 85.75%\n",
            "Training for epoch: 36\n",
            "Accuracy on training data 88.25%\n",
            "Accuracy on testing data 85.8%\n",
            "Training for epoch: 37\n",
            "Accuracy on training data 88.37%\n",
            "Accuracy on testing data 85.85%\n",
            "Training for epoch: 38\n",
            "Accuracy on training data 88.43%\n",
            "Accuracy on testing data 85.85%\n",
            "Training for epoch: 39\n",
            "Accuracy on training data 88.41%\n",
            "Accuracy on testing data 85.9%\n",
            "Training for epoch: 40\n",
            "Accuracy on training data 88.44%\n",
            "Accuracy on testing data 85.95%\n",
            "Training for epoch: 41\n",
            "Accuracy on training data 88.51%\n",
            "Accuracy on testing data 85.9%\n",
            "Training for epoch: 42\n",
            "Accuracy on training data 88.51%\n",
            "Accuracy on testing data 85.95%\n",
            "Training for epoch: 43\n",
            "Accuracy on training data 88.52%\n",
            "Accuracy on testing data 86.0%\n",
            "Training for epoch: 44\n",
            "Accuracy on training data 88.53%\n",
            "Accuracy on testing data 85.9%\n",
            "Training for epoch: 45\n",
            "Accuracy on training data 88.53%\n",
            "Accuracy on testing data 85.85%\n",
            "Training for epoch: 46\n",
            "Accuracy on training data 88.6%\n",
            "Accuracy on testing data 86.0%\n",
            "Training for epoch: 47\n",
            "Accuracy on training data 88.6%\n",
            "Accuracy on testing data 86.0%\n",
            "Training for epoch: 48\n",
            "Accuracy on training data 88.62%\n",
            "Accuracy on testing data 86.0%\n",
            "Training for epoch: 49\n",
            "Accuracy on training data 88.64%\n",
            "Accuracy on testing data 85.95%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 70.85%\n",
            "Accuracy on testing data 71.0%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 86.4%\n",
            "Accuracy on testing data 85.85%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 88.83%\n",
            "Accuracy on testing data 89.35%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 90.26%\n",
            "Accuracy on testing data 90.7%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 91.28%\n",
            "Accuracy on testing data 91.25%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 91.89%\n",
            "Accuracy on testing data 91.65%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 92.86%\n",
            "Accuracy on testing data 92.1%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 93.43%\n",
            "Accuracy on testing data 92.55%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 94.09%\n",
            "Accuracy on testing data 93.0%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 94.56%\n",
            "Accuracy on testing data 93.25%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 95.05%\n",
            "Accuracy on testing data 93.6%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 95.52%\n",
            "Accuracy on testing data 94.05%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 95.9%\n",
            "Accuracy on testing data 94.45%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 96.35%\n",
            "Accuracy on testing data 94.5%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 96.66%\n",
            "Accuracy on testing data 94.55%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 96.9%\n",
            "Accuracy on testing data 94.7%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 97.18%\n",
            "Accuracy on testing data 94.75%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 97.44%\n",
            "Accuracy on testing data 94.85%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 97.71%\n",
            "Accuracy on testing data 95.05%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 97.95%\n",
            "Accuracy on testing data 95.15%\n",
            "Training for epoch: 20\n",
            "Accuracy on training data 98.14%\n",
            "Accuracy on testing data 95.15%\n",
            "Training for epoch: 21\n",
            "Accuracy on training data 98.34%\n",
            "Accuracy on testing data 95.2%\n",
            "Training for epoch: 22\n",
            "Accuracy on training data 98.46%\n",
            "Accuracy on testing data 95.3%\n",
            "Training for epoch: 23\n",
            "Accuracy on training data 98.6%\n",
            "Accuracy on testing data 95.45%\n",
            "Training for epoch: 24\n",
            "Accuracy on training data 98.77%\n",
            "Accuracy on testing data 95.45%\n",
            "Training for epoch: 25\n",
            "Accuracy on training data 98.93%\n",
            "Accuracy on testing data 95.45%\n",
            "Training for epoch: 26\n",
            "Accuracy on training data 99.0%\n",
            "Accuracy on testing data 95.4%\n",
            "Training for epoch: 27\n",
            "Accuracy on training data 99.07%\n",
            "Accuracy on testing data 95.5%\n",
            "Training for epoch: 28\n",
            "Accuracy on training data 99.19%\n",
            "Accuracy on testing data 95.4%\n",
            "Training for epoch: 29\n",
            "Accuracy on training data 99.27%\n",
            "Accuracy on testing data 95.45%\n",
            "Training for epoch: 30\n",
            "Accuracy on training data 99.36%\n",
            "Accuracy on testing data 95.55%\n",
            "Training for epoch: 31\n",
            "Accuracy on training data 99.48%\n",
            "Accuracy on testing data 95.6%\n",
            "Training for epoch: 32\n",
            "Accuracy on training data 99.52%\n",
            "Accuracy on testing data 95.7%\n",
            "Training for epoch: 33\n",
            "Accuracy on training data 99.56%\n",
            "Accuracy on testing data 95.8%\n",
            "Training for epoch: 34\n",
            "Accuracy on training data 99.6%\n",
            "Accuracy on testing data 95.75%\n",
            "Training for epoch: 35\n",
            "Accuracy on training data 99.63%\n",
            "Accuracy on testing data 95.8%\n",
            "Training for epoch: 36\n",
            "Accuracy on training data 99.67%\n",
            "Accuracy on testing data 95.75%\n",
            "Training for epoch: 37\n",
            "Accuracy on training data 99.69%\n",
            "Accuracy on testing data 95.75%\n",
            "Training for epoch: 38\n",
            "Accuracy on training data 99.75%\n",
            "Accuracy on testing data 96.0%\n",
            "Training for epoch: 39\n",
            "Accuracy on training data 99.79%\n",
            "Accuracy on testing data 96.0%\n",
            "Training for epoch: 40\n",
            "Accuracy on training data 99.81%\n",
            "Accuracy on testing data 95.95%\n",
            "Training for epoch: 41\n",
            "Accuracy on training data 99.84%\n",
            "Accuracy on testing data 96.0%\n",
            "Training for epoch: 42\n",
            "Accuracy on training data 99.85%\n",
            "Accuracy on testing data 96.0%\n",
            "Training for epoch: 43\n",
            "Accuracy on training data 99.86%\n",
            "Accuracy on testing data 96.05%\n",
            "Training for epoch: 44\n",
            "Accuracy on training data 99.89%\n",
            "Accuracy on testing data 96.1%\n",
            "Training for epoch: 45\n",
            "Accuracy on training data 99.89%\n",
            "Accuracy on testing data 96.1%\n",
            "Training for epoch: 46\n",
            "Accuracy on training data 99.9%\n",
            "Accuracy on testing data 96.05%\n",
            "Training for epoch: 47\n",
            "Accuracy on training data 99.91%\n",
            "Accuracy on testing data 96.0%\n",
            "Training for epoch: 48\n",
            "Accuracy on training data 99.92%\n",
            "Accuracy on testing data 96.05%\n",
            "Training for epoch: 49\n",
            "Accuracy on training data 99.92%\n",
            "Accuracy on testing data 96.15%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 51.88%\n",
            "Accuracy on testing data 51.05%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 60.3%\n",
            "Accuracy on testing data 60.3%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 69.5%\n",
            "Accuracy on testing data 68.3%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 70.98%\n",
            "Accuracy on testing data 69.55%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 71.69%\n",
            "Accuracy on testing data 70.9%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 72.3%\n",
            "Accuracy on testing data 71.3%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 72.9%\n",
            "Accuracy on testing data 71.45%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 73.34%\n",
            "Accuracy on testing data 71.6%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 73.69%\n",
            "Accuracy on testing data 72.05%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 74.1%\n",
            "Accuracy on testing data 72.4%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 74.43%\n",
            "Accuracy on testing data 72.6%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 74.77%\n",
            "Accuracy on testing data 72.8%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 75.09%\n",
            "Accuracy on testing data 73.05%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 75.39%\n",
            "Accuracy on testing data 73.3%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 75.71%\n",
            "Accuracy on testing data 73.5%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 75.98%\n",
            "Accuracy on testing data 73.55%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 76.24%\n",
            "Accuracy on testing data 73.65%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 76.48%\n",
            "Accuracy on testing data 73.85%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 76.61%\n",
            "Accuracy on testing data 73.8%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 76.8%\n",
            "Accuracy on testing data 74.0%\n",
            "Training for epoch: 20\n",
            "Accuracy on training data 76.85%\n",
            "Accuracy on testing data 73.9%\n",
            "Training for epoch: 21\n",
            "Accuracy on training data 76.91%\n",
            "Accuracy on testing data 73.95%\n",
            "Training for epoch: 22\n",
            "Accuracy on training data 77.06%\n",
            "Accuracy on testing data 73.95%\n",
            "Training for epoch: 23\n",
            "Accuracy on training data 77.16%\n",
            "Accuracy on testing data 73.95%\n",
            "Training for epoch: 24\n",
            "Accuracy on training data 77.24%\n",
            "Accuracy on testing data 73.9%\n",
            "Training for epoch: 25\n",
            "Accuracy on training data 77.28%\n",
            "Accuracy on testing data 73.95%\n",
            "Training for epoch: 26\n",
            "Accuracy on training data 77.31%\n",
            "Accuracy on testing data 74.05%\n",
            "Training for epoch: 27\n",
            "Accuracy on training data 77.37%\n",
            "Accuracy on testing data 74.05%\n",
            "Training for epoch: 28\n",
            "Accuracy on training data 77.47%\n",
            "Accuracy on testing data 74.05%\n",
            "Training for epoch: 29\n",
            "Accuracy on training data 77.69%\n",
            "Accuracy on testing data 74.3%\n",
            "Training for epoch: 30\n",
            "Accuracy on training data 77.76%\n",
            "Accuracy on testing data 74.35%\n",
            "Training for epoch: 31\n",
            "Accuracy on training data 77.81%\n",
            "Accuracy on testing data 74.4%\n",
            "Training for epoch: 32\n",
            "Accuracy on training data 77.89%\n",
            "Accuracy on testing data 74.4%\n",
            "Training for epoch: 33\n",
            "Accuracy on training data 77.94%\n",
            "Accuracy on testing data 74.4%\n",
            "Training for epoch: 34\n",
            "Accuracy on training data 77.97%\n",
            "Accuracy on testing data 74.45%\n",
            "Training for epoch: 35\n",
            "Accuracy on training data 78.05%\n",
            "Accuracy on testing data 74.3%\n",
            "Training for epoch: 36\n",
            "Accuracy on training data 78.04%\n",
            "Accuracy on testing data 74.3%\n",
            "Training for epoch: 37\n",
            "Accuracy on training data 78.03%\n",
            "Accuracy on testing data 74.25%\n",
            "Training for epoch: 38\n",
            "Accuracy on training data 78.07%\n",
            "Accuracy on testing data 74.25%\n",
            "Training for epoch: 39\n",
            "Accuracy on training data 78.04%\n",
            "Accuracy on testing data 74.3%\n",
            "Training for epoch: 40\n",
            "Accuracy on training data 78.14%\n",
            "Accuracy on testing data 74.4%\n",
            "Training for epoch: 41\n",
            "Accuracy on training data 78.17%\n",
            "Accuracy on testing data 74.4%\n",
            "Training for epoch: 42\n",
            "Accuracy on training data 78.18%\n",
            "Accuracy on testing data 74.45%\n",
            "Training for epoch: 43\n",
            "Accuracy on training data 78.19%\n",
            "Accuracy on testing data 74.45%\n",
            "Training for epoch: 44\n",
            "Accuracy on training data 78.21%\n",
            "Accuracy on testing data 74.4%\n",
            "Training for epoch: 45\n",
            "Accuracy on training data 78.23%\n",
            "Accuracy on testing data 74.45%\n",
            "Training for epoch: 46\n",
            "Accuracy on training data 78.24%\n",
            "Accuracy on testing data 74.5%\n",
            "Training for epoch: 47\n",
            "Accuracy on training data 78.26%\n",
            "Accuracy on testing data 74.55%\n",
            "Training for epoch: 48\n",
            "Accuracy on training data 78.28%\n",
            "Accuracy on testing data 74.6%\n",
            "Training for epoch: 49\n",
            "Accuracy on training data 78.31%\n",
            "Accuracy on testing data 74.55%\n",
            "Added record to eval DF. Total records so far: 3\n",
            "                  size epochs  ... avg_accuracy avg_time_taken\n",
            "1       [784, 100, 10]     50  ...    85.520333     192.845041\n",
            "2  [784, 100, 100, 10]     50  ...    83.360667     199.749612\n",
            "0        [784, 30, 10]     50  ...    77.374667     176.200480\n",
            "\n",
            "[3 rows x 17 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-c70befec1ae9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;34m\"dropout_on_input_layer\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     }\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0meval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHyperTuner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTestingConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-11747017836d>\u001b[0m in \u001b[0;36mtune\u001b[0;34m(self, config, verbose)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrearrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0meval_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: get() missing 1 required positional argument: 'rearrange'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzNma1cd9EXc",
        "outputId": "ad23bb19-aead-4cc7-f566-4da89000e073"
      },
      "source": [
        "class TestingConfig:\n",
        "    CONFIG = {\n",
        "        \"size\": [[784, 100, 100, 10]], \n",
        "        \"epochs\": [50],  \n",
        "        \"hidden_act_function\": [\"ReLU\"],  \n",
        "        \"output_act_function\": [\"ReLU\"],  \n",
        "        \"loss_func\": [\"CrossEntropyLoss\"],  \n",
        "        \"optimizer\": [\"SGD\"],  \n",
        "        \"learning_rate\": [0.01], \n",
        "        \"weight_decay\": [0.0],  \n",
        "        \"batch_size\": [10],  \n",
        "        \"testing_dataset_type\": [\"validation\"],  \n",
        "        \"training_size\": [10000],  \n",
        "        \"testing_size\": [2000],  \n",
        "        \"p_to_be_zeroed\": [0.0, 0.15, 0.20, 0.25],  \n",
        "        \"dropout_on_input_layer\": [True, False],  \n",
        "    }\n",
        "eval_data = HyperTuner().tune(TestingConfig.CONFIG, False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total combinations for exp: 8\n",
            "Added record to eval DF. Total records so far: 1\n",
            "Added record to eval DF. Total records so far: 2\n",
            "Added record to eval DF. Total records so far: 3\n",
            "Added record to eval DF. Total records so far: 4\n",
            "Added record to eval DF. Total records so far: 5\n",
            "Added record to eval DF. Total records so far: 6\n",
            "Added record to eval DF. Total records so far: 7\n",
            "Added record to eval DF. Total records so far: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "id": "S1pD0ozv-qrF",
        "outputId": "8ea8c996-4bd6-4315-9064-40a0738cf975"
      },
      "source": [
        "eval_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>best_accuracy</th>\n",
              "      <th>avg_accuracy</th>\n",
              "      <th>avg_time_taken</th>\n",
              "      <th>size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>hidden_act_function</th>\n",
              "      <th>output_act_function</th>\n",
              "      <th>loss_func</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>testing_dataset_type</th>\n",
              "      <th>training_size</th>\n",
              "      <th>testing_size</th>\n",
              "      <th>p_to_be_zeroed</th>\n",
              "      <th>dropout_on_input_layer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>95.20</td>\n",
              "      <td>91.750000</td>\n",
              "      <td>134.366458</td>\n",
              "      <td>[784, 100, 100, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.15</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>94.45</td>\n",
              "      <td>91.457333</td>\n",
              "      <td>134.786392</td>\n",
              "      <td>[784, 100, 100, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>93.75</td>\n",
              "      <td>90.518667</td>\n",
              "      <td>137.006188</td>\n",
              "      <td>[784, 100, 100, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.15</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>92.35</td>\n",
              "      <td>89.725000</td>\n",
              "      <td>136.551217</td>\n",
              "      <td>[784, 100, 100, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.20</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>95.00</td>\n",
              "      <td>89.156000</td>\n",
              "      <td>132.419563</td>\n",
              "      <td>[784, 100, 100, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.20</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>91.20</td>\n",
              "      <td>88.756333</td>\n",
              "      <td>138.792837</td>\n",
              "      <td>[784, 100, 100, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>96.15</td>\n",
              "      <td>83.360667</td>\n",
              "      <td>123.694075</td>\n",
              "      <td>[784, 100, 100, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>96.15</td>\n",
              "      <td>83.360667</td>\n",
              "      <td>124.731418</td>\n",
              "      <td>[784, 100, 100, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   best_accuracy  avg_accuracy  ...  p_to_be_zeroed dropout_on_input_layer\n",
              "3          95.20     91.750000  ...            0.15                  False\n",
              "7          94.45     91.457333  ...            0.25                  False\n",
              "2          93.75     90.518667  ...            0.15                   True\n",
              "4          92.35     89.725000  ...            0.20                   True\n",
              "5          95.00     89.156000  ...            0.20                  False\n",
              "6          91.20     88.756333  ...            0.25                   True\n",
              "0          96.15     83.360667  ...            0.00                   True\n",
              "1          96.15     83.360667  ...            0.00                  False\n",
              "\n",
              "[8 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj3glfdzNTL8"
      },
      "source": [
        "class TestingConfig:\n",
        "    CONFIG = {\n",
        "        \"size\": [[784, 100, 100, 10]], \n",
        "        \"epochs\": [50],  \n",
        "        \"hidden_act_function\": [\"ReLU\"],  \n",
        "        \"output_act_function\": [\"ReLU\"],  \n",
        "        \"loss_func\": [\"CrossEntropyLoss\"],  \n",
        "        \"optimizer\": [\"SGD\"],  \n",
        "        \"learning_rate\": [1e-2], \n",
        "        \"weight_decay\": [1e-4, 1e-3, 1e-2],  \n",
        "        \"batch_size\": [10],  \n",
        "        \"testing_dataset_type\": [\"validation\"],  \n",
        "        \"training_size\": [10000],  \n",
        "        \"testing_size\": [2000],  \n",
        "        \"p_to_be_zeroed\": [0.0],  \n",
        "        \"dropout_on_input_layer\": [False],  \n",
        "    }\n",
        "eval_data = HyperTuner().tune(TestingConfig.CONFIG, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "QHPWpwIVUmMX",
        "outputId": "641bb472-cfb9-4ab0-ddef-5910babb41c0"
      },
      "source": [
        "eval_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>best_accuracy</th>\n",
              "      <th>avg_accuracy</th>\n",
              "      <th>avg_time_taken</th>\n",
              "      <th>size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>hidden_act_function</th>\n",
              "      <th>output_act_function</th>\n",
              "      <th>loss_func</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>testing_dataset_type</th>\n",
              "      <th>training_size</th>\n",
              "      <th>testing_size</th>\n",
              "      <th>p_to_be_zeroed</th>\n",
              "      <th>dropout_on_input_layer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>96.0</td>\n",
              "      <td>85.453333</td>\n",
              "      <td>134.261753</td>\n",
              "      <td>[784, 100, 100, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>96.0</td>\n",
              "      <td>81.793333</td>\n",
              "      <td>130.313463</td>\n",
              "      <td>[784, 100, 100, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>93.8</td>\n",
              "      <td>76.666667</td>\n",
              "      <td>130.804522</td>\n",
              "      <td>[784, 100, 100, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   best_accuracy  avg_accuracy  ...  p_to_be_zeroed dropout_on_input_layer\n",
              "0           96.0     85.453333  ...             0.0                  False\n",
              "1           96.0     81.793333  ...             0.0                  False\n",
              "2           93.8     76.666667  ...             0.0                  False\n",
              "\n",
              "[3 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmyEULe4U5NQ",
        "outputId": "cbf6fe75-2ebf-45d6-d1de-3e5b5ea51d38"
      },
      "source": [
        "class TestingConfig:\n",
        "    CONFIG = {\n",
        "        \"size\": [[784, 100, 100, 10]], \n",
        "        \"epochs\": [50],  \n",
        "        \"hidden_act_function\": [\"ReLU\"],  \n",
        "        \"output_act_function\": [\"ReLU\"],  \n",
        "        \"loss_func\": [\"CrossEntropyLoss\"],  \n",
        "        \"optimizer\": [\"SGD\"],  \n",
        "        \"learning_rate\": [1e-2], \n",
        "        \"weight_decay\": [1e-4],  \n",
        "        \"batch_size\": [10, 100, 250],  \n",
        "        \"testing_dataset_type\": [\"validation\"],  \n",
        "        \"training_size\": [10000],  \n",
        "        \"testing_size\": [2000],  \n",
        "        \"p_to_be_zeroed\": [0.0],  \n",
        "        \"dropout_on_input_layer\": [False],  \n",
        "    }\n",
        "eval_data = HyperTuner().tune(TestingConfig.CONFIG, False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total combinations for exp: 3\n",
            "Added record to eval DF. Total records so far: 1\n",
            "Added record to eval DF. Total records so far: 2\n",
            "Added record to eval DF. Total records so far: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "jFTSXIydcnQc",
        "outputId": "ba4ca3c0-e422-495c-aa43-d52892de6d97"
      },
      "source": [
        "eval_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>best_accuracy</th>\n",
              "      <th>avg_accuracy</th>\n",
              "      <th>avg_time_taken</th>\n",
              "      <th>size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>hidden_act_function</th>\n",
              "      <th>output_act_function</th>\n",
              "      <th>loss_func</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>testing_dataset_type</th>\n",
              "      <th>training_size</th>\n",
              "      <th>testing_size</th>\n",
              "      <th>p_to_be_zeroed</th>\n",
              "      <th>dropout_on_input_layer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>96.00</td>\n",
              "      <td>85.453333</td>\n",
              "      <td>129.989560</td>\n",
              "      <td>[784, 100, 100, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>91.95</td>\n",
              "      <td>79.076667</td>\n",
              "      <td>70.637680</td>\n",
              "      <td>[784, 100, 100, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>86.90</td>\n",
              "      <td>69.423333</td>\n",
              "      <td>65.616332</td>\n",
              "      <td>[784, 100, 100, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>250</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   best_accuracy  avg_accuracy  ...  p_to_be_zeroed dropout_on_input_layer\n",
              "0          96.00     85.453333  ...             0.0                  False\n",
              "1          91.95     79.076667  ...             0.0                  False\n",
              "2          86.90     69.423333  ...             0.0                  False\n",
              "\n",
              "[3 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaegUQC_dCNY",
        "outputId": "0f6a48ba-c529-4357-bc32-829135df7040"
      },
      "source": [
        "model = TorchMLP(\n",
        "        size=[784, 100, 100, 10],\n",
        "        loss_func=\"CrossEntropyLoss\",\n",
        "        hidden_act_function=\"ReLU\",\n",
        "        output_act_function=\"ReLU\",\n",
        "        output_act_function_kwargs={},\n",
        "        optimizer=\"SGD\",\n",
        "        learning_rate=1e-2,\n",
        "        lmda_wt_decay=1e-4,\n",
        "        p_to_be_zeroed=0.0,\n",
        "        batch_size=10,\n",
        "        training_size=60000,\n",
        "        testing_size=10000,\n",
        "        seed=21,\n",
        "        dropout_on_input=False\n",
        "    ).to(device)\n",
        "train_data = MNIST(root='mnist_torch_data', train=True, download=True, transform=ToTensor())\n",
        "test_data = MNIST(root='mnist_torch_data', train=False, download=True, transform=ToTensor())\n",
        "training_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
        "testing_loader = DataLoader(test_data, batch_size=10, shuffle=True)\n",
        "for epoch in range(125):\n",
        "    print(f\"Training for epoch: {epoch}\")\n",
        "    model.train_model(training_loader)\n",
        "    model.evaluate(testing_loader, model.testing_size, \"testing\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for epoch: 0\n",
            "Accuracy on training data 74.51%\n",
            "Accuracy on testing data 75.17%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 92.27%\n",
            "Accuracy on testing data 92.41%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 94.48%\n",
            "Accuracy on testing data 94.05%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 95.71%\n",
            "Accuracy on testing data 95.12%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 96.5%\n",
            "Accuracy on testing data 95.92%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 97.05%\n",
            "Accuracy on testing data 96.37%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 97.48%\n",
            "Accuracy on testing data 96.65%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 97.86%\n",
            "Accuracy on testing data 96.94%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 98.05%\n",
            "Accuracy on testing data 97.18%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 98.28%\n",
            "Accuracy on testing data 97.22%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 98.45%\n",
            "Accuracy on testing data 97.27%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 98.6%\n",
            "Accuracy on testing data 97.38%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 98.75%\n",
            "Accuracy on testing data 97.45%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 98.87%\n",
            "Accuracy on testing data 97.48%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 99.0%\n",
            "Accuracy on testing data 97.57%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 99.08%\n",
            "Accuracy on testing data 97.56%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 99.19%\n",
            "Accuracy on testing data 97.62%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 99.24%\n",
            "Accuracy on testing data 97.64%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 99.33%\n",
            "Accuracy on testing data 97.68%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 99.43%\n",
            "Accuracy on testing data 97.71%\n",
            "Training for epoch: 20\n",
            "Accuracy on training data 99.49%\n",
            "Accuracy on testing data 97.78%\n",
            "Training for epoch: 21\n",
            "Accuracy on training data 99.57%\n",
            "Accuracy on testing data 97.78%\n",
            "Training for epoch: 22\n",
            "Accuracy on training data 99.61%\n",
            "Accuracy on testing data 97.76%\n",
            "Training for epoch: 23\n",
            "Accuracy on training data 99.66%\n",
            "Accuracy on testing data 97.79%\n",
            "Training for epoch: 24\n",
            "Accuracy on training data 99.69%\n",
            "Accuracy on testing data 97.82%\n",
            "Training for epoch: 25\n",
            "Accuracy on training data 99.72%\n",
            "Accuracy on testing data 97.8%\n",
            "Training for epoch: 26\n",
            "Accuracy on training data 99.74%\n",
            "Accuracy on testing data 97.79%\n",
            "Training for epoch: 27\n",
            "Accuracy on training data 99.78%\n",
            "Accuracy on testing data 97.77%\n",
            "Training for epoch: 28\n",
            "Accuracy on training data 99.79%\n",
            "Accuracy on testing data 97.73%\n",
            "Training for epoch: 29\n",
            "Accuracy on training data 99.81%\n",
            "Accuracy on testing data 97.77%\n",
            "Training for epoch: 30\n",
            "Accuracy on training data 99.84%\n",
            "Accuracy on testing data 97.81%\n",
            "Training for epoch: 31\n",
            "Accuracy on training data 99.84%\n",
            "Accuracy on testing data 97.79%\n",
            "Training for epoch: 32\n",
            "Accuracy on training data 99.85%\n",
            "Accuracy on testing data 97.78%\n",
            "Training for epoch: 33\n",
            "Accuracy on training data 99.87%\n",
            "Accuracy on testing data 97.79%\n",
            "Training for epoch: 34\n",
            "Accuracy on training data 99.88%\n",
            "Accuracy on testing data 97.79%\n",
            "Training for epoch: 35\n",
            "Accuracy on training data 99.9%\n",
            "Accuracy on testing data 97.8%\n",
            "Training for epoch: 36\n",
            "Accuracy on training data 99.91%\n",
            "Accuracy on testing data 97.8%\n",
            "Training for epoch: 37\n",
            "Accuracy on training data 99.91%\n",
            "Accuracy on testing data 97.81%\n",
            "Training for epoch: 38\n",
            "Accuracy on training data 99.92%\n",
            "Accuracy on testing data 97.81%\n",
            "Training for epoch: 39\n",
            "Accuracy on training data 99.92%\n",
            "Accuracy on testing data 97.8%\n",
            "Training for epoch: 40\n",
            "Accuracy on training data 99.93%\n",
            "Accuracy on testing data 97.8%\n",
            "Training for epoch: 41\n",
            "Accuracy on training data 99.93%\n",
            "Accuracy on testing data 97.83%\n",
            "Training for epoch: 42\n",
            "Accuracy on training data 99.94%\n",
            "Accuracy on testing data 97.83%\n",
            "Training for epoch: 43\n",
            "Accuracy on training data 99.94%\n",
            "Accuracy on testing data 97.83%\n",
            "Training for epoch: 44\n",
            "Accuracy on training data 99.95%\n",
            "Accuracy on testing data 97.84%\n",
            "Training for epoch: 45\n",
            "Accuracy on training data 99.96%\n",
            "Accuracy on testing data 97.87%\n",
            "Training for epoch: 46\n",
            "Accuracy on training data 99.96%\n",
            "Accuracy on testing data 97.87%\n",
            "Training for epoch: 47\n",
            "Accuracy on training data 99.96%\n",
            "Accuracy on testing data 97.85%\n",
            "Training for epoch: 48\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.87%\n",
            "Training for epoch: 49\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.88%\n",
            "Training for epoch: 50\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.89%\n",
            "Training for epoch: 51\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.9%\n",
            "Training for epoch: 52\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.88%\n",
            "Training for epoch: 53\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.89%\n",
            "Training for epoch: 54\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.9%\n",
            "Training for epoch: 55\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.9%\n",
            "Training for epoch: 56\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.89%\n",
            "Training for epoch: 57\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.91%\n",
            "Training for epoch: 58\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.92%\n",
            "Training for epoch: 59\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.93%\n",
            "Training for epoch: 60\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.92%\n",
            "Training for epoch: 61\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.92%\n",
            "Training for epoch: 62\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.93%\n",
            "Training for epoch: 63\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.93%\n",
            "Training for epoch: 64\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.93%\n",
            "Training for epoch: 65\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 66\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.96%\n",
            "Training for epoch: 67\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.94%\n",
            "Training for epoch: 68\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 69\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 70\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 71\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 72\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.97%\n",
            "Training for epoch: 73\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.94%\n",
            "Training for epoch: 74\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.94%\n",
            "Training for epoch: 75\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 76\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 77\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 78\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 79\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 80\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.96%\n",
            "Training for epoch: 81\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 82\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.97%\n",
            "Training for epoch: 83\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.94%\n",
            "Training for epoch: 84\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 85\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 86\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.98%\n",
            "Training for epoch: 87\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 88\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.94%\n",
            "Training for epoch: 89\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 90\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 91\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 92\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 93\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 94\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.94%\n",
            "Training for epoch: 95\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 96\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.96%\n",
            "Training for epoch: 97\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.94%\n",
            "Training for epoch: 98\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.96%\n",
            "Training for epoch: 99\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 100\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.96%\n",
            "Training for epoch: 101\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 102\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 103\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.94%\n",
            "Training for epoch: 104\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 105\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 106\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 107\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 108\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 109\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 110\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 111\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 112\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 113\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 114\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 115\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.94%\n",
            "Training for epoch: 116\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.96%\n",
            "Training for epoch: 117\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.96%\n",
            "Training for epoch: 118\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 119\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.96%\n",
            "Training for epoch: 120\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.94%\n",
            "Training for epoch: 121\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.96%\n",
            "Training for epoch: 122\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 123\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 124\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.94%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQALz1sxejCZ",
        "outputId": "17ab247f-ea22-4b3f-d24b-ae93cf45c56b"
      },
      "source": [
        "model = TorchMLP(\n",
        "        size=[784, 100, 100, 10],\n",
        "        loss_func=\"CrossEntropyLoss\",\n",
        "        hidden_act_function=\"ReLU\",\n",
        "        output_act_function=\"ReLU\",\n",
        "        output_act_function_kwargs={},\n",
        "        optimizer=\"SGD\",\n",
        "        learning_rate=1e-2,\n",
        "        lmda_wt_decay=1e-4,\n",
        "        p_to_be_zeroed=0.20,\n",
        "        batch_size=10,\n",
        "        training_size=60000,\n",
        "        testing_size=10000,\n",
        "        seed=21,\n",
        "        dropout_on_input=False\n",
        "    ).to(device)\n",
        "train_data = MNIST(root='mnist_torch_data', train=True, download=True, transform=ToTensor())\n",
        "test_data = MNIST(root='mnist_torch_data', train=False, download=True, transform=ToTensor())\n",
        "training_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
        "testing_loader = DataLoader(test_data, batch_size=10, shuffle=True)\n",
        "for epoch in range(125):\n",
        "    print(f\"Training for epoch: {epoch}\")\n",
        "    model.train_model(training_loader)\n",
        "    model.evaluate(testing_loader, model.testing_size, \"testing\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for epoch: 0\n",
            "Accuracy on training data 83.66%\n",
            "Accuracy on testing data 83.87%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 92.9%\n",
            "Accuracy on testing data 92.52%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 94.67%\n",
            "Accuracy on testing data 94.03%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 95.67%\n",
            "Accuracy on testing data 94.81%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 96.43%\n",
            "Accuracy on testing data 95.32%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 96.89%\n",
            "Accuracy on testing data 95.69%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 97.24%\n",
            "Accuracy on testing data 96.04%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 97.55%\n",
            "Accuracy on testing data 96.28%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 97.84%\n",
            "Accuracy on testing data 96.57%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 98.04%\n",
            "Accuracy on testing data 96.75%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 98.24%\n",
            "Accuracy on testing data 96.81%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 98.42%\n",
            "Accuracy on testing data 96.9%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 98.48%\n",
            "Accuracy on testing data 96.92%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 98.61%\n",
            "Accuracy on testing data 97.0%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 98.7%\n",
            "Accuracy on testing data 97.0%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 98.78%\n",
            "Accuracy on testing data 97.0%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 98.9%\n",
            "Accuracy on testing data 97.13%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 99.02%\n",
            "Accuracy on testing data 97.23%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 99.11%\n",
            "Accuracy on testing data 97.3%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 99.16%\n",
            "Accuracy on testing data 97.27%\n",
            "Training for epoch: 20\n",
            "Accuracy on training data 99.24%\n",
            "Accuracy on testing data 97.33%\n",
            "Training for epoch: 21\n",
            "Accuracy on training data 99.3%\n",
            "Accuracy on testing data 97.37%\n",
            "Training for epoch: 22\n",
            "Accuracy on training data 99.34%\n",
            "Accuracy on testing data 97.42%\n",
            "Training for epoch: 23\n",
            "Accuracy on training data 99.41%\n",
            "Accuracy on testing data 97.44%\n",
            "Training for epoch: 24\n",
            "Accuracy on training data 99.46%\n",
            "Accuracy on testing data 97.48%\n",
            "Training for epoch: 25\n",
            "Accuracy on training data 99.5%\n",
            "Accuracy on testing data 97.5%\n",
            "Training for epoch: 26\n",
            "Accuracy on training data 99.58%\n",
            "Accuracy on testing data 97.5%\n",
            "Training for epoch: 27\n",
            "Accuracy on training data 99.62%\n",
            "Accuracy on testing data 97.5%\n",
            "Training for epoch: 28\n",
            "Accuracy on training data 99.65%\n",
            "Accuracy on testing data 97.49%\n",
            "Training for epoch: 29\n",
            "Accuracy on training data 99.69%\n",
            "Accuracy on testing data 97.49%\n",
            "Training for epoch: 30\n",
            "Accuracy on training data 99.73%\n",
            "Accuracy on testing data 97.47%\n",
            "Training for epoch: 31\n",
            "Accuracy on training data 99.76%\n",
            "Accuracy on testing data 97.46%\n",
            "Training for epoch: 32\n",
            "Accuracy on training data 99.78%\n",
            "Accuracy on testing data 97.43%\n",
            "Training for epoch: 33\n",
            "Accuracy on training data 99.8%\n",
            "Accuracy on testing data 97.42%\n",
            "Training for epoch: 34\n",
            "Accuracy on training data 99.81%\n",
            "Accuracy on testing data 97.42%\n",
            "Training for epoch: 35\n",
            "Accuracy on training data 99.84%\n",
            "Accuracy on testing data 97.43%\n",
            "Training for epoch: 36\n",
            "Accuracy on training data 99.86%\n",
            "Accuracy on testing data 97.46%\n",
            "Training for epoch: 37\n",
            "Accuracy on training data 99.88%\n",
            "Accuracy on testing data 97.49%\n",
            "Training for epoch: 38\n",
            "Accuracy on training data 99.89%\n",
            "Accuracy on testing data 97.5%\n",
            "Training for epoch: 39\n",
            "Accuracy on training data 99.89%\n",
            "Accuracy on testing data 97.48%\n",
            "Training for epoch: 40\n",
            "Accuracy on training data 99.91%\n",
            "Accuracy on testing data 97.47%\n",
            "Training for epoch: 41\n",
            "Accuracy on training data 99.91%\n",
            "Accuracy on testing data 97.46%\n",
            "Training for epoch: 42\n",
            "Accuracy on training data 99.92%\n",
            "Accuracy on testing data 97.5%\n",
            "Training for epoch: 43\n",
            "Accuracy on training data 99.92%\n",
            "Accuracy on testing data 97.5%\n",
            "Training for epoch: 44\n",
            "Accuracy on training data 99.94%\n",
            "Accuracy on testing data 97.5%\n",
            "Training for epoch: 45\n",
            "Accuracy on training data 99.94%\n",
            "Accuracy on testing data 97.48%\n",
            "Training for epoch: 46\n",
            "Accuracy on training data 99.94%\n",
            "Accuracy on testing data 97.49%\n",
            "Training for epoch: 47\n",
            "Accuracy on training data 99.95%\n",
            "Accuracy on testing data 97.5%\n",
            "Training for epoch: 48\n",
            "Accuracy on training data 99.95%\n",
            "Accuracy on testing data 97.52%\n",
            "Training for epoch: 49\n",
            "Accuracy on training data 99.95%\n",
            "Accuracy on testing data 97.49%\n",
            "Training for epoch: 50\n",
            "Accuracy on training data 99.96%\n",
            "Accuracy on testing data 97.49%\n",
            "Training for epoch: 51\n",
            "Accuracy on training data 99.96%\n",
            "Accuracy on testing data 97.5%\n",
            "Training for epoch: 52\n",
            "Accuracy on training data 99.96%\n",
            "Accuracy on testing data 97.47%\n",
            "Training for epoch: 53\n",
            "Accuracy on training data 99.96%\n",
            "Accuracy on testing data 97.48%\n",
            "Training for epoch: 54\n",
            "Accuracy on training data 99.96%\n",
            "Accuracy on testing data 97.47%\n",
            "Training for epoch: 55\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.47%\n",
            "Training for epoch: 56\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.49%\n",
            "Training for epoch: 57\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.47%\n",
            "Training for epoch: 58\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.47%\n",
            "Training for epoch: 59\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.48%\n",
            "Training for epoch: 60\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.47%\n",
            "Training for epoch: 61\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.5%\n",
            "Training for epoch: 62\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.47%\n",
            "Training for epoch: 63\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.47%\n",
            "Training for epoch: 64\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.45%\n",
            "Training for epoch: 65\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.45%\n",
            "Training for epoch: 66\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.44%\n",
            "Training for epoch: 67\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.45%\n",
            "Training for epoch: 68\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.44%\n",
            "Training for epoch: 69\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.44%\n",
            "Training for epoch: 70\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.43%\n",
            "Training for epoch: 71\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.44%\n",
            "Training for epoch: 72\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.43%\n",
            "Training for epoch: 73\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.43%\n",
            "Training for epoch: 74\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.43%\n",
            "Training for epoch: 75\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.42%\n",
            "Training for epoch: 76\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.42%\n",
            "Training for epoch: 77\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.41%\n",
            "Training for epoch: 78\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.4%\n",
            "Training for epoch: 79\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.42%\n",
            "Training for epoch: 80\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.4%\n",
            "Training for epoch: 81\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.41%\n",
            "Training for epoch: 82\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.42%\n",
            "Training for epoch: 83\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.43%\n",
            "Training for epoch: 84\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.45%\n",
            "Training for epoch: 85\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.44%\n",
            "Training for epoch: 86\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.43%\n",
            "Training for epoch: 87\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.45%\n",
            "Training for epoch: 88\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.45%\n",
            "Training for epoch: 89\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.44%\n",
            "Training for epoch: 90\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.46%\n",
            "Training for epoch: 91\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.46%\n",
            "Training for epoch: 92\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.46%\n",
            "Training for epoch: 93\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.47%\n",
            "Training for epoch: 94\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.44%\n",
            "Training for epoch: 95\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.47%\n",
            "Training for epoch: 96\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.47%\n",
            "Training for epoch: 97\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.46%\n",
            "Training for epoch: 98\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.49%\n",
            "Training for epoch: 99\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.44%\n",
            "Training for epoch: 100\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.44%\n",
            "Training for epoch: 101\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.44%\n",
            "Training for epoch: 102\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.44%\n",
            "Training for epoch: 103\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.44%\n",
            "Training for epoch: 104\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.45%\n",
            "Training for epoch: 105\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.45%\n",
            "Training for epoch: 106\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.44%\n",
            "Training for epoch: 107\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.45%\n",
            "Training for epoch: 108\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.46%\n",
            "Training for epoch: 109\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.46%\n",
            "Training for epoch: 110\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.46%\n",
            "Training for epoch: 111\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.47%\n",
            "Training for epoch: 112\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.48%\n",
            "Training for epoch: 113\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.48%\n",
            "Training for epoch: 114\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.48%\n",
            "Training for epoch: 115\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.5%\n",
            "Training for epoch: 116\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.49%\n",
            "Training for epoch: 117\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.5%\n",
            "Training for epoch: 118\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.49%\n",
            "Training for epoch: 119\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.49%\n",
            "Training for epoch: 120\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.49%\n",
            "Training for epoch: 121\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.48%\n",
            "Training for epoch: 122\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.49%\n",
            "Training for epoch: 123\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.48%\n",
            "Training for epoch: 124\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 97.49%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rAhKwKDen5k",
        "outputId": "15d04ddf-59b2-4635-9052-b0eb5ec9b089"
      },
      "source": [
        "model = TorchMLP(\n",
        "        size=[784, 100, 100, 10],\n",
        "        loss_func=\"CrossEntropyLoss\",\n",
        "        hidden_act_function=\"ReLU\",\n",
        "        output_act_function=\"ReLU\",\n",
        "        output_act_function_kwargs={},\n",
        "        optimizer=\"SGD\",\n",
        "        learning_rate=1e-2,\n",
        "        lmda_wt_decay=1e-4,\n",
        "        p_to_be_zeroed=0.10,\n",
        "        batch_size=10,\n",
        "        training_size=60000,\n",
        "        testing_size=10000,\n",
        "        seed=21,\n",
        "        dropout_on_input=False\n",
        "    ).to(device)\n",
        "train_data = MNIST(root='mnist_torch_data', train=True, download=True, transform=ToTensor())\n",
        "test_data = MNIST(root='mnist_torch_data', train=False, download=True, transform=ToTensor())\n",
        "training_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
        "testing_loader = DataLoader(test_data, batch_size=10, shuffle=True)\n",
        "for epoch in range(125):\n",
        "    print(f\"Training for epoch: {epoch}\")\n",
        "    model.train_model(training_loader)\n",
        "    model.evaluate(testing_loader, model.testing_size, \"testing\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for epoch: 0\n",
            "Accuracy on training data 90.37%\n",
            "Accuracy on testing data 90.31%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 93.55%\n",
            "Accuracy on testing data 93.26%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 95.16%\n",
            "Accuracy on testing data 94.6%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 96.1%\n",
            "Accuracy on testing data 95.47%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 96.74%\n",
            "Accuracy on testing data 96.0%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 97.21%\n",
            "Accuracy on testing data 96.35%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 97.51%\n",
            "Accuracy on testing data 96.62%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 97.81%\n",
            "Accuracy on testing data 96.83%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 98.05%\n",
            "Accuracy on testing data 96.82%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 98.3%\n",
            "Accuracy on testing data 96.99%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 98.46%\n",
            "Accuracy on testing data 97.05%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 98.59%\n",
            "Accuracy on testing data 97.14%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 98.77%\n",
            "Accuracy on testing data 97.23%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 98.89%\n",
            "Accuracy on testing data 97.35%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 99.03%\n",
            "Accuracy on testing data 97.37%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 99.1%\n",
            "Accuracy on testing data 97.4%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 99.19%\n",
            "Accuracy on testing data 97.45%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 99.24%\n",
            "Accuracy on testing data 97.42%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 99.3%\n",
            "Accuracy on testing data 97.46%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 99.32%\n",
            "Accuracy on testing data 97.46%\n",
            "Training for epoch: 20\n",
            "Accuracy on training data 99.34%\n",
            "Accuracy on testing data 97.47%\n",
            "Training for epoch: 21\n",
            "Accuracy on training data 99.41%\n",
            "Accuracy on testing data 97.45%\n",
            "Training for epoch: 22\n",
            "Accuracy on training data 99.47%\n",
            "Accuracy on testing data 97.42%\n",
            "Training for epoch: 23\n",
            "Accuracy on training data 99.5%\n",
            "Accuracy on testing data 97.44%\n",
            "Training for epoch: 24\n",
            "Accuracy on training data 99.55%\n",
            "Accuracy on testing data 97.49%\n",
            "Training for epoch: 25\n",
            "Accuracy on training data 99.59%\n",
            "Accuracy on testing data 97.5%\n",
            "Training for epoch: 26\n",
            "Accuracy on training data 99.64%\n",
            "Accuracy on testing data 97.5%\n",
            "Training for epoch: 27\n",
            "Accuracy on training data 99.68%\n",
            "Accuracy on testing data 97.51%\n",
            "Training for epoch: 28\n",
            "Accuracy on training data 99.7%\n",
            "Accuracy on testing data 97.48%\n",
            "Training for epoch: 29\n",
            "Accuracy on training data 99.74%\n",
            "Accuracy on testing data 97.49%\n",
            "Training for epoch: 30\n",
            "Accuracy on training data 99.77%\n",
            "Accuracy on testing data 97.51%\n",
            "Training for epoch: 31\n",
            "Accuracy on training data 99.79%\n",
            "Accuracy on testing data 97.52%\n",
            "Training for epoch: 32\n",
            "Accuracy on training data 99.8%\n",
            "Accuracy on testing data 97.53%\n",
            "Training for epoch: 33\n",
            "Accuracy on training data 99.83%\n",
            "Accuracy on testing data 97.53%\n",
            "Training for epoch: 34\n",
            "Accuracy on training data 99.84%\n",
            "Accuracy on testing data 97.55%\n",
            "Training for epoch: 35\n",
            "Accuracy on training data 99.85%\n",
            "Accuracy on testing data 97.52%\n",
            "Training for epoch: 36\n",
            "Accuracy on training data 99.86%\n",
            "Accuracy on testing data 97.53%\n",
            "Training for epoch: 37\n",
            "Accuracy on training data 99.88%\n",
            "Accuracy on testing data 97.52%\n",
            "Training for epoch: 38\n",
            "Accuracy on training data 99.89%\n",
            "Accuracy on testing data 97.56%\n",
            "Training for epoch: 39\n",
            "Accuracy on training data 99.89%\n",
            "Accuracy on testing data 97.54%\n",
            "Training for epoch: 40\n",
            "Accuracy on training data 99.9%\n",
            "Accuracy on testing data 97.59%\n",
            "Training for epoch: 41\n",
            "Accuracy on training data 99.91%\n",
            "Accuracy on testing data 97.58%\n",
            "Training for epoch: 42\n",
            "Accuracy on training data 99.92%\n",
            "Accuracy on testing data 97.57%\n",
            "Training for epoch: 43\n",
            "Accuracy on training data 99.92%\n",
            "Accuracy on testing data 97.6%\n",
            "Training for epoch: 44\n",
            "Accuracy on training data 99.92%\n",
            "Accuracy on testing data 97.58%\n",
            "Training for epoch: 45\n",
            "Accuracy on training data 99.92%\n",
            "Accuracy on testing data 97.58%\n",
            "Training for epoch: 46\n",
            "Accuracy on training data 99.93%\n",
            "Accuracy on testing data 97.6%\n",
            "Training for epoch: 47\n",
            "Accuracy on training data 99.93%\n",
            "Accuracy on testing data 97.58%\n",
            "Training for epoch: 48\n",
            "Accuracy on training data 99.93%\n",
            "Accuracy on testing data 97.58%\n",
            "Training for epoch: 49\n",
            "Accuracy on training data 99.94%\n",
            "Accuracy on testing data 97.59%\n",
            "Training for epoch: 50\n",
            "Accuracy on training data 99.94%\n",
            "Accuracy on testing data 97.6%\n",
            "Training for epoch: 51\n",
            "Accuracy on training data 99.94%\n",
            "Accuracy on testing data 97.62%\n",
            "Training for epoch: 52\n",
            "Accuracy on training data 99.94%\n",
            "Accuracy on testing data 97.61%\n",
            "Training for epoch: 53\n",
            "Accuracy on training data 99.94%\n",
            "Accuracy on testing data 97.63%\n",
            "Training for epoch: 54\n",
            "Accuracy on training data 99.95%\n",
            "Accuracy on testing data 97.65%\n",
            "Training for epoch: 55\n",
            "Accuracy on training data 99.95%\n",
            "Accuracy on testing data 97.63%\n",
            "Training for epoch: 56\n",
            "Accuracy on training data 99.95%\n",
            "Accuracy on testing data 97.68%\n",
            "Training for epoch: 57\n",
            "Accuracy on training data 99.95%\n",
            "Accuracy on testing data 97.66%\n",
            "Training for epoch: 58\n",
            "Accuracy on training data 99.95%\n",
            "Accuracy on testing data 97.64%\n",
            "Training for epoch: 59\n",
            "Accuracy on training data 99.95%\n",
            "Accuracy on testing data 97.64%\n",
            "Training for epoch: 60\n",
            "Accuracy on training data 99.95%\n",
            "Accuracy on testing data 97.63%\n",
            "Training for epoch: 61\n",
            "Accuracy on training data 99.95%\n",
            "Accuracy on testing data 97.61%\n",
            "Training for epoch: 62\n",
            "Accuracy on training data 99.95%\n",
            "Accuracy on testing data 97.63%\n",
            "Training for epoch: 63\n",
            "Accuracy on training data 99.95%\n",
            "Accuracy on testing data 97.61%\n",
            "Training for epoch: 64\n",
            "Accuracy on training data 99.96%\n",
            "Accuracy on testing data 97.6%\n",
            "Training for epoch: 65\n",
            "Accuracy on training data 99.96%\n",
            "Accuracy on testing data 97.63%\n",
            "Training for epoch: 66\n",
            "Accuracy on training data 99.96%\n",
            "Accuracy on testing data 97.64%\n",
            "Training for epoch: 67\n",
            "Accuracy on training data 99.96%\n",
            "Accuracy on testing data 97.64%\n",
            "Training for epoch: 68\n",
            "Accuracy on training data 99.96%\n",
            "Accuracy on testing data 97.64%\n",
            "Training for epoch: 69\n",
            "Accuracy on training data 99.96%\n",
            "Accuracy on testing data 97.65%\n",
            "Training for epoch: 70\n",
            "Accuracy on training data 99.96%\n",
            "Accuracy on testing data 97.65%\n",
            "Training for epoch: 71\n",
            "Accuracy on training data 99.96%\n",
            "Accuracy on testing data 97.68%\n",
            "Training for epoch: 72\n",
            "Accuracy on training data 99.96%\n",
            "Accuracy on testing data 97.66%\n",
            "Training for epoch: 73\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.66%\n",
            "Training for epoch: 74\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.66%\n",
            "Training for epoch: 75\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.66%\n",
            "Training for epoch: 76\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.66%\n",
            "Training for epoch: 77\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.66%\n",
            "Training for epoch: 78\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.65%\n",
            "Training for epoch: 79\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.65%\n",
            "Training for epoch: 80\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.66%\n",
            "Training for epoch: 81\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.66%\n",
            "Training for epoch: 82\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.67%\n",
            "Training for epoch: 83\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.67%\n",
            "Training for epoch: 84\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.67%\n",
            "Training for epoch: 85\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.7%\n",
            "Training for epoch: 86\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.7%\n",
            "Training for epoch: 87\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.71%\n",
            "Training for epoch: 88\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.73%\n",
            "Training for epoch: 89\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.73%\n",
            "Training for epoch: 90\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.72%\n",
            "Training for epoch: 91\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.73%\n",
            "Training for epoch: 92\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.72%\n",
            "Training for epoch: 93\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.73%\n",
            "Training for epoch: 94\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.71%\n",
            "Training for epoch: 95\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.71%\n",
            "Training for epoch: 96\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.73%\n",
            "Training for epoch: 97\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.73%\n",
            "Training for epoch: 98\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.72%\n",
            "Training for epoch: 99\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.73%\n",
            "Training for epoch: 100\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.71%\n",
            "Training for epoch: 101\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.72%\n",
            "Training for epoch: 102\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.71%\n",
            "Training for epoch: 103\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.71%\n",
            "Training for epoch: 104\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.71%\n",
            "Training for epoch: 105\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.69%\n",
            "Training for epoch: 106\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.7%\n",
            "Training for epoch: 107\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 97.68%\n",
            "Training for epoch: 108\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.7%\n",
            "Training for epoch: 109\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.69%\n",
            "Training for epoch: 110\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.69%\n",
            "Training for epoch: 111\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.72%\n",
            "Training for epoch: 112\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.72%\n",
            "Training for epoch: 113\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.69%\n",
            "Training for epoch: 114\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.69%\n",
            "Training for epoch: 115\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.72%\n",
            "Training for epoch: 116\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.7%\n",
            "Training for epoch: 117\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.7%\n",
            "Training for epoch: 118\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.71%\n",
            "Training for epoch: 119\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.7%\n",
            "Training for epoch: 120\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.7%\n",
            "Training for epoch: 121\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.72%\n",
            "Training for epoch: 122\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.7%\n",
            "Training for epoch: 123\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.71%\n",
            "Training for epoch: 124\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.71%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OqHg6b14PtMJ",
        "outputId": "e4950934-02e6-42ed-fc2a-48ca26131afe"
      },
      "source": [
        "model = TorchMLP(\n",
        "        size=[784, 100, 100, 10],\n",
        "        loss_func=\"CrossEntropyLoss\",\n",
        "        hidden_act_function=\"ReLU\",\n",
        "        output_act_function=\"ReLU\",\n",
        "        output_act_function_kwargs={},\n",
        "        optimizer=\"SGD\",\n",
        "        learning_rate=1e-2,\n",
        "        lmda_wt_decay=1e-4,\n",
        "        p_to_be_zeroed=0.0,\n",
        "        batch_size=10,\n",
        "        training_size=60000,\n",
        "        testing_size=10000,\n",
        "        seed=21,\n",
        "        dropout_on_input=False\n",
        "    ).to(device)\n",
        "torch.manual_seed(35)\n",
        "train_data = MNIST(root='mnist_torch_data', train=True, download=True, transform=ToTensor())\n",
        "test_data = MNIST(root='mnist_torch_data', train=False, download=True, transform=ToTensor())\n",
        "training_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
        "testing_loader = DataLoader(test_data, batch_size=10, shuffle=True)\n",
        "for epoch in range(200):\n",
        "    print(f\"Training for epoch: {epoch}\")\n",
        "    model.train_model(training_loader)\n",
        "    model.evaluate(testing_loader, model.testing_size, \"testing\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for epoch: 0\n",
            "Accuracy on training data 84.16%\n",
            "Accuracy on testing data 84.57%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 85.75%\n",
            "Accuracy on testing data 85.74%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 86.9%\n",
            "Accuracy on testing data 86.56%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 87.65%\n",
            "Accuracy on testing data 87.14%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 88.19%\n",
            "Accuracy on testing data 87.74%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 88.58%\n",
            "Accuracy on testing data 88.16%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 88.86%\n",
            "Accuracy on testing data 88.42%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 89.13%\n",
            "Accuracy on testing data 88.61%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 89.26%\n",
            "Accuracy on testing data 88.69%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 89.43%\n",
            "Accuracy on testing data 88.83%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 89.6%\n",
            "Accuracy on testing data 88.9%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 89.71%\n",
            "Accuracy on testing data 88.98%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 89.83%\n",
            "Accuracy on testing data 88.95%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 89.88%\n",
            "Accuracy on testing data 88.97%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 89.98%\n",
            "Accuracy on testing data 89.0%\n",
            "Training for epoch: 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-3fe16c3b1d98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training for epoch: {epoch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"testing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-0445ee2cf95f>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, training_loader, verbose)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2702\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mversionadded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2703\u001b[0m     \"\"\"\n\u001b[0;32m-> 2704\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array_interface__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2705\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2706\u001b[0m     \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj70ZEo5Un_w",
        "outputId": "60b51f40-c6aa-4165-9ae7-a1aa96996abb"
      },
      "source": [
        "class TestingConfig:\n",
        "    CONFIG = {\n",
        "        \"size\": [[784, 100, 100, 10]], \n",
        "        \"epochs\": [50],  \n",
        "        \"hidden_act_function\": [\"ReLU\"],  \n",
        "        \"output_act_function\": [\"ReLU\"],  \n",
        "        \"loss_func\": [\"CrossEntropyLoss\"],  \n",
        "        \"optimizer\": [\"SGD\"],  \n",
        "        \"learning_rate\": [1e-2], \n",
        "        \"weight_decay\": [1e-4],  \n",
        "        \"batch_size\": [10],  \n",
        "        \"testing_dataset_type\": [\"validation\"],  \n",
        "        \"momentum\": [0.6, 0.7, 0.8, 0.9], \n",
        "        \"training_size\": [10000],  \n",
        "        \"testing_size\": [2000],  \n",
        "        \"p_to_be_zeroed\": [0.0],  \n",
        "        \"dropout_on_input_layer\": [False], \n",
        "    }\n",
        "eval_data = HyperTuner().tune(TestingConfig.CONFIG, False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total combinations for exp: 4\n",
            "Added record to eval DF. Total records so far: 1\n",
            "Added record to eval DF. Total records so far: 2\n",
            "Added record to eval DF. Total records so far: 3\n",
            "Added record to eval DF. Total records so far: 4\n",
            "['size', 'epochs', 'hidden_act_function', 'output_act_function', 'loss_func', 'optimizer', 'learning_rate', 'weight_decay', 'batch_size', 'momentumtesting_dataset_type', 'training_size', 'testing_size', 'p_to_be_zeroed', 'dropout_on_input_layer', 'best_accuracy', 'avg_accuracy', 'avg_time_taken', 'momentum', 'testing_dataset_type']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "G-HCjVqvdcmz",
        "outputId": "eff33ae3-6c9d-4205-88ae-485a1da81fa6"
      },
      "source": [
        "eval_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>avg_time_taken</th>\n",
              "      <th>momentum</th>\n",
              "      <th>testing_dataset_type</th>\n",
              "      <th>size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>hidden_act_function</th>\n",
              "      <th>output_act_function</th>\n",
              "      <th>loss_func</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>momentumtesting_dataset_type</th>\n",
              "      <th>training_size</th>\n",
              "      <th>testing_size</th>\n",
              "      <th>p_to_be_zeroed</th>\n",
              "      <th>dropout_on_input_layer</th>\n",
              "      <th>best_accuracy</th>\n",
              "      <th>avg_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>105.358101</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>[784, 100, 100, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>96.85</td>\n",
              "      <td>93.116667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>104.933231</td>\n",
              "      <td>0.8</td>\n",
              "      <td>validation</td>\n",
              "      <td>[784, 100, 100, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>96.15</td>\n",
              "      <td>88.916667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>104.263320</td>\n",
              "      <td>0.6</td>\n",
              "      <td>validation</td>\n",
              "      <td>[784, 100, 100, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>95.55</td>\n",
              "      <td>82.006667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>104.454231</td>\n",
              "      <td>0.7</td>\n",
              "      <td>validation</td>\n",
              "      <td>[784, 100, 100, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>87.80</td>\n",
              "      <td>79.650000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   avg_time_taken  momentum  ... best_accuracy avg_accuracy\n",
              "3      105.358101       0.9  ...         96.85    93.116667\n",
              "2      104.933231       0.8  ...         96.15    88.916667\n",
              "0      104.263320       0.6  ...         95.55    82.006667\n",
              "1      104.454231       0.7  ...         87.80    79.650000\n",
              "\n",
              "[4 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGjl1kmJk1Jn",
        "outputId": "e44d8f6d-754f-4008-a993-fa5efb42d9dd"
      },
      "source": [
        "model = TorchMLP(\n",
        "        size=[784, 100, 100, 10],\n",
        "        loss_func=\"CrossEntropyLoss\",\n",
        "        hidden_act_function=\"ReLU\",\n",
        "        output_act_function=\"ReLU\",\n",
        "        output_act_function_kwargs={},\n",
        "        optimizer=\"SGD\",\n",
        "        learning_rate=1e-2,\n",
        "        lmda_wt_decay=1e-4,\n",
        "        p_to_be_zeroed=0.0,\n",
        "        batch_size=10,\n",
        "        training_size=60000,\n",
        "        testing_size=10000,\n",
        "        seed=21,\n",
        "        dropout_on_input=False,\n",
        "        momentum=0.9\n",
        "    ).to(device)\n",
        "train_data = MNIST(root='mnist_torch_data', train=True, download=True, transform=ToTensor())\n",
        "test_data = MNIST(root='mnist_torch_data', train=False, download=True, transform=ToTensor())\n",
        "training_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
        "testing_loader = DataLoader(test_data, batch_size=10, shuffle=True)\n",
        "for epoch in range(200):\n",
        "    print(f\"Training for epoch: {epoch}\")\n",
        "    model.train_model(training_loader)\n",
        "    accuracies.append(model.evaluate(testing_loader, model.testing_size, \"testing\"))\n",
        "print(max(accuracies))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for epoch: 0\n",
            "Accuracy on training data 87.94%\n",
            "Accuracy on testing data 87.74%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 97.24%\n",
            "Accuracy on testing data 96.63%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 98.1%\n",
            "Accuracy on testing data 97.27%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 98.17%\n",
            "Accuracy on testing data 97.23%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 98.42%\n",
            "Accuracy on testing data 97.25%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 98.83%\n",
            "Accuracy on testing data 97.43%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 98.52%\n",
            "Accuracy on testing data 97.34%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 98.92%\n",
            "Accuracy on testing data 97.42%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 99.08%\n",
            "Accuracy on testing data 98.02%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 99.18%\n",
            "Accuracy on testing data 97.95%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 98.91%\n",
            "Accuracy on testing data 97.57%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 99.34%\n",
            "Accuracy on testing data 97.88%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 99.08%\n",
            "Accuracy on testing data 97.79%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 99.42%\n",
            "Accuracy on testing data 98.11%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 99.21%\n",
            "Accuracy on testing data 97.76%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 99.47%\n",
            "Accuracy on testing data 98.18%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 98.93%\n",
            "Accuracy on testing data 97.66%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 99.12%\n",
            "Accuracy on testing data 97.71%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 99.42%\n",
            "Accuracy on testing data 97.9%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 99.52%\n",
            "Accuracy on testing data 97.99%\n",
            "Training for epoch: 20\n",
            "Accuracy on training data 99.55%\n",
            "Accuracy on testing data 97.9%\n",
            "Training for epoch: 21\n",
            "Accuracy on training data 99.3%\n",
            "Accuracy on testing data 97.64%\n",
            "Training for epoch: 22\n",
            "Accuracy on training data 99.35%\n",
            "Accuracy on testing data 97.85%\n",
            "Training for epoch: 23\n",
            "Accuracy on training data 99.47%\n",
            "Accuracy on testing data 97.94%\n",
            "Training for epoch: 24\n",
            "Accuracy on training data 99.53%\n",
            "Accuracy on testing data 97.86%\n",
            "Training for epoch: 25\n",
            "Accuracy on training data 99.45%\n",
            "Accuracy on testing data 97.75%\n",
            "Training for epoch: 26\n",
            "Accuracy on training data 99.21%\n",
            "Accuracy on testing data 97.66%\n",
            "Training for epoch: 27\n",
            "Accuracy on training data 98.81%\n",
            "Accuracy on testing data 97.28%\n",
            "Training for epoch: 28\n",
            "Accuracy on training data 99.36%\n",
            "Accuracy on testing data 97.74%\n",
            "Training for epoch: 29\n",
            "Accuracy on training data 99.44%\n",
            "Accuracy on testing data 97.93%\n",
            "Training for epoch: 30\n",
            "Accuracy on training data 99.67%\n",
            "Accuracy on testing data 98.06%\n",
            "Training for epoch: 31\n",
            "Accuracy on training data 99.51%\n",
            "Accuracy on testing data 98.06%\n",
            "Training for epoch: 32\n",
            "Accuracy on training data 99.3%\n",
            "Accuracy on testing data 97.84%\n",
            "Training for epoch: 33\n",
            "Accuracy on training data 99.47%\n",
            "Accuracy on testing data 97.97%\n",
            "Training for epoch: 34\n",
            "Accuracy on training data 99.67%\n",
            "Accuracy on testing data 98.1%\n",
            "Training for epoch: 35\n",
            "Accuracy on training data 99.7%\n",
            "Accuracy on testing data 98.16%\n",
            "Training for epoch: 36\n",
            "Accuracy on training data 99.5%\n",
            "Accuracy on testing data 98.06%\n",
            "Training for epoch: 37\n",
            "Accuracy on training data 99.64%\n",
            "Accuracy on testing data 98.22%\n",
            "Training for epoch: 38\n",
            "Accuracy on training data 99.77%\n",
            "Accuracy on testing data 98.29%\n",
            "Training for epoch: 39\n",
            "Accuracy on training data 99.3%\n",
            "Accuracy on testing data 97.73%\n",
            "Training for epoch: 40\n",
            "Accuracy on training data 99.45%\n",
            "Accuracy on testing data 97.92%\n",
            "Training for epoch: 41\n",
            "Accuracy on training data 99.49%\n",
            "Accuracy on testing data 97.96%\n",
            "Training for epoch: 42\n",
            "Accuracy on training data 99.61%\n",
            "Accuracy on testing data 98.16%\n",
            "Training for epoch: 43\n",
            "Accuracy on training data 99.64%\n",
            "Accuracy on testing data 98.1%\n",
            "Training for epoch: 44\n",
            "Accuracy on training data 99.73%\n",
            "Accuracy on testing data 98.16%\n",
            "Training for epoch: 45\n",
            "Accuracy on training data 99.76%\n",
            "Accuracy on testing data 98.23%\n",
            "Training for epoch: 46\n",
            "Accuracy on training data 99.38%\n",
            "Accuracy on testing data 97.92%\n",
            "Training for epoch: 47\n",
            "Accuracy on training data 99.33%\n",
            "Accuracy on testing data 97.93%\n",
            "Training for epoch: 48\n",
            "Accuracy on training data 99.06%\n",
            "Accuracy on testing data 97.51%\n",
            "Training for epoch: 49\n",
            "Accuracy on training data 99.61%\n",
            "Accuracy on testing data 98.1%\n",
            "Training for epoch: 50\n",
            "Accuracy on training data 99.04%\n",
            "Accuracy on testing data 97.38%\n",
            "Training for epoch: 51\n",
            "Accuracy on training data 99.53%\n",
            "Accuracy on testing data 98.01%\n",
            "Training for epoch: 52\n",
            "Accuracy on training data 99.18%\n",
            "Accuracy on testing data 97.61%\n",
            "Training for epoch: 53\n",
            "Accuracy on training data 99.18%\n",
            "Accuracy on testing data 97.82%\n",
            "Training for epoch: 54\n",
            "Accuracy on training data 99.49%\n",
            "Accuracy on testing data 97.67%\n",
            "Training for epoch: 55\n",
            "Accuracy on training data 99.74%\n",
            "Accuracy on testing data 98.11%\n",
            "Training for epoch: 56\n",
            "Accuracy on training data 99.82%\n",
            "Accuracy on testing data 98.29%\n",
            "Training for epoch: 57\n",
            "Accuracy on training data 99.85%\n",
            "Accuracy on testing data 98.28%\n",
            "Training for epoch: 58\n",
            "Accuracy on training data 99.8%\n",
            "Accuracy on testing data 98.25%\n",
            "Training for epoch: 59\n",
            "Accuracy on training data 99.77%\n",
            "Accuracy on testing data 98.18%\n",
            "Training for epoch: 60\n",
            "Accuracy on training data 99.28%\n",
            "Accuracy on testing data 97.6%\n",
            "Training for epoch: 61\n",
            "Accuracy on training data 98.97%\n",
            "Accuracy on testing data 97.57%\n",
            "Training for epoch: 62\n",
            "Accuracy on training data 99.42%\n",
            "Accuracy on testing data 97.94%\n",
            "Training for epoch: 63\n",
            "Accuracy on training data 99.31%\n",
            "Accuracy on testing data 97.53%\n",
            "Training for epoch: 64\n",
            "Accuracy on training data 99.32%\n",
            "Accuracy on testing data 97.74%\n",
            "Training for epoch: 65\n",
            "Accuracy on training data 99.62%\n",
            "Accuracy on testing data 97.94%\n",
            "Training for epoch: 66\n",
            "Accuracy on training data 99.2%\n",
            "Accuracy on testing data 97.55%\n",
            "Training for epoch: 67\n",
            "Accuracy on training data 99.73%\n",
            "Accuracy on testing data 98.08%\n",
            "Training for epoch: 68\n",
            "Accuracy on training data 99.83%\n",
            "Accuracy on testing data 98.26%\n",
            "Training for epoch: 69\n",
            "Accuracy on training data 99.75%\n",
            "Accuracy on testing data 98.23%\n",
            "Training for epoch: 70\n",
            "Accuracy on training data 99.8%\n",
            "Accuracy on testing data 98.22%\n",
            "Training for epoch: 71\n",
            "Accuracy on training data 99.52%\n",
            "Accuracy on testing data 97.97%\n",
            "Training for epoch: 72\n",
            "Accuracy on training data 99.54%\n",
            "Accuracy on testing data 98.12%\n",
            "Training for epoch: 73\n",
            "Accuracy on training data 99.45%\n",
            "Accuracy on testing data 97.98%\n",
            "Training for epoch: 74\n",
            "Accuracy on training data 99.39%\n",
            "Accuracy on testing data 97.88%\n",
            "Training for epoch: 75\n",
            "Accuracy on training data 99.4%\n",
            "Accuracy on testing data 97.76%\n",
            "Training for epoch: 76\n",
            "Accuracy on training data 99.59%\n",
            "Accuracy on testing data 97.98%\n",
            "Training for epoch: 77\n",
            "Accuracy on training data 99.66%\n",
            "Accuracy on testing data 98.22%\n",
            "Training for epoch: 78\n",
            "Accuracy on training data 99.77%\n",
            "Accuracy on testing data 98.23%\n",
            "Training for epoch: 79\n",
            "Accuracy on training data 99.63%\n",
            "Accuracy on testing data 98.18%\n",
            "Training for epoch: 80\n",
            "Accuracy on training data 99.94%\n",
            "Accuracy on testing data 98.43%\n",
            "Training for epoch: 81\n",
            "Accuracy on training data 99.78%\n",
            "Accuracy on testing data 98.2%\n",
            "Training for epoch: 82\n",
            "Accuracy on training data 99.84%\n",
            "Accuracy on testing data 98.16%\n",
            "Training for epoch: 83\n",
            "Accuracy on training data 99.4%\n",
            "Accuracy on testing data 97.74%\n",
            "Training for epoch: 84\n",
            "Accuracy on training data 99.37%\n",
            "Accuracy on testing data 97.85%\n",
            "Training for epoch: 85\n",
            "Accuracy on training data 99.17%\n",
            "Accuracy on testing data 97.66%\n",
            "Training for epoch: 86\n",
            "Accuracy on training data 99.02%\n",
            "Accuracy on testing data 97.72%\n",
            "Training for epoch: 87\n",
            "Accuracy on training data 99.39%\n",
            "Accuracy on testing data 97.45%\n",
            "Training for epoch: 88\n",
            "Accuracy on training data 99.56%\n",
            "Accuracy on testing data 97.87%\n",
            "Training for epoch: 89\n",
            "Accuracy on training data 99.74%\n",
            "Accuracy on testing data 98.12%\n",
            "Training for epoch: 90\n",
            "Accuracy on training data 99.69%\n",
            "Accuracy on testing data 98.12%\n",
            "Training for epoch: 91\n",
            "Accuracy on training data 99.72%\n",
            "Accuracy on testing data 98.09%\n",
            "Training for epoch: 92\n",
            "Accuracy on training data 99.31%\n",
            "Accuracy on testing data 97.55%\n",
            "Training for epoch: 93\n",
            "Accuracy on training data 99.4%\n",
            "Accuracy on testing data 97.82%\n",
            "Training for epoch: 94\n",
            "Accuracy on training data 99.62%\n",
            "Accuracy on testing data 98.19%\n",
            "Training for epoch: 95\n",
            "Accuracy on training data 99.67%\n",
            "Accuracy on testing data 98.17%\n",
            "Training for epoch: 96\n",
            "Accuracy on training data 99.64%\n",
            "Accuracy on testing data 97.98%\n",
            "Training for epoch: 97\n",
            "Accuracy on training data 99.46%\n",
            "Accuracy on testing data 97.84%\n",
            "Training for epoch: 98\n",
            "Accuracy on training data 99.5%\n",
            "Accuracy on testing data 98.03%\n",
            "Training for epoch: 99\n",
            "Accuracy on training data 98.7%\n",
            "Accuracy on testing data 97.14%\n",
            "Training for epoch: 100\n",
            "Accuracy on training data 99.57%\n",
            "Accuracy on testing data 98.0%\n",
            "Training for epoch: 101\n",
            "Accuracy on training data 99.41%\n",
            "Accuracy on testing data 97.96%\n",
            "Training for epoch: 102\n",
            "Accuracy on training data 99.29%\n",
            "Accuracy on testing data 97.81%\n",
            "Training for epoch: 103\n",
            "Accuracy on training data 99.55%\n",
            "Accuracy on testing data 97.93%\n",
            "Training for epoch: 104\n",
            "Accuracy on training data 99.62%\n",
            "Accuracy on testing data 98.0%\n",
            "Training for epoch: 105\n",
            "Accuracy on training data 99.85%\n",
            "Accuracy on testing data 98.4%\n",
            "Training for epoch: 106\n",
            "Accuracy on training data 99.69%\n",
            "Accuracy on testing data 98.08%\n",
            "Training for epoch: 107\n",
            "Accuracy on training data 99.9%\n",
            "Accuracy on testing data 98.31%\n",
            "Training for epoch: 108\n",
            "Accuracy on training data 99.83%\n",
            "Accuracy on testing data 98.36%\n",
            "Training for epoch: 109\n",
            "Accuracy on training data 99.86%\n",
            "Accuracy on testing data 98.3%\n",
            "Training for epoch: 110\n",
            "Accuracy on training data 99.33%\n",
            "Accuracy on testing data 97.46%\n",
            "Training for epoch: 111\n",
            "Accuracy on training data 97.18%\n",
            "Accuracy on testing data 95.71%\n",
            "Training for epoch: 112\n",
            "Accuracy on training data 99.63%\n",
            "Accuracy on testing data 97.89%\n",
            "Training for epoch: 113\n",
            "Accuracy on training data 99.25%\n",
            "Accuracy on testing data 97.73%\n",
            "Training for epoch: 114\n",
            "Accuracy on training data 99.31%\n",
            "Accuracy on testing data 97.7%\n",
            "Training for epoch: 115\n",
            "Accuracy on training data 99.8%\n",
            "Accuracy on testing data 98.36%\n",
            "Training for epoch: 116\n",
            "Accuracy on training data 99.64%\n",
            "Accuracy on testing data 98.06%\n",
            "Training for epoch: 117\n",
            "Accuracy on training data 99.56%\n",
            "Accuracy on testing data 97.79%\n",
            "Training for epoch: 118\n",
            "Accuracy on training data 99.83%\n",
            "Accuracy on testing data 98.3%\n",
            "Training for epoch: 119\n",
            "Accuracy on training data 99.79%\n",
            "Accuracy on testing data 98.3%\n",
            "Training for epoch: 120\n",
            "Accuracy on training data 99.89%\n",
            "Accuracy on testing data 98.32%\n",
            "Training for epoch: 121\n",
            "Accuracy on training data 99.93%\n",
            "Accuracy on testing data 98.48%\n",
            "Training for epoch: 122\n",
            "Accuracy on training data 99.84%\n",
            "Accuracy on testing data 98.34%\n",
            "Training for epoch: 123\n",
            "Accuracy on training data 99.93%\n",
            "Accuracy on testing data 98.36%\n",
            "Training for epoch: 124\n",
            "Accuracy on training data 99.96%\n",
            "Accuracy on testing data 98.46%\n",
            "Training for epoch: 125\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 98.5%\n",
            "Training for epoch: 126\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 98.5%\n",
            "Training for epoch: 127\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 98.51%\n",
            "Training for epoch: 128\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 98.47%\n",
            "Training for epoch: 129\n",
            "Accuracy on training data 99.96%\n",
            "Accuracy on testing data 98.47%\n",
            "Training for epoch: 130\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 98.45%\n",
            "Training for epoch: 131\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 98.47%\n",
            "Training for epoch: 132\n",
            "Accuracy on training data 99.95%\n",
            "Accuracy on testing data 98.44%\n",
            "Training for epoch: 133\n",
            "Accuracy on training data 99.94%\n",
            "Accuracy on testing data 98.45%\n",
            "Training for epoch: 134\n",
            "Accuracy on training data 99.95%\n",
            "Accuracy on testing data 98.44%\n",
            "Training for epoch: 135\n",
            "Accuracy on training data 99.94%\n",
            "Accuracy on testing data 98.39%\n",
            "Training for epoch: 136\n",
            "Accuracy on training data 98.34%\n",
            "Accuracy on testing data 97.31%\n",
            "Training for epoch: 137\n",
            "Accuracy on training data 99.12%\n",
            "Accuracy on testing data 97.56%\n",
            "Training for epoch: 138\n",
            "Accuracy on training data 99.25%\n",
            "Accuracy on testing data 97.89%\n",
            "Training for epoch: 139\n",
            "Accuracy on training data 98.98%\n",
            "Accuracy on testing data 97.45%\n",
            "Training for epoch: 140\n",
            "Accuracy on training data 99.36%\n",
            "Accuracy on testing data 97.96%\n",
            "Training for epoch: 141\n",
            "Accuracy on training data 99.06%\n",
            "Accuracy on testing data 97.75%\n",
            "Training for epoch: 142\n",
            "Accuracy on training data 99.44%\n",
            "Accuracy on testing data 97.9%\n",
            "Training for epoch: 143\n",
            "Accuracy on training data 99.61%\n",
            "Accuracy on testing data 98.09%\n",
            "Training for epoch: 144\n",
            "Accuracy on training data 99.5%\n",
            "Accuracy on testing data 98.04%\n",
            "Training for epoch: 145\n",
            "Accuracy on training data 99.67%\n",
            "Accuracy on testing data 98.09%\n",
            "Training for epoch: 146\n",
            "Accuracy on training data 99.64%\n",
            "Accuracy on testing data 98.01%\n",
            "Training for epoch: 147\n",
            "Accuracy on training data 99.5%\n",
            "Accuracy on testing data 98.1%\n",
            "Training for epoch: 148\n",
            "Accuracy on training data 99.66%\n",
            "Accuracy on testing data 97.96%\n",
            "Training for epoch: 149\n",
            "Accuracy on training data 99.7%\n",
            "Accuracy on testing data 98.06%\n",
            "Training for epoch: 150\n",
            "Accuracy on training data 99.21%\n",
            "Accuracy on testing data 97.77%\n",
            "Training for epoch: 151\n",
            "Accuracy on training data 99.55%\n",
            "Accuracy on testing data 97.93%\n",
            "Training for epoch: 152\n",
            "Accuracy on training data 99.55%\n",
            "Accuracy on testing data 97.87%\n",
            "Training for epoch: 153\n",
            "Accuracy on training data 99.82%\n",
            "Accuracy on testing data 98.26%\n",
            "Training for epoch: 154\n",
            "Accuracy on training data 99.51%\n",
            "Accuracy on testing data 97.78%\n",
            "Training for epoch: 155\n",
            "Accuracy on training data 99.79%\n",
            "Accuracy on testing data 98.24%\n",
            "Training for epoch: 156\n",
            "Accuracy on training data 99.69%\n",
            "Accuracy on testing data 98.11%\n",
            "Training for epoch: 157\n",
            "Accuracy on training data 99.64%\n",
            "Accuracy on testing data 97.81%\n",
            "Training for epoch: 158\n",
            "Accuracy on training data 99.69%\n",
            "Accuracy on testing data 98.12%\n",
            "Training for epoch: 159\n",
            "Accuracy on training data 99.68%\n",
            "Accuracy on testing data 98.15%\n",
            "Training for epoch: 160\n",
            "Accuracy on training data 99.55%\n",
            "Accuracy on testing data 98.0%\n",
            "Training for epoch: 161\n",
            "Accuracy on training data 99.5%\n",
            "Accuracy on testing data 97.99%\n",
            "Training for epoch: 162\n",
            "Accuracy on training data 99.25%\n",
            "Accuracy on testing data 97.51%\n",
            "Training for epoch: 163\n",
            "Accuracy on training data 99.39%\n",
            "Accuracy on testing data 97.78%\n",
            "Training for epoch: 164\n",
            "Accuracy on training data 99.56%\n",
            "Accuracy on testing data 97.98%\n",
            "Training for epoch: 165\n",
            "Accuracy on training data 99.61%\n",
            "Accuracy on testing data 97.99%\n",
            "Training for epoch: 166\n",
            "Accuracy on training data 99.67%\n",
            "Accuracy on testing data 98.09%\n",
            "Training for epoch: 167\n",
            "Accuracy on training data 99.84%\n",
            "Accuracy on testing data 98.17%\n",
            "Training for epoch: 168\n",
            "Accuracy on training data 99.22%\n",
            "Accuracy on testing data 97.47%\n",
            "Training for epoch: 169\n",
            "Accuracy on training data 99.69%\n",
            "Accuracy on testing data 98.0%\n",
            "Training for epoch: 170\n",
            "Accuracy on training data 99.28%\n",
            "Accuracy on testing data 97.72%\n",
            "Training for epoch: 171\n",
            "Accuracy on training data 99.74%\n",
            "Accuracy on testing data 98.14%\n",
            "Training for epoch: 172\n",
            "Accuracy on training data 99.68%\n",
            "Accuracy on testing data 98.11%\n",
            "Training for epoch: 173\n",
            "Accuracy on training data 99.45%\n",
            "Accuracy on testing data 97.82%\n",
            "Training for epoch: 174\n",
            "Accuracy on training data 99.28%\n",
            "Accuracy on testing data 97.72%\n",
            "Training for epoch: 175\n",
            "Accuracy on training data 99.24%\n",
            "Accuracy on testing data 97.63%\n",
            "Training for epoch: 176\n",
            "Accuracy on training data 98.93%\n",
            "Accuracy on testing data 97.48%\n",
            "Training for epoch: 177\n",
            "Accuracy on training data 99.77%\n",
            "Accuracy on testing data 98.11%\n",
            "Training for epoch: 178\n",
            "Accuracy on training data 99.58%\n",
            "Accuracy on testing data 97.89%\n",
            "Training for epoch: 179\n",
            "Accuracy on training data 99.5%\n",
            "Accuracy on testing data 97.92%\n",
            "Training for epoch: 180\n",
            "Accuracy on training data 99.44%\n",
            "Accuracy on testing data 97.8%\n",
            "Training for epoch: 181\n",
            "Accuracy on training data 99.22%\n",
            "Accuracy on testing data 97.78%\n",
            "Training for epoch: 182\n",
            "Accuracy on training data 99.61%\n",
            "Accuracy on testing data 97.84%\n",
            "Training for epoch: 183\n",
            "Accuracy on training data 99.57%\n",
            "Accuracy on testing data 98.06%\n",
            "Training for epoch: 184\n",
            "Accuracy on training data 99.86%\n",
            "Accuracy on testing data 98.23%\n",
            "Training for epoch: 185\n",
            "Accuracy on training data 99.72%\n",
            "Accuracy on testing data 98.04%\n",
            "Training for epoch: 186\n",
            "Accuracy on training data 99.96%\n",
            "Accuracy on testing data 98.49%\n",
            "Training for epoch: 187\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 98.5%\n",
            "Training for epoch: 188\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 98.48%\n",
            "Training for epoch: 189\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 98.53%\n",
            "Training for epoch: 190\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 98.51%\n",
            "Training for epoch: 191\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 98.51%\n",
            "Training for epoch: 192\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 98.51%\n",
            "Training for epoch: 193\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 98.5%\n",
            "Training for epoch: 194\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 98.48%\n",
            "Training for epoch: 195\n",
            "Accuracy on training data 99.96%\n",
            "Accuracy on testing data 98.49%\n",
            "Training for epoch: 196\n",
            "Accuracy on training data 99.97%\n",
            "Accuracy on testing data 98.49%\n",
            "Training for epoch: 197\n",
            "Accuracy on training data 99.96%\n",
            "Accuracy on testing data 98.45%\n",
            "Training for epoch: 198\n",
            "Accuracy on training data 98.33%\n",
            "Accuracy on testing data 96.98%\n",
            "Training for epoch: 199\n",
            "Accuracy on training data 98.88%\n",
            "Accuracy on testing data 97.61%\n",
            "98.53\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG03TlW1XnLc"
      },
      "source": [
        "Conclude with a peak of **98.53** accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8bKCF8O4Aeo",
        "outputId": "97edc1b2-24b2-4737-8de5-7afc3a1a3f28"
      },
      "source": [
        "model = TorchMLP(\n",
        "        size=[784, 100, 100, 10],\n",
        "        loss_func=\"CrossEntropyLoss\",\n",
        "        hidden_act_function=\"ReLU\",\n",
        "        output_act_function=\"ReLU\",\n",
        "        output_act_function_kwargs={},\n",
        "        optimizer=\"SGD\",\n",
        "        learning_rate=1e-2,\n",
        "        lmda_wt_decay=1e-4,\n",
        "        p_to_be_zeroed=0.20,\n",
        "        batch_size=10,\n",
        "        training_size=60000,\n",
        "        testing_size=10000,\n",
        "        seed=21,\n",
        "        dropout_on_input=False,\n",
        "        momentum=0.9\n",
        "    ).to(device)\n",
        "train_data = MNIST(root='mnist_torch_data', train=True, download=True, transform=ToTensor())\n",
        "test_data = MNIST(root='mnist_torch_data', train=False, download=True, transform=ToTensor())\n",
        "training_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
        "testing_loader = DataLoader(test_data, batch_size=10, shuffle=True)\n",
        "accuracies = []\n",
        "for epoch in range(200):\n",
        "    print(f\"Training for epoch: {epoch}\")\n",
        "    model.train_model(training_loader)\n",
        "    accuracies.append(model.evaluate(testing_loader, model.testing_size, \"testing\"))\n",
        "print(max(accuracies))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for epoch: 0\n",
            "Accuracy on training data 96.08%\n",
            "Accuracy on testing data 95.29%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 97.43%\n",
            "Accuracy on testing data 96.48%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 97.52%\n",
            "Accuracy on testing data 96.31%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 98.17%\n",
            "Accuracy on testing data 96.71%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 98.31%\n",
            "Accuracy on testing data 96.72%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 98.41%\n",
            "Accuracy on testing data 96.7%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 98.84%\n",
            "Accuracy on testing data 97.02%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 98.66%\n",
            "Accuracy on testing data 96.96%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 98.36%\n",
            "Accuracy on testing data 96.59%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 98.96%\n",
            "Accuracy on testing data 97.04%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 99.11%\n",
            "Accuracy on testing data 97.23%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 99.16%\n",
            "Accuracy on testing data 97.36%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 98.96%\n",
            "Accuracy on testing data 97.18%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 98.92%\n",
            "Accuracy on testing data 97.02%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 99.02%\n",
            "Accuracy on testing data 96.94%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 99.25%\n",
            "Accuracy on testing data 97.61%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 99.11%\n",
            "Accuracy on testing data 97.11%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 99.39%\n",
            "Accuracy on testing data 97.63%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 99.04%\n",
            "Accuracy on testing data 97.22%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 99.47%\n",
            "Accuracy on testing data 97.54%\n",
            "Training for epoch: 20\n",
            "Accuracy on training data 99.01%\n",
            "Accuracy on testing data 97.36%\n",
            "Training for epoch: 21\n",
            "Accuracy on training data 99.39%\n",
            "Accuracy on testing data 97.5%\n",
            "Training for epoch: 22\n",
            "Accuracy on training data 99.61%\n",
            "Accuracy on testing data 97.69%\n",
            "Training for epoch: 23\n",
            "Accuracy on training data 99.41%\n",
            "Accuracy on testing data 97.44%\n",
            "Training for epoch: 24\n",
            "Accuracy on training data 99.55%\n",
            "Accuracy on testing data 97.5%\n",
            "Training for epoch: 25\n",
            "Accuracy on training data 99.25%\n",
            "Accuracy on testing data 97.28%\n",
            "Training for epoch: 26\n",
            "Accuracy on training data 99.41%\n",
            "Accuracy on testing data 97.66%\n",
            "Training for epoch: 27\n",
            "Accuracy on training data 99.35%\n",
            "Accuracy on testing data 97.63%\n",
            "Training for epoch: 28\n",
            "Accuracy on training data 99.52%\n",
            "Accuracy on testing data 97.75%\n",
            "Training for epoch: 29\n",
            "Accuracy on training data 99.56%\n",
            "Accuracy on testing data 97.67%\n",
            "Training for epoch: 30\n",
            "Accuracy on training data 99.33%\n",
            "Accuracy on testing data 97.24%\n",
            "Training for epoch: 31\n",
            "Accuracy on training data 99.52%\n",
            "Accuracy on testing data 97.53%\n",
            "Training for epoch: 32\n",
            "Accuracy on training data 99.53%\n",
            "Accuracy on testing data 97.71%\n",
            "Training for epoch: 33\n",
            "Accuracy on training data 99.06%\n",
            "Accuracy on testing data 97.2%\n",
            "Training for epoch: 34\n",
            "Accuracy on training data 99.33%\n",
            "Accuracy on testing data 97.47%\n",
            "Training for epoch: 35\n",
            "Accuracy on training data 99.65%\n",
            "Accuracy on testing data 97.69%\n",
            "Training for epoch: 36\n",
            "Accuracy on training data 99.37%\n",
            "Accuracy on testing data 97.3%\n",
            "Training for epoch: 37\n",
            "Accuracy on training data 99.61%\n",
            "Accuracy on testing data 97.51%\n",
            "Training for epoch: 38\n",
            "Accuracy on training data 99.68%\n",
            "Accuracy on testing data 97.62%\n",
            "Training for epoch: 39\n",
            "Accuracy on training data 99.49%\n",
            "Accuracy on testing data 97.49%\n",
            "Training for epoch: 40\n",
            "Accuracy on training data 99.5%\n",
            "Accuracy on testing data 97.42%\n",
            "Training for epoch: 41\n",
            "Accuracy on training data 99.75%\n",
            "Accuracy on testing data 97.86%\n",
            "Training for epoch: 42\n",
            "Accuracy on training data 99.51%\n",
            "Accuracy on testing data 97.51%\n",
            "Training for epoch: 43\n",
            "Accuracy on training data 99.51%\n",
            "Accuracy on testing data 97.55%\n",
            "Training for epoch: 44\n",
            "Accuracy on training data 99.32%\n",
            "Accuracy on testing data 97.6%\n",
            "Training for epoch: 45\n",
            "Accuracy on training data 99.38%\n",
            "Accuracy on testing data 97.42%\n",
            "Training for epoch: 46\n",
            "Accuracy on training data 99.49%\n",
            "Accuracy on testing data 97.42%\n",
            "Training for epoch: 47\n",
            "Accuracy on training data 99.22%\n",
            "Accuracy on testing data 97.34%\n",
            "Training for epoch: 48\n",
            "Accuracy on training data 99.61%\n",
            "Accuracy on testing data 97.63%\n",
            "Training for epoch: 49\n",
            "Accuracy on training data 99.48%\n",
            "Accuracy on testing data 97.45%\n",
            "Training for epoch: 50\n",
            "Accuracy on training data 99.84%\n",
            "Accuracy on testing data 97.93%\n",
            "Training for epoch: 51\n",
            "Accuracy on training data 99.5%\n",
            "Accuracy on testing data 97.63%\n",
            "Training for epoch: 52\n",
            "Accuracy on training data 99.44%\n",
            "Accuracy on testing data 97.33%\n",
            "Training for epoch: 53\n",
            "Accuracy on training data 99.57%\n",
            "Accuracy on testing data 97.65%\n",
            "Training for epoch: 54\n",
            "Accuracy on training data 99.56%\n",
            "Accuracy on testing data 97.46%\n",
            "Training for epoch: 55\n",
            "Accuracy on training data 99.21%\n",
            "Accuracy on testing data 97.38%\n",
            "Training for epoch: 56\n",
            "Accuracy on training data 99.5%\n",
            "Accuracy on testing data 97.41%\n",
            "Training for epoch: 57\n",
            "Accuracy on training data 99.37%\n",
            "Accuracy on testing data 97.44%\n",
            "Training for epoch: 58\n",
            "Accuracy on training data 99.52%\n",
            "Accuracy on testing data 97.79%\n",
            "Training for epoch: 59\n",
            "Accuracy on training data 99.45%\n",
            "Accuracy on testing data 97.49%\n",
            "Training for epoch: 60\n",
            "Accuracy on training data 99.6%\n",
            "Accuracy on testing data 97.61%\n",
            "Training for epoch: 61\n",
            "Accuracy on training data 99.61%\n",
            "Accuracy on testing data 97.59%\n",
            "Training for epoch: 62\n",
            "Accuracy on training data 99.6%\n",
            "Accuracy on testing data 97.6%\n",
            "Training for epoch: 63\n",
            "Accuracy on training data 99.56%\n",
            "Accuracy on testing data 97.72%\n",
            "Training for epoch: 64\n",
            "Accuracy on training data 99.45%\n",
            "Accuracy on testing data 97.53%\n",
            "Training for epoch: 65\n",
            "Accuracy on training data 99.41%\n",
            "Accuracy on testing data 97.55%\n",
            "Training for epoch: 66\n",
            "Accuracy on training data 99.18%\n",
            "Accuracy on testing data 97.25%\n",
            "Training for epoch: 67\n",
            "Accuracy on training data 99.59%\n",
            "Accuracy on testing data 97.66%\n",
            "Training for epoch: 68\n",
            "Accuracy on training data 99.58%\n",
            "Accuracy on testing data 97.58%\n",
            "Training for epoch: 69\n",
            "Accuracy on training data 99.66%\n",
            "Accuracy on testing data 97.64%\n",
            "Training for epoch: 70\n",
            "Accuracy on training data 99.6%\n",
            "Accuracy on testing data 97.72%\n",
            "Training for epoch: 71\n",
            "Accuracy on training data 99.74%\n",
            "Accuracy on testing data 97.72%\n",
            "Training for epoch: 72\n",
            "Accuracy on training data 99.62%\n",
            "Accuracy on testing data 97.73%\n",
            "Training for epoch: 73\n",
            "Accuracy on training data 99.61%\n",
            "Accuracy on testing data 97.61%\n",
            "Training for epoch: 74\n",
            "Accuracy on training data 98.78%\n",
            "Accuracy on testing data 96.81%\n",
            "Training for epoch: 75\n",
            "Accuracy on training data 99.04%\n",
            "Accuracy on testing data 97.16%\n",
            "Training for epoch: 76\n",
            "Accuracy on training data 99.44%\n",
            "Accuracy on testing data 97.45%\n",
            "Training for epoch: 77\n",
            "Accuracy on training data 99.36%\n",
            "Accuracy on testing data 97.55%\n",
            "Training for epoch: 78\n",
            "Accuracy on training data 99.59%\n",
            "Accuracy on testing data 97.76%\n",
            "Training for epoch: 79\n",
            "Accuracy on training data 99.55%\n",
            "Accuracy on testing data 97.6%\n",
            "Training for epoch: 80\n",
            "Accuracy on training data 99.63%\n",
            "Accuracy on testing data 97.59%\n",
            "Training for epoch: 81\n",
            "Accuracy on training data 99.8%\n",
            "Accuracy on testing data 97.78%\n",
            "Training for epoch: 82\n",
            "Accuracy on training data 99.76%\n",
            "Accuracy on testing data 97.93%\n",
            "Training for epoch: 83\n",
            "Accuracy on training data 99.77%\n",
            "Accuracy on testing data 97.74%\n",
            "Training for epoch: 84\n",
            "Accuracy on training data 99.82%\n",
            "Accuracy on testing data 97.65%\n",
            "Training for epoch: 85\n",
            "Accuracy on training data 99.92%\n",
            "Accuracy on testing data 98.05%\n",
            "Training for epoch: 86\n",
            "Accuracy on training data 99.93%\n",
            "Accuracy on testing data 97.9%\n",
            "Training for epoch: 87\n",
            "Accuracy on training data 99.64%\n",
            "Accuracy on testing data 97.52%\n",
            "Training for epoch: 88\n",
            "Accuracy on training data 99.03%\n",
            "Accuracy on testing data 97.11%\n",
            "Training for epoch: 89\n",
            "Accuracy on training data 99.59%\n",
            "Accuracy on testing data 97.65%\n",
            "Training for epoch: 90\n",
            "Accuracy on training data 98.94%\n",
            "Accuracy on testing data 96.79%\n",
            "Training for epoch: 91\n",
            "Accuracy on training data 99.47%\n",
            "Accuracy on testing data 97.48%\n",
            "Training for epoch: 92\n",
            "Accuracy on training data 99.79%\n",
            "Accuracy on testing data 97.85%\n",
            "Training for epoch: 93\n",
            "Accuracy on training data 99.71%\n",
            "Accuracy on testing data 97.8%\n",
            "Training for epoch: 94\n",
            "Accuracy on training data 99.67%\n",
            "Accuracy on testing data 97.88%\n",
            "Training for epoch: 95\n",
            "Accuracy on training data 99.72%\n",
            "Accuracy on testing data 97.78%\n",
            "Training for epoch: 96\n",
            "Accuracy on training data 99.73%\n",
            "Accuracy on testing data 97.76%\n",
            "Training for epoch: 97\n",
            "Accuracy on training data 99.76%\n",
            "Accuracy on testing data 97.98%\n",
            "Training for epoch: 98\n",
            "Accuracy on training data 99.44%\n",
            "Accuracy on testing data 97.55%\n",
            "Training for epoch: 99\n",
            "Accuracy on training data 99.91%\n",
            "Accuracy on testing data 97.99%\n",
            "Training for epoch: 100\n",
            "Accuracy on training data 99.79%\n",
            "Accuracy on testing data 97.88%\n",
            "Training for epoch: 101\n",
            "Accuracy on training data 99.95%\n",
            "Accuracy on testing data 98.0%\n",
            "Training for epoch: 102\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 98.06%\n",
            "Training for epoch: 103\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 98.04%\n",
            "Training for epoch: 104\n",
            "Accuracy on training data 99.99%\n",
            "Accuracy on testing data 98.08%\n",
            "Training for epoch: 105\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 98.05%\n",
            "Training for epoch: 106\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 98.06%\n",
            "Training for epoch: 107\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 98.01%\n",
            "Training for epoch: 108\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 98.01%\n",
            "Training for epoch: 109\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 98.01%\n",
            "Training for epoch: 110\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 97.99%\n",
            "Training for epoch: 111\n",
            "Accuracy on training data 99.98%\n",
            "Accuracy on testing data 98.01%\n",
            "Training for epoch: 112\n",
            "Accuracy on training data 99.95%\n",
            "Accuracy on testing data 97.96%\n",
            "Training for epoch: 113\n",
            "Accuracy on training data 98.02%\n",
            "Accuracy on testing data 96.81%\n",
            "Training for epoch: 114\n",
            "Accuracy on training data 99.06%\n",
            "Accuracy on testing data 97.47%\n",
            "Training for epoch: 115\n",
            "Accuracy on training data 99.43%\n",
            "Accuracy on testing data 97.69%\n",
            "Training for epoch: 116\n",
            "Accuracy on training data 99.3%\n",
            "Accuracy on testing data 97.39%\n",
            "Training for epoch: 117\n",
            "Accuracy on training data 99.36%\n",
            "Accuracy on testing data 97.5%\n",
            "Training for epoch: 118\n",
            "Accuracy on training data 99.49%\n",
            "Accuracy on testing data 97.55%\n",
            "Training for epoch: 119\n",
            "Accuracy on training data 99.35%\n",
            "Accuracy on testing data 97.53%\n",
            "Training for epoch: 120\n",
            "Accuracy on training data 99.42%\n",
            "Accuracy on testing data 97.6%\n",
            "Training for epoch: 121\n",
            "Accuracy on training data 99.48%\n",
            "Accuracy on testing data 97.63%\n",
            "Training for epoch: 122\n",
            "Accuracy on training data 99.52%\n",
            "Accuracy on testing data 97.64%\n",
            "Training for epoch: 123\n",
            "Accuracy on training data 99.48%\n",
            "Accuracy on testing data 97.73%\n",
            "Training for epoch: 124\n",
            "Accuracy on training data 99.68%\n",
            "Accuracy on testing data 97.49%\n",
            "Training for epoch: 125\n",
            "Accuracy on training data 99.54%\n",
            "Accuracy on testing data 97.63%\n",
            "Training for epoch: 126\n",
            "Accuracy on training data 99.56%\n",
            "Accuracy on testing data 97.73%\n",
            "Training for epoch: 127\n",
            "Accuracy on training data 99.67%\n",
            "Accuracy on testing data 97.84%\n",
            "Training for epoch: 128\n",
            "Accuracy on training data 99.71%\n",
            "Accuracy on testing data 97.64%\n",
            "Training for epoch: 129\n",
            "Accuracy on training data 99.62%\n",
            "Accuracy on testing data 97.68%\n",
            "Training for epoch: 130\n",
            "Accuracy on training data 99.52%\n",
            "Accuracy on testing data 97.65%\n",
            "Training for epoch: 131\n",
            "Accuracy on training data 99.31%\n",
            "Accuracy on testing data 97.22%\n",
            "Training for epoch: 132\n",
            "Accuracy on training data 99.56%\n",
            "Accuracy on testing data 97.6%\n",
            "Training for epoch: 133\n",
            "Accuracy on training data 99.82%\n",
            "Accuracy on testing data 97.86%\n",
            "Training for epoch: 134\n",
            "Accuracy on training data 99.45%\n",
            "Accuracy on testing data 97.4%\n",
            "Training for epoch: 135\n",
            "Accuracy on training data 99.31%\n",
            "Accuracy on testing data 97.35%\n",
            "Training for epoch: 136\n",
            "Accuracy on training data 99.53%\n",
            "Accuracy on testing data 97.75%\n",
            "Training for epoch: 137\n",
            "Accuracy on training data 99.64%\n",
            "Accuracy on testing data 97.66%\n",
            "Training for epoch: 138\n",
            "Accuracy on training data 99.78%\n",
            "Accuracy on testing data 97.84%\n",
            "Training for epoch: 139\n",
            "Accuracy on training data 99.44%\n",
            "Accuracy on testing data 97.52%\n",
            "Training for epoch: 140\n",
            "Accuracy on training data 99.86%\n",
            "Accuracy on testing data 97.93%\n",
            "Training for epoch: 141\n",
            "Accuracy on training data 99.79%\n",
            "Accuracy on testing data 97.94%\n",
            "Training for epoch: 142\n",
            "Accuracy on training data 99.78%\n",
            "Accuracy on testing data 97.83%\n",
            "Training for epoch: 143\n",
            "Accuracy on training data 99.41%\n",
            "Accuracy on testing data 97.57%\n",
            "Training for epoch: 144\n",
            "Accuracy on training data 99.28%\n",
            "Accuracy on testing data 97.43%\n",
            "Training for epoch: 145\n",
            "Accuracy on training data 99.13%\n",
            "Accuracy on testing data 97.49%\n",
            "Training for epoch: 146\n",
            "Accuracy on training data 99.69%\n",
            "Accuracy on testing data 97.6%\n",
            "Training for epoch: 147\n",
            "Accuracy on training data 99.46%\n",
            "Accuracy on testing data 97.54%\n",
            "Training for epoch: 148\n",
            "Accuracy on training data 99.27%\n",
            "Accuracy on testing data 97.33%\n",
            "Training for epoch: 149\n",
            "Accuracy on training data 99.7%\n",
            "Accuracy on testing data 97.96%\n",
            "Training for epoch: 150\n",
            "Accuracy on training data 99.59%\n",
            "Accuracy on testing data 97.84%\n",
            "Training for epoch: 151\n",
            "Accuracy on training data 99.83%\n",
            "Accuracy on testing data 97.99%\n",
            "Training for epoch: 152\n",
            "Accuracy on training data 99.82%\n",
            "Accuracy on testing data 97.9%\n",
            "Training for epoch: 153\n",
            "Accuracy on training data 99.6%\n",
            "Accuracy on testing data 97.73%\n",
            "Training for epoch: 154\n",
            "Accuracy on training data 99.65%\n",
            "Accuracy on testing data 97.74%\n",
            "Training for epoch: 155\n",
            "Accuracy on training data 99.42%\n",
            "Accuracy on testing data 97.48%\n",
            "Training for epoch: 156\n",
            "Accuracy on training data 99.7%\n",
            "Accuracy on testing data 97.69%\n",
            "Training for epoch: 157\n",
            "Accuracy on training data 99.34%\n",
            "Accuracy on testing data 97.26%\n",
            "Training for epoch: 158\n",
            "Accuracy on training data 99.72%\n",
            "Accuracy on testing data 97.93%\n",
            "Training for epoch: 159\n",
            "Accuracy on training data 99.69%\n",
            "Accuracy on testing data 97.64%\n",
            "Training for epoch: 160\n",
            "Accuracy on training data 99.34%\n",
            "Accuracy on testing data 97.44%\n",
            "Training for epoch: 161\n",
            "Accuracy on training data 99.62%\n",
            "Accuracy on testing data 97.57%\n",
            "Training for epoch: 162\n",
            "Accuracy on training data 99.69%\n",
            "Accuracy on testing data 97.62%\n",
            "Training for epoch: 163\n",
            "Accuracy on training data 99.62%\n",
            "Accuracy on testing data 97.46%\n",
            "Training for epoch: 164\n",
            "Accuracy on training data 99.63%\n",
            "Accuracy on testing data 97.8%\n",
            "Training for epoch: 165\n",
            "Accuracy on training data 99.59%\n",
            "Accuracy on testing data 97.73%\n",
            "Training for epoch: 166\n",
            "Accuracy on training data 99.65%\n",
            "Accuracy on testing data 97.82%\n",
            "Training for epoch: 167\n",
            "Accuracy on training data 99.38%\n",
            "Accuracy on testing data 97.24%\n",
            "Training for epoch: 168\n",
            "Accuracy on training data 99.78%\n",
            "Accuracy on testing data 97.81%\n",
            "Training for epoch: 169\n",
            "Accuracy on training data 99.69%\n",
            "Accuracy on testing data 97.77%\n",
            "Training for epoch: 170\n",
            "Accuracy on training data 99.82%\n",
            "Accuracy on testing data 97.82%\n",
            "Training for epoch: 171\n",
            "Accuracy on training data 99.56%\n",
            "Accuracy on testing data 97.5%\n",
            "Training for epoch: 172\n",
            "Accuracy on training data 99.67%\n",
            "Accuracy on testing data 97.88%\n",
            "Training for epoch: 173\n",
            "Accuracy on training data 99.76%\n",
            "Accuracy on testing data 97.86%\n",
            "Training for epoch: 174\n",
            "Accuracy on training data 99.72%\n",
            "Accuracy on testing data 97.87%\n",
            "Training for epoch: 175\n",
            "Accuracy on training data 99.61%\n",
            "Accuracy on testing data 97.73%\n",
            "Training for epoch: 176\n",
            "Accuracy on training data 99.58%\n",
            "Accuracy on testing data 97.64%\n",
            "Training for epoch: 177\n",
            "Accuracy on training data 99.26%\n",
            "Accuracy on testing data 97.47%\n",
            "Training for epoch: 178\n",
            "Accuracy on training data 99.64%\n",
            "Accuracy on testing data 97.54%\n",
            "Training for epoch: 179\n",
            "Accuracy on training data 99.3%\n",
            "Accuracy on testing data 97.35%\n",
            "Training for epoch: 180\n",
            "Accuracy on training data 99.71%\n",
            "Accuracy on testing data 97.76%\n",
            "Training for epoch: 181\n",
            "Accuracy on training data 99.69%\n",
            "Accuracy on testing data 97.79%\n",
            "Training for epoch: 182\n",
            "Accuracy on training data 99.69%\n",
            "Accuracy on testing data 97.87%\n",
            "Training for epoch: 183\n",
            "Accuracy on training data 99.76%\n",
            "Accuracy on testing data 97.81%\n",
            "Training for epoch: 184\n",
            "Accuracy on training data 99.87%\n",
            "Accuracy on testing data 97.96%\n",
            "Training for epoch: 185\n",
            "Accuracy on training data 99.67%\n",
            "Accuracy on testing data 97.61%\n",
            "Training for epoch: 186\n",
            "Accuracy on training data 99.76%\n",
            "Accuracy on testing data 97.88%\n",
            "Training for epoch: 187\n",
            "Accuracy on training data 99.73%\n",
            "Accuracy on testing data 97.99%\n",
            "Training for epoch: 188\n",
            "Accuracy on training data 99.85%\n",
            "Accuracy on testing data 98.13%\n",
            "Training for epoch: 189\n",
            "Accuracy on training data 99.86%\n",
            "Accuracy on testing data 98.03%\n",
            "Training for epoch: 190\n",
            "Accuracy on training data 99.72%\n",
            "Accuracy on testing data 97.73%\n",
            "Training for epoch: 191\n",
            "Accuracy on training data 98.95%\n",
            "Accuracy on testing data 97.1%\n",
            "Training for epoch: 192\n",
            "Accuracy on training data 99.42%\n",
            "Accuracy on testing data 97.73%\n",
            "Training for epoch: 193\n",
            "Accuracy on training data 99.57%\n",
            "Accuracy on testing data 97.68%\n",
            "Training for epoch: 194\n",
            "Accuracy on training data 99.38%\n",
            "Accuracy on testing data 97.51%\n",
            "Training for epoch: 195\n",
            "Accuracy on training data 99.55%\n",
            "Accuracy on testing data 97.7%\n",
            "Training for epoch: 196\n",
            "Accuracy on training data 99.73%\n",
            "Accuracy on testing data 97.81%\n",
            "Training for epoch: 197\n",
            "Accuracy on training data 99.63%\n",
            "Accuracy on testing data 97.67%\n",
            "Training for epoch: 198\n",
            "Accuracy on training data 99.61%\n",
            "Accuracy on testing data 97.75%\n",
            "Training for epoch: 199\n",
            "Accuracy on training data 99.6%\n",
            "Accuracy on testing data 97.74%\n",
            "98.13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObHoUpSxX03x"
      },
      "source": [
        "Introducing dropout does not seem to help. Better with no dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913,
          "referenced_widgets": [
            "5cff260761f94caa977d05bd2bdb6cd6",
            "0e884a1d69b5476bb3490af05217747a",
            "a8fcd9aff02a4607b6fbd0680e479531",
            "1bf686c0260d47d6b48be4b5aa961a95",
            "a97bb5b62b1f42cd816afe8242023176",
            "fe64fbe1258d4f0987ade4a922396bea",
            "213daecc473f40b98809a3cc9f58bcd6",
            "907b3afbfe8441a69c65c455b832e80d",
            "225c9b73996f43fab7a866a67c1ff9f0",
            "1edce11b6c5a40b59631cdfc73c01501",
            "151204098fcc46acae5bca98f6d90126",
            "e8c11f1f1fcc43e7ae737022b3a20ac0",
            "c4b59fba17094e0ab2f77094da8a0ca3",
            "cb5444d6fdab4096a895835dd7830417",
            "ddf041b8aaef437b902e62df4da6a0b5",
            "4f0afcedf8e44caab4a27508d0129288",
            "5f8e0290036a47ee844271c83ac2d1fa",
            "d37a7fb61dda48ca8db18929c28878a7",
            "278499e42f8140fea90c94b6fe08f4ad",
            "2a55016bdd5a44279e8b3cf0403c6a55",
            "192736de2eaa479cb5141a9eb2299ada",
            "f4342d27c7c54115be3c5141a156b79d",
            "249e9bb7698a47019eda5783c5385055",
            "5ba26beb692148a1a2d8c7762e3db5f3",
            "2479445cfb5e44fc9835e7690670f6a1",
            "13852165992b449383f3532ef33baf63",
            "ea5cef1e1bd447b3ae46d0408a580a94",
            "68e83959a5c44918b80b199791029887",
            "c76067d82d53469695c8998a59c2f871",
            "7b68446713dd49319b0e8b0e5eeadcd1",
            "3c65b358faa543ef85f6a101892e23d6",
            "00f0afa0100f46feba389784a3183d08"
          ]
        },
        "id": "YhD814rFcQvY",
        "outputId": "b87f8e6d-d47b-4a89-9ebc-94a19eaf3723"
      },
      "source": [
        "class TestingConfig:\n",
        "    CONFIG = {\n",
        "        \"size\": [[784, 100, 100, 10]], \n",
        "        \"epochs\": [50],  \n",
        "        \"hidden_act_function\": [\"ReLU\"],  \n",
        "        \"output_act_function\": [\"ReLU\"],  \n",
        "        \"loss_func\": [\"CrossEntropyLoss\"],  \n",
        "        \"optimizer\": [\"SGD\"],  \n",
        "        \"learning_rate\": [1e-2], \n",
        "        \"weight_decay\": [1e-4],  \n",
        "        \"batch_size\": [10],  \n",
        "        \"testing_dataset_type\": [\"validation\"],  \n",
        "        \"momentum\": [0.6, 0.7, 0.8, 0.9, 1.0], \n",
        "        \"training_size\": [10000],  \n",
        "        \"testing_size\": [2000],  \n",
        "        \"p_to_be_zeroed\": [0.0],  \n",
        "        \"dropout_on_input_layer\": [False], \n",
        "    }\n",
        "eval_data = HyperTuner().tune(TestingConfig.CONFIG, False)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist_torch_data/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to mnist_torch_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5cff260761f94caa977d05bd2bdb6cd6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting mnist_torch_data/MNIST/raw/train-images-idx3-ubyte.gz to mnist_torch_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist_torch_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "225c9b73996f43fab7a866a67c1ff9f0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting mnist_torch_data/MNIST/raw/train-labels-idx1-ubyte.gz to mnist_torch_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist_torch_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to mnist_torch_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f8e0290036a47ee844271c83ac2d1fa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting mnist_torch_data/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist_torch_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to mnist_torch_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2479445cfb5e44fc9835e7690670f6a1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting mnist_torch_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist_torch_data/MNIST/raw\n",
            "\n",
            "Processing...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done!\n",
            "Total combinations for exp: 5\n",
            "Added record to eval DF. Total records so far: 1\n",
            "Added record to eval DF. Total records so far: 2\n",
            "Added record to eval DF. Total records so far: 3\n",
            "Added record to eval DF. Total records so far: 4\n",
            "Added record to eval DF. Total records so far: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "BKgc-qS1ccRe",
        "outputId": "398b5c27-6632-4ecf-b7fb-0295de76bfcc"
      },
      "source": [
        "eval_data"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>best_accuracy</th>\n",
              "      <th>avg_accuracy</th>\n",
              "      <th>avg_time_taken</th>\n",
              "      <th>size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>hidden_act_function</th>\n",
              "      <th>output_act_function</th>\n",
              "      <th>loss_func</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>momentum</th>\n",
              "      <th>testing_dataset_type</th>\n",
              "      <th>training_size</th>\n",
              "      <th>testing_size</th>\n",
              "      <th>p_to_be_zeroed</th>\n",
              "      <th>dropout_on_input_layer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>96.4</td>\n",
              "      <td>93.036667</td>\n",
              "      <td>123.200460</td>\n",
              "      <td>[784, 100, 100, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>96.2</td>\n",
              "      <td>89.003333</td>\n",
              "      <td>125.999803</td>\n",
              "      <td>[784, 100, 100, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>0.8</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>88.0</td>\n",
              "      <td>83.046667</td>\n",
              "      <td>122.066078</td>\n",
              "      <td>[784, 100, 100, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>0.7</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>95.6</td>\n",
              "      <td>82.066667</td>\n",
              "      <td>125.920994</td>\n",
              "      <td>[784, 100, 100, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>0.6</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11.3</td>\n",
              "      <td>10.166667</td>\n",
              "      <td>121.889036</td>\n",
              "      <td>[784, 100, 100, 10]</td>\n",
              "      <td>50</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>1.0</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   best_accuracy  avg_accuracy  ...  p_to_be_zeroed dropout_on_input_layer\n",
              "3           96.4     93.036667  ...             0.0                  False\n",
              "2           96.2     89.003333  ...             0.0                  False\n",
              "1           88.0     83.046667  ...             0.0                  False\n",
              "0           95.6     82.066667  ...             0.0                  False\n",
              "4           11.3     10.166667  ...             0.0                  False\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}