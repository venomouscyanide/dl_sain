{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week_5_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM4u4PtH/i/x1WCmvdrsIWI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a6b42cf3d781469ca4404c05612c7e3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1aab329261c941d7a29bcc0eb491b913",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a7bb34f412744506b012a80b87cd42b9",
              "IPY_MODEL_f4b554c0ce9f409abe886f7f50b0db7e"
            ]
          }
        },
        "1aab329261c941d7a29bcc0eb491b913": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a7bb34f412744506b012a80b87cd42b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_403a6bc6b0604330b31345e6a59ee3c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b01bf9ee3cf74b788f6328ac84426042"
          }
        },
        "f4b554c0ce9f409abe886f7f50b0db7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8cba9322bf82456aacc37afd5af1b2c6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [2:02:01&lt;00:00, 23288.98it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_19533e6853f04b4fbb5a964fcfc95fc3"
          }
        },
        "403a6bc6b0604330b31345e6a59ee3c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b01bf9ee3cf74b788f6328ac84426042": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8cba9322bf82456aacc37afd5af1b2c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "19533e6853f04b4fbb5a964fcfc95fc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4e9bf4861f2417e92648d12b9e95f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7ed9879a9c844876929fd9ad435d507e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2f713587305445d6a340cb1cb892b2d2",
              "IPY_MODEL_0d1dab47c60547da9f1cc4bfcbc94dab"
            ]
          }
        },
        "7ed9879a9c844876929fd9ad435d507e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f713587305445d6a340cb1cb892b2d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f8895d34319e446ea16f48c6fc1c16bd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_27141384478a48599ee16450a5aebea2"
          }
        },
        "0d1dab47c60547da9f1cc4bfcbc94dab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_31f7b0429ce1466b846cef64c6c81def",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [3:06:59&lt;00:00, 15196.87it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9ad583b38464c26935e968bbcc458b6"
          }
        },
        "f8895d34319e446ea16f48c6fc1c16bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "27141384478a48599ee16450a5aebea2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31f7b0429ce1466b846cef64c6c81def": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9ad583b38464c26935e968bbcc458b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7fcd5d3611e047f89ab526d5654d2df5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d4a69b1954ef4edaa2a5eef06c203866",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_73a21ba9f47d4843820626bacad1e099",
              "IPY_MODEL_539446b036404120bb9d917b09c734fc"
            ]
          }
        },
        "d4a69b1954ef4edaa2a5eef06c203866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73a21ba9f47d4843820626bacad1e099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e6ae83fda4e74be083c7107f7ea91763",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8bf7edaa4a748978fa3d4e560fd96d4"
          }
        },
        "539446b036404120bb9d917b09c734fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c8cbd5689f5b4d6cb582a55680844f96",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:11&lt;00:00, 14609027.15it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f63e9e511a144e4eb0f837834359933f"
          }
        },
        "e6ae83fda4e74be083c7107f7ea91763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8bf7edaa4a748978fa3d4e560fd96d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8cbd5689f5b4d6cb582a55680844f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f63e9e511a144e4eb0f837834359933f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "766dbaa71dcc4fb5ad10e8666cc33bcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e09481dd406440dcbb8013a2df87f24b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b1986ce8ab41486686c1db9637f2bdf9",
              "IPY_MODEL_574fa2e2c427415fa24a2e0e52c6a66a"
            ]
          }
        },
        "e09481dd406440dcbb8013a2df87f24b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b1986ce8ab41486686c1db9637f2bdf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_39746bde3c72407982f3c45df4ab573c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 169001437,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 169001437,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6d18f8a3cb21447a8c12f447f64b9928"
          }
        },
        "574fa2e2c427415fa24a2e0e52c6a66a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_84a4d44ec1674bca9631c3de2888a8af",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169001984/? [00:07&lt;00:00, 23865938.42it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3aeaa0c3a3f4e86b8b2d0a1042ca765"
          }
        },
        "39746bde3c72407982f3c45df4ab573c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6d18f8a3cb21447a8c12f447f64b9928": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84a4d44ec1674bca9631c3de2888a8af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3aeaa0c3a3f4e86b8b2d0a1042ca765": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "696fd21a8ac64ca1bef46f495476e766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2fb0f73d2afc43f9a78d28c137673bad",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a898220c0661475b923ab0ada603c8e2",
              "IPY_MODEL_4bea1562d3204a39bfc1644dbe9ba0f4"
            ]
          }
        },
        "2fb0f73d2afc43f9a78d28c137673bad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a898220c0661475b923ab0ada603c8e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1186dade88b645fc8b13a4d12c571176",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 169001437,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 169001437,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b0f994b4c0d140bea15c5248ed500343"
          }
        },
        "4bea1562d3204a39bfc1644dbe9ba0f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d405f2b340e14e89ad97573956f9d05c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169001984/? [20:49&lt;00:00, 135281.54it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5976811a85043d8aea1fce70732fb78"
          }
        },
        "1186dade88b645fc8b13a4d12c571176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b0f994b4c0d140bea15c5248ed500343": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d405f2b340e14e89ad97573956f9d05c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5976811a85043d8aea1fce70732fb78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venomouscyanide/dl_sain/blob/master/week5/week_5_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml4LnaJR1HuA"
      },
      "source": [
        "# Setup NN base + Hyper Tuning class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPBf2n9k1NqU"
      },
      "source": [
        "### All Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsB0pOEJU4_K"
      },
      "source": [
        "import itertools\n",
        "from typing import List, Dict, Type\n",
        "import copy\n",
        "import time\n",
        "from abc import abstractmethod\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST, CIFAR10, CIFAR100\n",
        "from torchvision.transforms import ToTensor, transforms\n",
        "from torch.utils.data.dataset import random_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjTrmu3cVWXh",
        "outputId": "b23c8113-12dd-44c8-b7f5-e81fa37334db"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')\n",
        "# TODO; reproducibility is only guarenteed on cpu.\n",
        "# For some reason, using cuda, each run produces different results regarless of me setting manual_seed().\n",
        "# However, reproducibility is consistent on cpu.\n",
        "# Time taken for experiments increases due to this"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cpu device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWJ7T82j1TTW"
      },
      "source": [
        "### Setup a factory that returns the dataloader for the Dataset that you want\n",
        "Using this I can conduct multiple experiments across CIFAR10, CIFAR100 and MNIST using the same `Module()` base class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ-Pg6cKVW1R"
      },
      "source": [
        "class DataLoaderWrapper:\n",
        "    @abstractmethod\n",
        "    def get_data(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_validation_splits(self) -> List[int]:\n",
        "        pass\n",
        "\n",
        "\n",
        "class GetDataLoaderFactory:\n",
        "    def get(self, dataset: str) -> Type[DataLoaderWrapper]:\n",
        "        if dataset == \"MNIST\":\n",
        "            return MNISTLoader\n",
        "        elif dataset == \"CIFAR10\":\n",
        "            return CIFAR10Loader\n",
        "        elif dataset == \"CIFAR100\":\n",
        "            return CIFAR100Loader\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Dataset {dataset} not configured\")\n",
        "\n",
        "\n",
        "class MNISTLoader(DataLoaderWrapper):\n",
        "    def get_data(self):\n",
        "        train_data = MNIST(root='mnist_torch_data', train=True, download=True, transform=ToTensor())\n",
        "        test_data = MNIST(root='mnist_torch_data', train=False, download=True, transform=ToTensor())\n",
        "        return train_data, test_data\n",
        "\n",
        "    def get_validation_splits(self) -> List[int]:\n",
        "        return [50000, 10000]\n",
        "\n",
        "\n",
        "cifar_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "\n",
        "class CIFAR10Loader(DataLoaderWrapper):\n",
        "    def get_data(self):\n",
        "        train_data = CIFAR10(root='cifar10', train=True, download=True, transform=cifar_transform)\n",
        "        test_data = CIFAR10(root='cifar10', train=False, download=True, transform=cifar_transform)\n",
        "        return train_data, test_data\n",
        "\n",
        "    def get_validation_splits(self) -> List[int]:\n",
        "        return [40000, 10000]\n",
        "\n",
        "\n",
        "class CIFAR100Loader(DataLoaderWrapper):\n",
        "    def get_data(self):\n",
        "        train_data = CIFAR100(root='cifar100', train=True, download=True, transform=cifar_transform)\n",
        "        test_data = CIFAR100(root='cifar100', train=False, download=True, transform=cifar_transform)\n",
        "        return train_data, test_data\n",
        "\n",
        "    def get_validation_splits(self) -> List[int]:\n",
        "        return [40000, 10000]\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDmIJO8d1izY"
      },
      "source": [
        "### Hypertuner & EvalData classes\n",
        "- `EvalData` holds the data obtained from each iteration inside a Dataframe\n",
        "- `HyperTuner` takes a catesian product of all combinations and adds a row to EvalData after 3 iterations on each combination(each iteration has a fixed random seed value). `Hypertuner` internally calls `TorchCNN` for training and evaluation on any given dataset\n",
        "\n",
        "Work here is highly inspired by work done by Isaac last week "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVj7nGysVyM1"
      },
      "source": [
        "class EvalData:\n",
        "    def __init__(self):\n",
        "        self.data = pd.DataFrame(\n",
        "            columns=[\"dataset\", \"epochs\", \"nn_stack\", \"loss_func\",\n",
        "                     \"optimizer\", \"learning_rate\", \"weight_decay\", \"batch_size\", \"momentum\",\n",
        "                     \"testing_dataset_type\", \"training_size\", \"testing_size\",\n",
        "                     \"best_accuracy\", \"avg_accuracy\",\n",
        "                     \"avg_time_taken\"])\n",
        "\n",
        "    def add_record(self, data_dict: Dict):\n",
        "        self.data = self.data.append(data_dict, ignore_index=True)\n",
        "        print(f\"Added record to eval DF. Total records so far: {self.data.shape[0]}\")\n",
        "\n",
        "    def get(self, rearrange: bool) -> pd.DataFrame:\n",
        "        if rearrange:\n",
        "            # push \"best_accuracy\", \"avg_accuracy\", \"avg_time_taken\" cols to the front and sort by \"avg_accuracy\"\n",
        "            curr_cols = self.data.columns.tolist()\n",
        "            updated_order = curr_cols[-3:] + curr_cols[:-3]\n",
        "            self.data = self.data[updated_order]\n",
        "        return self.data.sort_values(by=\"avg_accuracy\", ascending=False)\n",
        "\n",
        "\n",
        "class HyperTuner:\n",
        "    def tune(self, config: Dict, verbose: bool = True) -> pd.DataFrame:\n",
        "        eval_data = EvalData()\n",
        "\n",
        "        all_combinations = list(itertools.product(*config.values()))\n",
        "        print(f\"Total combinations for exp: {len(all_combinations)}\")\n",
        "        for combination in all_combinations:\n",
        "            # reconstruct the dict using the combination\n",
        "            combination_dict = {k: v for k, v in zip(config.keys(), combination)}\n",
        "\n",
        "            data_loader = GetDataLoaderFactory().get(combination_dict[\"dataset\"])()\n",
        "            train_data, test_data = data_loader.get_data()\n",
        "\n",
        "            accuracies = np.array([])\n",
        "            time_consumed = np.array([])\n",
        "\n",
        "            for seed in [28, 35, 42]:\n",
        "                batch_size = combination_dict[\"batch_size\"]\n",
        "                testing_dataset_type = combination_dict[\"testing_dataset_type\"]\n",
        "\n",
        "                training_subset = train_data\n",
        "                torch.manual_seed(seed)\n",
        "                training_loader = DataLoader(training_subset, batch_size=batch_size, shuffle=True)\n",
        "                testing_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "                if testing_dataset_type == \"validation\":\n",
        "                    splits = data_loader.get_validation_splits()\n",
        "                    training_subset, validation_subset = random_split(train_data, lengths=splits)\n",
        "                    validation_loader = DataLoader(validation_subset, batch_size=batch_size, shuffle=True)\n",
        "                    testing_loader = validation_loader if testing_dataset_type == \"validation\" else testing_loader\n",
        "\n",
        "                model = TorchCNN(\n",
        "                    loss_func=combination_dict[\"loss_func\"],\n",
        "                    optimizer=combination_dict[\"optimizer\"],\n",
        "                    learning_rate=combination_dict[\"learning_rate\"],\n",
        "                    lmda_wt_decay=combination_dict[\"weight_decay\"],\n",
        "                    batch_size=batch_size,\n",
        "                    momentum=combination_dict[\"momentum\"],\n",
        "                    training_size=combination_dict[\"training_size\"],\n",
        "                    testing_size=combination_dict[\"testing_size\"],\n",
        "                    seed=seed,\n",
        "                    nn_stack=combination_dict['nn_stack']\n",
        "                ).to(device)\n",
        "\n",
        "                num_epochs = combination_dict[\"epochs\"]\n",
        "                time_epoch_start = time.time()\n",
        "                for epoch in range(num_epochs):\n",
        "                    if verbose:\n",
        "                        print(f\"Training for epoch: {epoch}\")\n",
        "                    model.train_model(training_loader, verbose)\n",
        "                    accuracy = model.evaluate(testing_loader, model.testing_size, \"testing\", verbose)\n",
        "                    accuracies = np.append(accuracies, accuracy)\n",
        "                time_for_seed = time.time() - time_epoch_start\n",
        "                time_consumed = np.append(time_consumed, time_for_seed)\n",
        "\n",
        "                self._reset_params(model)\n",
        "\n",
        "            avg_time = np.mean(time_consumed)\n",
        "            avg_accuracy = np.mean(accuracies)\n",
        "            best_accuracy = np.max(accuracies)\n",
        "\n",
        "            combination_dict.update({\n",
        "                \"best_accuracy\": best_accuracy,\n",
        "                \"avg_accuracy\": avg_accuracy,\n",
        "                \"avg_time_taken\": avg_time\n",
        "            })\n",
        "\n",
        "            eval_data.add_record(combination_dict)\n",
        "\n",
        "            if verbose:\n",
        "                print(eval_data.get(rearrange=False))\n",
        "        return eval_data.get(rearrange=True)\n",
        "\n",
        "    def _reset_params(self, model: nn.Module):\n",
        "        for layer in list(model.children())[0]:\n",
        "            if hasattr(layer, 'reset_parameters'):\n",
        "                layer.reset_parameters()\n",
        "\n",
        "\n",
        "def _get_nn_stacks_with_dropouts(base_architectures, dropout_options):\n",
        "    archs_with_dropout = []\n",
        "    for base_architecture in base_architectures:\n",
        "        for dropout_option in dropout_options:\n",
        "            arch_copy = copy.deepcopy(base_architecture)\n",
        "            for index, module in enumerate(arch_copy):\n",
        "                if type(module) == nn.Dropout:\n",
        "                    arch_copy[index] = nn.Dropout(dropout_option)\n",
        "            archs_with_dropout += [arch_copy]\n",
        "    return archs_with_dropout"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o-GkVFU2XQ2"
      },
      "source": [
        "### The Neural Network Module which takes in different architectures and hyperparameters by argument\n",
        "This class gets called by `HyperTuner` on different values of hyperparameters, datasets and even architectures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V9yTKESV7z7"
      },
      "source": [
        "class TorchCNN(nn.Module):\n",
        "    def __init__(self, loss_func: str,\n",
        "                 optimizer: str, learning_rate: float, lmda_wt_decay: float, batch_size: int,\n",
        "                 momentum: float, nn_stack: List[nn.Module], training_size: int,\n",
        "                 testing_size: int, seed: int = 42):\n",
        "        super().__init__()\n",
        "        self.loss_func = loss_func\n",
        "        self.optimizer = optimizer\n",
        "        self.learning_rate = learning_rate\n",
        "        self.lmda_wt_decay = lmda_wt_decay\n",
        "        self.mlp = nn.Sequential(*nn_stack)\n",
        "        self.momentum = momentum\n",
        "        optimizer_params = self._get_optimizer_params()\n",
        "        self.optimizer = getattr(torch.optim, self.optimizer)(**optimizer_params)\n",
        "        self.loss_function = getattr(nn, self.loss_func)()\n",
        "        self.batch_size = batch_size\n",
        "        self.training_size = training_size\n",
        "        self.testing_size = testing_size\n",
        "        self.seed = seed\n",
        "\n",
        "    def _get_optimizer_params(self):\n",
        "        opt_params = {\n",
        "            \"params\": self.parameters(),\n",
        "            \"lr\": self.learning_rate,\n",
        "            \"weight_decay\": self.lmda_wt_decay,\n",
        "            \"momentum\": self.momentum,\n",
        "        }\n",
        "        return opt_params\n",
        "\n",
        "    def forward(self, data: torch.Tensor) -> torch.Tensor:\n",
        "        logits = self.mlp(data)\n",
        "        return logits\n",
        "\n",
        "    def train_model(self, training_loader: DataLoader, verbose: int = True):\n",
        "        torch.manual_seed(self.seed)\n",
        "        for input, labels in itertools.islice(training_loader, self.training_size // self.batch_size):\n",
        "            prediction = self(input.to(device))\n",
        "            labels = labels.to(device)\n",
        "            if self.loss_function._get_name() == 'MSELoss':\n",
        "                # TODO: This will not work for CIFAR100\n",
        "                labels = torch.nn.functional.one_hot(labels, 10).float()\n",
        "            loss = self.loss_function(prediction, labels)\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "        if verbose:\n",
        "            self.evaluate(training_loader, self.training_size, verbose=verbose)\n",
        "\n",
        "    def evaluate(self, data_loader: DataLoader, dataset_size: int, data_type: str = \"training\",\n",
        "                 verbose: bool = True) -> float:\n",
        "        correct_classifications = 0\n",
        "        with torch.no_grad():\n",
        "            torch.manual_seed(self.seed)\n",
        "            for input, labels in itertools.islice(data_loader, dataset_size // self.batch_size):\n",
        "                prediction = self(input.to(device))\n",
        "                labels = labels.to(device)\n",
        "                correct_classifications += (prediction.argmax(1) == labels).type(torch.float).sum().item()\n",
        "        numerator = int(correct_classifications)\n",
        "        denominator = dataset_size\n",
        "        accuracy = round((numerator / denominator) * 100, 2)\n",
        "        if verbose:\n",
        "            print(f'Accuracy on {data_type} data {accuracy}({numerator}/{denominator})%')\n",
        "        return accuracy"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16Ulbb_CXpco"
      },
      "source": [
        "# get rid of the UserWarning from being shown\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOYoMnsQhoke"
      },
      "source": [
        "# MNIST Tuning on CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuoUDTsh28Xd"
      },
      "source": [
        "Try out the hyperparameters from previous week which gave 98% accuracy on test data + introduce Conv2d and pooling layers.\n",
        "The archtecture for CNN is taken from Neilson's work in [chapter 6](http://neuralnetworksanddeeplearning.com/chap6.html#convolutional_neural_networks_in_practice)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "First try with different values of dropouts - [0.00, 0.10, 0.20, 0.30, 0.40, 0.50]\n",
        "<br><br>\n",
        "Note: all trials are on \"validation\" dataset and we only consume 10,000 training samples + 1,000 testing sample and lower number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncnaroARWBN6",
        "outputId": "55e6f872-2e72-4143-99d5-1336fe4c595a"
      },
      "source": [
        "class TestingConfig:\n",
        "    torch.manual_seed(35)\n",
        "    base_architectures = [[nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, stride=1),\n",
        "                            nn.ReLU(),\n",
        "                            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                            nn.Dropout(0.0),\n",
        "                            nn.Conv2d(in_channels=20, out_channels=40, kernel_size=5, stride=1),\n",
        "                            nn.ReLU(),\n",
        "                            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                            nn.Dropout(0.0),\n",
        "                            nn.Flatten(),\n",
        "                            nn.Linear(40 * 4 * 4, 40 * 4 * 4 * 2),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Dropout(0.0),\n",
        "                            nn.Linear(40 * 4 * 4 * 2, 10),\n",
        "                            nn.ReLU()]]\n",
        "    CONFIG = {\n",
        "        \"dataset\": [\"MNIST\"],\n",
        "        \"epochs\": [10],\n",
        "        \"nn_stack\": _get_nn_stacks_with_dropouts(base_architectures, dropout_options=[0.00, 0.10, 0.20, 0.30, 0.40, 0.50]),\n",
        "        \"loss_func\": [\"CrossEntropyLoss\"],\n",
        "        \"optimizer\": [\"SGD\"],\n",
        "        \"learning_rate\": [1e-2],\n",
        "        \"weight_decay\": [1e-4],\n",
        "        \"batch_size\": [10],\n",
        "        \"testing_dataset_type\": [\"validation\"],\n",
        "        \"training_size\": [10000],\n",
        "        \"testing_size\": [1000],\n",
        "        \"momentum\": [0.9]\n",
        "    }\n",
        "eval_data = HyperTuner().tune(TestingConfig.CONFIG, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total combinations for exp: 6\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 56.76(5676/10000)%\n",
            "Accuracy on testing data 56.4(564/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 57.63(5763/10000)%\n",
            "Accuracy on testing data 57.1(571/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 57.73(5773/10000)%\n",
            "Accuracy on testing data 57.7(577/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 68.76(6876/10000)%\n",
            "Accuracy on testing data 67.8(678/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 79.62(7962/10000)%\n",
            "Accuracy on testing data 79.5(795/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 79.78(7978/10000)%\n",
            "Accuracy on testing data 79.4(794/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 79.9(7990/10000)%\n",
            "Accuracy on testing data 79.9(799/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 79.93(7993/10000)%\n",
            "Accuracy on testing data 79.9(799/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 90.02(9002/10000)%\n",
            "Accuracy on testing data 89.5(895/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 90.19(9019/10000)%\n",
            "Accuracy on testing data 89.7(897/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 38.74(3874/10000)%\n",
            "Accuracy on testing data 37.5(375/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 38.95(3895/10000)%\n",
            "Accuracy on testing data 37.2(372/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 39.32(3932/10000)%\n",
            "Accuracy on testing data 37.7(377/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 39.23(3923/10000)%\n",
            "Accuracy on testing data 37.3(373/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 39.27(3927/10000)%\n",
            "Accuracy on testing data 38.1(381/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 39.58(3958/10000)%\n",
            "Accuracy on testing data 38.1(381/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 39.49(3949/10000)%\n",
            "Accuracy on testing data 37.9(379/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 39.53(3953/10000)%\n",
            "Accuracy on testing data 37.6(376/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 39.53(3953/10000)%\n",
            "Accuracy on testing data 38.0(380/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 39.7(3970/10000)%\n",
            "Accuracy on testing data 38.1(381/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 65.52(6552/10000)%\n",
            "Accuracy on testing data 64.5(645/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 66.25(6625/10000)%\n",
            "Accuracy on testing data 64.5(645/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 66.16(6616/10000)%\n",
            "Accuracy on testing data 64.7(647/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 66.67(6667/10000)%\n",
            "Accuracy on testing data 64.7(647/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 67.45(6745/10000)%\n",
            "Accuracy on testing data 65.9(659/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 67.84(6784/10000)%\n",
            "Accuracy on testing data 66.2(662/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 67.28(6728/10000)%\n",
            "Accuracy on testing data 65.6(656/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 67.7(6770/10000)%\n",
            "Accuracy on testing data 65.9(659/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 68.06(6806/10000)%\n",
            "Accuracy on testing data 66.6(666/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 68.12(6812/10000)%\n",
            "Accuracy on testing data 66.2(662/1000)%\n",
            "Added record to eval DF. Total records so far: 1\n",
            "  dataset epochs  ... avg_accuracy avg_time_taken\n",
            "0   MNIST     10  ...    58.973333     194.402864\n",
            "\n",
            "[1 rows x 15 columns]\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 9.59(959/10000)%\n",
            "Accuracy on testing data 10.8(108/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 9.59(959/10000)%\n",
            "Accuracy on testing data 10.8(108/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 9.59(959/10000)%\n",
            "Accuracy on testing data 10.8(108/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 9.59(959/10000)%\n",
            "Accuracy on testing data 10.8(108/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 9.59(959/10000)%\n",
            "Accuracy on testing data 10.8(108/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 9.59(959/10000)%\n",
            "Accuracy on testing data 10.8(108/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 9.59(959/10000)%\n",
            "Accuracy on testing data 10.8(108/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 9.59(959/10000)%\n",
            "Accuracy on testing data 10.8(108/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 9.59(959/10000)%\n",
            "Accuracy on testing data 10.8(108/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 9.59(959/10000)%\n",
            "Accuracy on testing data 10.8(108/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 87.0(8700/10000)%\n",
            "Accuracy on testing data 85.2(852/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 88.12(8812/10000)%\n",
            "Accuracy on testing data 86.4(864/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 98.6(9860/10000)%\n",
            "Accuracy on testing data 96.3(963/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 98.68(9868/10000)%\n",
            "Accuracy on testing data 97.1(971/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 99.02(9902/10000)%\n",
            "Accuracy on testing data 95.9(959/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 99.68(9968/10000)%\n",
            "Accuracy on testing data 97.4(974/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 99.57(9957/10000)%\n",
            "Accuracy on testing data 97.1(971/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 98.45(9845/10000)%\n",
            "Accuracy on testing data 95.9(959/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 99.71(9971/10000)%\n",
            "Accuracy on testing data 97.5(975/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 99.71(9971/10000)%\n",
            "Accuracy on testing data 97.8(978/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 65.48(6548/10000)%\n",
            "Accuracy on testing data 63.3(633/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 75.07(7507/10000)%\n",
            "Accuracy on testing data 72.6(726/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 78.38(7838/10000)%\n",
            "Accuracy on testing data 74.8(748/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 78.56(7856/10000)%\n",
            "Accuracy on testing data 74.3(743/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 78.83(7883/10000)%\n",
            "Accuracy on testing data 75.3(753/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 79.06(7906/10000)%\n",
            "Accuracy on testing data 74.7(747/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 79.12(7912/10000)%\n",
            "Accuracy on testing data 75.2(752/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 79.09(7909/10000)%\n",
            "Accuracy on testing data 75.2(752/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 79.21(7921/10000)%\n",
            "Accuracy on testing data 75.2(752/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 79.22(7922/10000)%\n",
            "Accuracy on testing data 75.3(753/1000)%\n",
            "Added record to eval DF. Total records so far: 2\n",
            "  dataset epochs  ... avg_accuracy avg_time_taken\n",
            "1   MNIST     10  ...    59.683333     201.010889\n",
            "0   MNIST     10  ...    58.973333     194.402864\n",
            "\n",
            "[2 rows x 15 columns]\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 66.16(6616/10000)%\n",
            "Accuracy on testing data 65.0(650/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 76.64(7664/10000)%\n",
            "Accuracy on testing data 74.1(741/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 77.33(7733/10000)%\n",
            "Accuracy on testing data 73.7(737/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 77.49(7749/10000)%\n",
            "Accuracy on testing data 73.2(732/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 77.77(7777/10000)%\n",
            "Accuracy on testing data 75.1(751/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 78.4(7840/10000)%\n",
            "Accuracy on testing data 75.0(750/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 78.25(7825/10000)%\n",
            "Accuracy on testing data 74.3(743/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 78.32(7832/10000)%\n",
            "Accuracy on testing data 74.8(748/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 78.34(7834/10000)%\n",
            "Accuracy on testing data 74.6(746/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 78.39(7839/10000)%\n",
            "Accuracy on testing data 75.2(752/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 86.83(8683/10000)%\n",
            "Accuracy on testing data 85.4(854/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 87.96(8796/10000)%\n",
            "Accuracy on testing data 86.9(869/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 88.6(8860/10000)%\n",
            "Accuracy on testing data 86.5(865/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 88.8(8880/10000)%\n",
            "Accuracy on testing data 87.0(870/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 88.8(8880/10000)%\n",
            "Accuracy on testing data 86.1(861/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 99.08(9908/10000)%\n",
            "Accuracy on testing data 96.6(966/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 99.34(9934/10000)%\n",
            "Accuracy on testing data 96.7(967/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 98.86(9886/10000)%\n",
            "Accuracy on testing data 95.4(954/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 99.88(9988/10000)%\n",
            "Accuracy on testing data 97.7(977/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 99.74(9974/10000)%\n",
            "Accuracy on testing data 97.1(971/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 86.15(8615/10000)%\n",
            "Accuracy on testing data 83.3(833/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 87.62(8762/10000)%\n",
            "Accuracy on testing data 84.3(843/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 87.68(8768/10000)%\n",
            "Accuracy on testing data 82.9(829/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 89.24(8924/10000)%\n",
            "Accuracy on testing data 85.5(855/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 88.91(8891/10000)%\n",
            "Accuracy on testing data 84.9(849/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 89.19(8919/10000)%\n",
            "Accuracy on testing data 84.9(849/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 88.75(8875/10000)%\n",
            "Accuracy on testing data 83.7(837/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 89.27(8927/10000)%\n",
            "Accuracy on testing data 85.0(850/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 89.38(8938/10000)%\n",
            "Accuracy on testing data 84.8(848/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 89.62(8962/10000)%\n",
            "Accuracy on testing data 85.6(856/1000)%\n",
            "Added record to eval DF. Total records so far: 3\n",
            "  dataset epochs  ... avg_accuracy avg_time_taken\n",
            "2   MNIST     10  ...    83.176667     211.172637\n",
            "1   MNIST     10  ...    59.683333     201.010889\n",
            "0   MNIST     10  ...    58.973333     194.402864\n",
            "\n",
            "[3 rows x 15 columns]\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 64.17(6417/10000)%\n",
            "Accuracy on testing data 63.1(631/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 77.16(7716/10000)%\n",
            "Accuracy on testing data 74.7(747/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 97.64(9764/10000)%\n",
            "Accuracy on testing data 94.1(941/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 99.04(9904/10000)%\n",
            "Accuracy on testing data 94.1(941/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 99.57(9957/10000)%\n",
            "Accuracy on testing data 95.6(956/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 99.24(9924/10000)%\n",
            "Accuracy on testing data 95.4(954/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 99.83(9983/10000)%\n",
            "Accuracy on testing data 96.4(964/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 99.5(9950/10000)%\n",
            "Accuracy on testing data 95.4(954/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 98.95(9895/10000)%\n",
            "Accuracy on testing data 95.1(951/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 99.14(9914/10000)%\n",
            "Accuracy on testing data 95.1(951/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 67.86(6786/10000)%\n",
            "Accuracy on testing data 65.8(658/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 88.86(8886/10000)%\n",
            "Accuracy on testing data 86.9(869/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 89.41(8941/10000)%\n",
            "Accuracy on testing data 86.7(867/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 89.65(8965/10000)%\n",
            "Accuracy on testing data 86.2(862/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 89.8(8980/10000)%\n",
            "Accuracy on testing data 87.1(871/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 89.92(8992/10000)%\n",
            "Accuracy on testing data 86.7(867/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 88.66(8866/10000)%\n",
            "Accuracy on testing data 84.5(845/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 89.25(8925/10000)%\n",
            "Accuracy on testing data 86.0(860/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 89.84(8984/10000)%\n",
            "Accuracy on testing data 87.0(870/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 89.8(8980/10000)%\n",
            "Accuracy on testing data 87.4(874/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 93.89(9389/10000)%\n",
            "Accuracy on testing data 90.3(903/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 98.25(9825/10000)%\n",
            "Accuracy on testing data 94.5(945/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 98.48(9848/10000)%\n",
            "Accuracy on testing data 94.4(944/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 99.09(9909/10000)%\n",
            "Accuracy on testing data 94.5(945/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 98.82(9882/10000)%\n",
            "Accuracy on testing data 94.6(946/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 99.08(9908/10000)%\n",
            "Accuracy on testing data 95.2(952/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 99.34(9934/10000)%\n",
            "Accuracy on testing data 95.0(950/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 98.32(9832/10000)%\n",
            "Accuracy on testing data 94.4(944/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 99.27(9927/10000)%\n",
            "Accuracy on testing data 94.5(945/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 98.38(9838/10000)%\n",
            "Accuracy on testing data 93.9(939/1000)%\n",
            "Added record to eval DF. Total records so far: 4\n",
            "  dataset epochs  ... avg_accuracy avg_time_taken\n",
            "3   MNIST     10  ...    89.486667     203.551767\n",
            "2   MNIST     10  ...    83.176667     211.172637\n",
            "1   MNIST     10  ...    59.683333     201.010889\n",
            "0   MNIST     10  ...    58.973333     194.402864\n",
            "\n",
            "[4 rows x 15 columns]\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 84.67(8467/10000)%\n",
            "Accuracy on testing data 80.4(804/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 97.4(9740/10000)%\n",
            "Accuracy on testing data 92.8(928/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 98.06(9806/10000)%\n",
            "Accuracy on testing data 92.4(924/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 98.36(9836/10000)%\n",
            "Accuracy on testing data 93.7(937/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 98.69(9869/10000)%\n",
            "Accuracy on testing data 93.9(939/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 98.72(9872/10000)%\n",
            "Accuracy on testing data 93.3(933/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 98.76(9876/10000)%\n",
            "Accuracy on testing data 93.0(930/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 96.77(9677/10000)%\n",
            "Accuracy on testing data 91.6(916/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 90.79(9079/10000)%\n",
            "Accuracy on testing data 83.9(839/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 96.01(9601/10000)%\n",
            "Accuracy on testing data 89.3(893/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 96.58(9658/10000)%\n",
            "Accuracy on testing data 92.9(929/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 97.77(9777/10000)%\n",
            "Accuracy on testing data 92.9(929/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 95.74(9574/10000)%\n",
            "Accuracy on testing data 90.1(901/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 97.84(9784/10000)%\n",
            "Accuracy on testing data 92.5(925/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 96.72(9672/10000)%\n",
            "Accuracy on testing data 92.3(923/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 97.25(9725/10000)%\n",
            "Accuracy on testing data 93.3(933/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 95.82(9582/10000)%\n",
            "Accuracy on testing data 90.3(903/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 98.07(9807/10000)%\n",
            "Accuracy on testing data 92.9(929/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 97.07(9707/10000)%\n",
            "Accuracy on testing data 91.1(911/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 95.58(9558/10000)%\n",
            "Accuracy on testing data 88.9(889/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 78.08(7808/10000)%\n",
            "Accuracy on testing data 74.7(747/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 77.87(7787/10000)%\n",
            "Accuracy on testing data 73.4(734/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 79.51(7951/10000)%\n",
            "Accuracy on testing data 75.7(757/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 87.45(8745/10000)%\n",
            "Accuracy on testing data 82.0(820/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 89.01(8901/10000)%\n",
            "Accuracy on testing data 83.5(835/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 87.65(8765/10000)%\n",
            "Accuracy on testing data 81.7(817/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 88.17(8817/10000)%\n",
            "Accuracy on testing data 81.1(811/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 87.84(8784/10000)%\n",
            "Accuracy on testing data 81.7(817/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 87.77(8777/10000)%\n",
            "Accuracy on testing data 82.0(820/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 79.32(7932/10000)%\n",
            "Accuracy on testing data 74.7(747/1000)%\n",
            "Added record to eval DF. Total records so far: 5\n",
            "  dataset epochs  ... avg_accuracy avg_time_taken\n",
            "3   MNIST     10  ...    89.486667     203.551767\n",
            "4   MNIST     10  ...    87.066667     198.729376\n",
            "2   MNIST     10  ...    83.176667     211.172637\n",
            "1   MNIST     10  ...    59.683333     201.010889\n",
            "0   MNIST     10  ...    58.973333     194.402864\n",
            "\n",
            "[5 rows x 15 columns]\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 83.23(8323/10000)%\n",
            "Accuracy on testing data 80.0(800/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 85.18(8518/10000)%\n",
            "Accuracy on testing data 80.1(801/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 87.98(8798/10000)%\n",
            "Accuracy on testing data 83.4(834/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 94.83(9483/10000)%\n",
            "Accuracy on testing data 87.4(874/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 91.46(9146/10000)%\n",
            "Accuracy on testing data 83.4(834/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 90.58(9058/10000)%\n",
            "Accuracy on testing data 82.7(827/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 40.86(4086/10000)%\n",
            "Accuracy on testing data 39.0(390/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 9.63(963/10000)%\n",
            "Accuracy on testing data 10.8(108/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 9.61(961/10000)%\n",
            "Accuracy on testing data 10.9(109/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 9.75(975/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 93.72(9372/10000)%\n",
            "Accuracy on testing data 88.9(889/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 94.69(9469/10000)%\n",
            "Accuracy on testing data 89.7(897/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 90.62(9062/10000)%\n",
            "Accuracy on testing data 84.4(844/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 86.68(8668/10000)%\n",
            "Accuracy on testing data 78.6(786/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 92.34(9234/10000)%\n",
            "Accuracy on testing data 85.9(859/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 96.17(9617/10000)%\n",
            "Accuracy on testing data 88.8(888/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 88.85(8885/10000)%\n",
            "Accuracy on testing data 81.8(818/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 92.73(9273/10000)%\n",
            "Accuracy on testing data 83.3(833/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 89.66(8966/10000)%\n",
            "Accuracy on testing data 81.4(814/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 80.07(8007/10000)%\n",
            "Accuracy on testing data 71.1(711/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 65.34(6534/10000)%\n",
            "Accuracy on testing data 61.7(617/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 93.16(9316/10000)%\n",
            "Accuracy on testing data 86.9(869/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 96.52(9652/10000)%\n",
            "Accuracy on testing data 89.1(891/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 88.23(8823/10000)%\n",
            "Accuracy on testing data 78.8(788/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 92.78(9278/10000)%\n",
            "Accuracy on testing data 83.5(835/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 92.07(9207/10000)%\n",
            "Accuracy on testing data 82.9(829/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 85.92(8592/10000)%\n",
            "Accuracy on testing data 76.8(768/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 77.99(7799/10000)%\n",
            "Accuracy on testing data 69.1(691/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 82.57(8257/10000)%\n",
            "Accuracy on testing data 73.0(730/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 61.76(6176/10000)%\n",
            "Accuracy on testing data 54.4(544/1000)%\n",
            "Added record to eval DF. Total records so far: 6\n",
            "  dataset epochs  ... avg_accuracy avg_time_taken\n",
            "3   MNIST     10  ...    89.486667     203.551767\n",
            "4   MNIST     10  ...    87.066667     198.729376\n",
            "2   MNIST     10  ...    83.176667     211.172637\n",
            "5   MNIST     10  ...    71.960000     198.976652\n",
            "1   MNIST     10  ...    59.683333     201.010889\n",
            "0   MNIST     10  ...    58.973333     194.402864\n",
            "\n",
            "[6 rows x 15 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "XH3mQ-iLWn2Q",
        "outputId": "0d2aae34-b3c8-4082-82c0-ebce9aae666a"
      },
      "source": [
        "eval_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>best_accuracy</th>\n",
              "      <th>avg_accuracy</th>\n",
              "      <th>avg_time_taken</th>\n",
              "      <th>dataset</th>\n",
              "      <th>epochs</th>\n",
              "      <th>nn_stack</th>\n",
              "      <th>loss_func</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>momentum</th>\n",
              "      <th>testing_dataset_type</th>\n",
              "      <th>training_size</th>\n",
              "      <th>testing_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>96.4</td>\n",
              "      <td>89.486667</td>\n",
              "      <td>203.551767</td>\n",
              "      <td>MNIST</td>\n",
              "      <td>10</td>\n",
              "      <td>[Conv2d(1, 20, kernel_size=(5, 5), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>93.9</td>\n",
              "      <td>87.066667</td>\n",
              "      <td>198.729376</td>\n",
              "      <td>MNIST</td>\n",
              "      <td>10</td>\n",
              "      <td>[Conv2d(1, 20, kernel_size=(5, 5), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>97.7</td>\n",
              "      <td>83.176667</td>\n",
              "      <td>211.172637</td>\n",
              "      <td>MNIST</td>\n",
              "      <td>10</td>\n",
              "      <td>[Conv2d(1, 20, kernel_size=(5, 5), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>89.7</td>\n",
              "      <td>71.960000</td>\n",
              "      <td>198.976652</td>\n",
              "      <td>MNIST</td>\n",
              "      <td>10</td>\n",
              "      <td>[Conv2d(1, 20, kernel_size=(5, 5), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>97.8</td>\n",
              "      <td>59.683333</td>\n",
              "      <td>201.010889</td>\n",
              "      <td>MNIST</td>\n",
              "      <td>10</td>\n",
              "      <td>[Conv2d(1, 20, kernel_size=(5, 5), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>89.7</td>\n",
              "      <td>58.973333</td>\n",
              "      <td>194.402864</td>\n",
              "      <td>MNIST</td>\n",
              "      <td>10</td>\n",
              "      <td>[Conv2d(1, 20, kernel_size=(5, 5), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   best_accuracy  avg_accuracy  ...  training_size testing_size\n",
              "3           96.4     89.486667  ...          10000         1000\n",
              "4           93.9     87.066667  ...          10000         1000\n",
              "2           97.7     83.176667  ...          10000         1000\n",
              "5           89.7     71.960000  ...          10000         1000\n",
              "1           97.8     59.683333  ...          10000         1000\n",
              "0           89.7     58.973333  ...          10000         1000\n",
              "\n",
              "[6 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcGdSf-6Wp1P",
        "outputId": "6d7daacf-c62d-4903-9f35-044f0cddd536"
      },
      "source": [
        "eval_data['nn_stack'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1)),\n",
              " ReLU(),\n",
              " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
              " Dropout(p=0.0, inplace=False),\n",
              " Conv2d(20, 40, kernel_size=(5, 5), stride=(1, 1)),\n",
              " ReLU(),\n",
              " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
              " Dropout(p=0.0, inplace=False),\n",
              " Flatten(start_dim=1, end_dim=-1),\n",
              " Linear(in_features=640, out_features=1280, bias=True),\n",
              " ReLU(),\n",
              " Dropout(p=0.0, inplace=False),\n",
              " Linear(in_features=1280, out_features=10, bias=True),\n",
              " ReLU()]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xC1imtBf4IGs"
      },
      "source": [
        "Dropout value of **0.20** performs best during the evaluation. \n",
        "\n",
        "---\n",
        "Next, Try out two different architectures\n",
        "- Same as before\n",
        "- Add more hidden neurons to the Linear layers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1IGKug3iZMk",
        "outputId": "cc9e1fcd-30d5-4697-a2f0-0d45178f994a"
      },
      "source": [
        "class TestingConfig:\n",
        "    torch.manual_seed(35)\n",
        "    base_architectures = [ # more hidden neurons\n",
        "                            [nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, stride=1),\n",
        "                            nn.ReLU(),\n",
        "                            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                            nn.Dropout(0.0),\n",
        "                            nn.Conv2d(in_channels=20, out_channels=40, kernel_size=5, stride=1),\n",
        "                            nn.ReLU(),\n",
        "                            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                            nn.Dropout(0.0),\n",
        "                            nn.Flatten(),\n",
        "                            nn.Linear(40 * 4 * 4, 40 * 4 * 4 * 20),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Dropout(0.0),\n",
        "                            nn.Linear(40 * 4 * 4 * 20, 10),\n",
        "                            nn.ReLU()],  \n",
        "                            # same config as above\n",
        "                            [nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, stride=1),\n",
        "                            nn.ReLU(),\n",
        "                            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                            nn.Dropout(0.0),\n",
        "                            nn.Conv2d(in_channels=20, out_channels=40, kernel_size=5, stride=1),\n",
        "                            nn.ReLU(),\n",
        "                            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                            nn.Dropout(0.0),\n",
        "                            nn.Flatten(),\n",
        "                            nn.Linear(40 * 4 * 4, 40 * 4 * 4 * 2),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Dropout(0.0),\n",
        "                            nn.Linear(40 * 4 * 4 * 2, 10),\n",
        "                            nn.ReLU()],\n",
        "                            ]\n",
        "    CONFIG = {\n",
        "    \"dataset\": [\"MNIST\"],\n",
        "    \"epochs\": [10],\n",
        "    \"nn_stack\": _get_nn_stacks_with_dropouts(base_architectures, dropout_options=[0.20]),\n",
        "    \"loss_func\": [\"CrossEntropyLoss\"],\n",
        "    \"optimizer\": [\"SGD\"],\n",
        "    \"learning_rate\": [1e-2],\n",
        "    \"weight_decay\": [1e-4],\n",
        "    \"batch_size\": [10],\n",
        "    \"testing_dataset_type\": [\"validation\"],\n",
        "    \"training_size\": [10000],\n",
        "    \"testing_size\": [1000],\n",
        "    \"momentum\": [0.9]\n",
        "    }\n",
        "eval_data = HyperTuner().tune(TestingConfig.CONFIG, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total combinations for exp: 2\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 59.62(5962/10000)%\n",
            "Accuracy on testing data 58.4(584/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 68.9(6890/10000)%\n",
            "Accuracy on testing data 66.0(660/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 69.64(6964/10000)%\n",
            "Accuracy on testing data 66.6(666/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 69.89(6989/10000)%\n",
            "Accuracy on testing data 66.3(663/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 69.71(6971/10000)%\n",
            "Accuracy on testing data 66.4(664/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 70.05(7005/10000)%\n",
            "Accuracy on testing data 67.0(670/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 69.08(6908/10000)%\n",
            "Accuracy on testing data 65.7(657/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 69.34(6934/10000)%\n",
            "Accuracy on testing data 66.1(661/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 70.03(7003/10000)%\n",
            "Accuracy on testing data 66.3(663/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 69.93(6993/10000)%\n",
            "Accuracy on testing data 66.5(665/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 19.81(1981/10000)%\n",
            "Accuracy on testing data 18.9(189/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 29.21(2921/10000)%\n",
            "Accuracy on testing data 25.4(254/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 29.52(2952/10000)%\n",
            "Accuracy on testing data 25.7(257/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 29.57(2957/10000)%\n",
            "Accuracy on testing data 26.1(261/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 29.65(2965/10000)%\n",
            "Accuracy on testing data 26.0(260/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 29.72(2972/10000)%\n",
            "Accuracy on testing data 26.3(263/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 29.73(2973/10000)%\n",
            "Accuracy on testing data 26.3(263/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 29.73(2973/10000)%\n",
            "Accuracy on testing data 25.9(259/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 29.79(2979/10000)%\n",
            "Accuracy on testing data 26.3(263/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 29.77(2977/10000)%\n",
            "Accuracy on testing data 26.1(261/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 28.5(2850/10000)%\n",
            "Accuracy on testing data 27.0(270/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 28.89(2889/10000)%\n",
            "Accuracy on testing data 27.9(279/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 29.02(2902/10000)%\n",
            "Accuracy on testing data 28.0(280/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 29.01(2901/10000)%\n",
            "Accuracy on testing data 27.8(278/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 29.16(2916/10000)%\n",
            "Accuracy on testing data 28.2(282/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 29.15(2915/10000)%\n",
            "Accuracy on testing data 28.1(281/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 29.22(2922/10000)%\n",
            "Accuracy on testing data 28.4(284/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 29.22(2922/10000)%\n",
            "Accuracy on testing data 28.4(284/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 29.24(2924/10000)%\n",
            "Accuracy on testing data 28.3(283/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 29.24(2924/10000)%\n",
            "Accuracy on testing data 28.2(282/1000)%\n",
            "Added record to eval DF. Total records so far: 1\n",
            "  dataset epochs  ... avg_accuracy avg_time_taken\n",
            "0   MNIST     10  ...        39.62     970.561377\n",
            "\n",
            "[1 rows x 15 columns]\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 59.41(5941/10000)%\n",
            "Accuracy on testing data 57.6(576/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 60.13(6013/10000)%\n",
            "Accuracy on testing data 58.0(580/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 60.46(6046/10000)%\n",
            "Accuracy on testing data 58.4(584/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 60.48(6048/10000)%\n",
            "Accuracy on testing data 58.6(586/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 60.51(6051/10000)%\n",
            "Accuracy on testing data 58.8(588/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 60.45(6045/10000)%\n",
            "Accuracy on testing data 58.8(588/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 60.54(6054/10000)%\n",
            "Accuracy on testing data 58.8(588/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 60.57(6057/10000)%\n",
            "Accuracy on testing data 58.9(589/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 60.58(6058/10000)%\n",
            "Accuracy on testing data 58.7(587/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 60.58(6058/10000)%\n",
            "Accuracy on testing data 58.5(585/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 86.83(8683/10000)%\n",
            "Accuracy on testing data 85.4(854/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 87.96(8796/10000)%\n",
            "Accuracy on testing data 86.9(869/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 88.6(8860/10000)%\n",
            "Accuracy on testing data 86.5(865/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 88.8(8880/10000)%\n",
            "Accuracy on testing data 87.0(870/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 88.8(8880/10000)%\n",
            "Accuracy on testing data 86.1(861/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 99.08(9908/10000)%\n",
            "Accuracy on testing data 96.6(966/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 99.34(9934/10000)%\n",
            "Accuracy on testing data 96.7(967/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 98.86(9886/10000)%\n",
            "Accuracy on testing data 95.4(954/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 99.88(9988/10000)%\n",
            "Accuracy on testing data 97.7(977/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 99.74(9974/10000)%\n",
            "Accuracy on testing data 97.1(971/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 86.15(8615/10000)%\n",
            "Accuracy on testing data 83.3(833/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 87.62(8762/10000)%\n",
            "Accuracy on testing data 84.3(843/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 87.68(8768/10000)%\n",
            "Accuracy on testing data 82.9(829/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 89.24(8924/10000)%\n",
            "Accuracy on testing data 85.5(855/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 88.91(8891/10000)%\n",
            "Accuracy on testing data 84.9(849/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 89.19(8919/10000)%\n",
            "Accuracy on testing data 84.9(849/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 88.75(8875/10000)%\n",
            "Accuracy on testing data 83.7(837/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 89.27(8927/10000)%\n",
            "Accuracy on testing data 85.0(850/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 89.38(8938/10000)%\n",
            "Accuracy on testing data 84.8(848/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 89.62(8962/10000)%\n",
            "Accuracy on testing data 85.6(856/1000)%\n",
            "Added record to eval DF. Total records so far: 2\n",
            "  dataset epochs  ... avg_accuracy avg_time_taken\n",
            "1   MNIST     10  ...        78.18     206.669593\n",
            "0   MNIST     10  ...        39.62     970.561377\n",
            "\n",
            "[2 rows x 15 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "CC9n_xRHpbbE",
        "outputId": "adac6db4-fb33-4644-b45d-1ab7fc56bb9c"
      },
      "source": [
        "eval_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>best_accuracy</th>\n",
              "      <th>avg_accuracy</th>\n",
              "      <th>avg_time_taken</th>\n",
              "      <th>dataset</th>\n",
              "      <th>epochs</th>\n",
              "      <th>nn_stack</th>\n",
              "      <th>loss_func</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>momentum</th>\n",
              "      <th>testing_dataset_type</th>\n",
              "      <th>training_size</th>\n",
              "      <th>testing_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>97.7</td>\n",
              "      <td>78.18</td>\n",
              "      <td>206.669593</td>\n",
              "      <td>MNIST</td>\n",
              "      <td>10</td>\n",
              "      <td>[Conv2d(1, 20, kernel_size=(5, 5), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>67.0</td>\n",
              "      <td>39.62</td>\n",
              "      <td>970.561377</td>\n",
              "      <td>MNIST</td>\n",
              "      <td>10</td>\n",
              "      <td>[Conv2d(1, 20, kernel_size=(5, 5), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   best_accuracy  avg_accuracy  ...  training_size testing_size\n",
              "1           97.7         78.18  ...          10000         1000\n",
              "0           67.0         39.62  ...          10000         1000\n",
              "\n",
              "[2 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNZwPFm64e0k"
      },
      "source": [
        "Initial architecture performs better.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Full Run on 60, 00 training samples and 10,000 testing samples for best observed architecture and hyperparameters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LQg68i3dqbg",
        "outputId": "d6163355-d606-4505-95e1-2b4699861b16"
      },
      "source": [
        "model = TorchCNN(\n",
        "    loss_func=\"CrossEntropyLoss\",\n",
        "    optimizer=\"SGD\",\n",
        "    learning_rate=1e-2,\n",
        "    lmda_wt_decay=1e-4,\n",
        "    batch_size=10,\n",
        "    training_size=60000,\n",
        "    testing_size=10000,\n",
        "    seed=35,\n",
        "    momentum=0.9,\n",
        "    nn_stack=[nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, stride=1),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                nn.Dropout(0.20),\n",
        "                nn.Conv2d(in_channels=20, out_channels=40, kernel_size=5, stride=1),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                nn.Dropout(0.20),\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(40 * 4 * 4, 40 * 4 * 4 * 2),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(0.20),\n",
        "                nn.Linear(40 * 4 * 4 * 2, 10),\n",
        "                nn.ReLU()]\n",
        ").to(device)\n",
        "train_data = MNIST(root='mnist_torch_data', train=True, download=True, transform=ToTensor())\n",
        "test_data = MNIST(root='mnist_torch_data', train=False, download=True, transform=ToTensor())\n",
        "torch.manual_seed(35)\n",
        "training_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
        "testing_loader = DataLoader(test_data, batch_size=10, shuffle=True)\n",
        "accuracies = []\n",
        "for epoch in range(20):\n",
        "    print(f\"Training for epoch: {epoch}\")\n",
        "    model.train_model(training_loader)\n",
        "    accuracies.append(model.evaluate(testing_loader, model.testing_size, \"testing\"))\n",
        "print(max(accuracies))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for epoch: 0\n",
            "Accuracy on training data 98.52(59109/60000)%\n",
            "Accuracy on testing data 97.92(9792/10000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 99.11(59464/60000)%\n",
            "Accuracy on testing data 98.19(9819/10000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 98.88(59330/60000)%\n",
            "Accuracy on testing data 97.84(9784/10000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 99.64(59787/60000)%\n",
            "Accuracy on testing data 98.55(9855/10000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 99.39(59634/60000)%\n",
            "Accuracy on testing data 98.24(9824/10000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 99.68(59810/60000)%\n",
            "Accuracy on testing data 98.58(9858/10000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 99.83(59900/60000)%\n",
            "Accuracy on testing data 98.59(9859/10000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 99.78(59868/60000)%\n",
            "Accuracy on testing data 98.51(9851/10000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 99.88(59928/60000)%\n",
            "Accuracy on testing data 98.73(9873/10000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 99.46(59677/60000)%\n",
            "Accuracy on testing data 98.27(9827/10000)%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 99.84(59904/60000)%\n",
            "Accuracy on testing data 98.76(9876/10000)%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 99.81(59884/60000)%\n",
            "Accuracy on testing data 98.71(9871/10000)%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 99.95(59971/60000)%\n",
            "Accuracy on testing data 98.97(9897/10000)%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 99.77(59864/60000)%\n",
            "Accuracy on testing data 98.43(9843/10000)%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 100.0(59997/60000)%\n",
            "Accuracy on testing data 98.95(9895/10000)%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 100.0(59999/60000)%\n",
            "Accuracy on testing data 98.98(9898/10000)%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 100.0(59999/60000)%\n",
            "Accuracy on testing data 99.0(9900/10000)%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 100.0(59999/60000)%\n",
            "Accuracy on testing data 98.99(9899/10000)%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 100.0(59999/60000)%\n",
            "Accuracy on testing data 98.96(9896/10000)%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 100.0(59999/60000)%\n",
            "Accuracy on testing data 98.9(9890/10000)%\n",
            "99.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD8ibCChTVam"
      },
      "source": [
        "Observe Peak accuracy of **99.0%** on MNIST testing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI61-GHqRjZQ"
      },
      "source": [
        "# CIFAR10 Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLJElmGD4_vt"
      },
      "source": [
        "Start tuning using the same layers as MNIST with two different dropout values `[0.00, 0.10]`\n",
        "\n",
        "---\n",
        "\n",
        "Note: all trials are on \"validation\" dataset and we only consume 10,000 training samples + 1,000 testing sample and lower number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a6b42cf3d781469ca4404c05612c7e3e",
            "1aab329261c941d7a29bcc0eb491b913",
            "a7bb34f412744506b012a80b87cd42b9",
            "f4b554c0ce9f409abe886f7f50b0db7e",
            "403a6bc6b0604330b31345e6a59ee3c1",
            "b01bf9ee3cf74b788f6328ac84426042",
            "8cba9322bf82456aacc37afd5af1b2c6",
            "19533e6853f04b4fbb5a964fcfc95fc3"
          ]
        },
        "id": "UzW3f4ARRlSu",
        "outputId": "681abf4d-d97d-4b79-e9c8-b6f1c576417d"
      },
      "source": [
        "class TestingConfig:\n",
        "    torch.manual_seed(21)\n",
        "    base_architectures = [[nn.Conv2d(in_channels=3, out_channels=20, kernel_size=5, stride=1),\n",
        "                            nn.ReLU(),\n",
        "                            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                            nn.Dropout(0.0),\n",
        "                            nn.Conv2d(in_channels=20, out_channels=40, kernel_size=5, stride=1),\n",
        "                            nn.ReLU(),\n",
        "                            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                            nn.Dropout(0.0),\n",
        "                            nn.Flatten(),\n",
        "                            nn.Linear(40 * 5 * 5, 40 * 5 * 5 * 5),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Dropout(0.0),\n",
        "                            nn.Linear(40 * 5 * 5 * 5, 10),\n",
        "                            nn.ReLU()]]\n",
        "    CONFIG = {\n",
        "        \"dataset\": [\"CIFAR10\"],\n",
        "        \"epochs\": [20],\n",
        "        \"nn_stack\": _get_nn_stacks_with_dropouts(base_architectures, dropout_options=[0.0, 0.10]),\n",
        "        \"loss_func\": [\"CrossEntropyLoss\"],\n",
        "        \"optimizer\": [\"SGD\"],\n",
        "        \"learning_rate\": [1e-2],\n",
        "        \"weight_decay\": [1e-4],\n",
        "        \"batch_size\": [10],\n",
        "        \"testing_dataset_type\": [\"validation\"],\n",
        "        \"training_size\": [10000],\n",
        "        \"testing_size\": [1000],\n",
        "        \"momentum\": [0.9]\n",
        "    }\n",
        "\n",
        "\n",
        "eval_data = HyperTuner().tune(TestingConfig.CONFIG, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total combinations for exp: 2\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to cifar10/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6b42cf3d781469ca4404c05612c7e3e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting cifar10/cifar-10-python.tar.gz to cifar10\n",
            "Files already downloaded and verified\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 15.91(1591/10000)%\n",
            "Accuracy on testing data 16.4(164/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 21.4(2140/10000)%\n",
            "Accuracy on testing data 22.9(229/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 29.73(2973/10000)%\n",
            "Accuracy on testing data 29.6(296/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 30.02(3002/10000)%\n",
            "Accuracy on testing data 28.5(285/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 43.34(4334/10000)%\n",
            "Accuracy on testing data 39.1(391/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 52.33(5233/10000)%\n",
            "Accuracy on testing data 44.9(449/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 65.77(6577/10000)%\n",
            "Accuracy on testing data 52.5(525/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 72.17(7217/10000)%\n",
            "Accuracy on testing data 54.5(545/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 69.82(6982/10000)%\n",
            "Accuracy on testing data 52.4(524/1000)%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 76.76(7676/10000)%\n",
            "Accuracy on testing data 54.7(547/1000)%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 74.61(7461/10000)%\n",
            "Accuracy on testing data 53.3(533/1000)%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 78.93(7893/10000)%\n",
            "Accuracy on testing data 53.9(539/1000)%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 76.64(7664/10000)%\n",
            "Accuracy on testing data 52.5(525/1000)%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 72.62(7262/10000)%\n",
            "Accuracy on testing data 53.0(530/1000)%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 78.14(7814/10000)%\n",
            "Accuracy on testing data 53.2(532/1000)%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 61.14(6114/10000)%\n",
            "Accuracy on testing data 41.0(410/1000)%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 70.53(7053/10000)%\n",
            "Accuracy on testing data 45.7(457/1000)%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 36.37(3637/10000)%\n",
            "Accuracy on testing data 25.9(259/1000)%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 19.62(1962/10000)%\n",
            "Accuracy on testing data 15.9(159/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 10.57(1057/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 10.57(1057/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 16.34(1634/10000)%\n",
            "Accuracy on testing data 16.9(169/1000)%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 18.43(1843/10000)%\n",
            "Accuracy on testing data 17.7(177/1000)%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 18.51(1851/10000)%\n",
            "Accuracy on testing data 17.4(174/1000)%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 24.19(2419/10000)%\n",
            "Accuracy on testing data 22.7(227/1000)%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 31.45(3145/10000)%\n",
            "Accuracy on testing data 30.3(303/1000)%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 40.69(4069/10000)%\n",
            "Accuracy on testing data 34.4(344/1000)%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 49.14(4914/10000)%\n",
            "Accuracy on testing data 39.3(393/1000)%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 65.04(6504/10000)%\n",
            "Accuracy on testing data 48.9(489/1000)%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 67.33(6733/10000)%\n",
            "Accuracy on testing data 47.6(476/1000)%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 68.82(6882/10000)%\n",
            "Accuracy on testing data 49.5(495/1000)%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 70.35(7035/10000)%\n",
            "Accuracy on testing data 50.8(508/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 24.37(2437/10000)%\n",
            "Accuracy on testing data 27.3(273/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 35.44(3544/10000)%\n",
            "Accuracy on testing data 36.3(363/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 49.79(4979/10000)%\n",
            "Accuracy on testing data 45.0(450/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 52.66(5266/10000)%\n",
            "Accuracy on testing data 45.9(459/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 64.67(6467/10000)%\n",
            "Accuracy on testing data 51.1(511/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 68.79(6879/10000)%\n",
            "Accuracy on testing data 51.4(514/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 59.28(5928/10000)%\n",
            "Accuracy on testing data 43.7(437/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 75.02(7502/10000)%\n",
            "Accuracy on testing data 49.9(499/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 75.7(7570/10000)%\n",
            "Accuracy on testing data 52.7(527/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 75.34(7534/10000)%\n",
            "Accuracy on testing data 50.7(507/1000)%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 70.54(7054/10000)%\n",
            "Accuracy on testing data 47.5(475/1000)%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 75.26(7526/10000)%\n",
            "Accuracy on testing data 50.3(503/1000)%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 79.0(7900/10000)%\n",
            "Accuracy on testing data 48.8(488/1000)%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 75.6(7560/10000)%\n",
            "Accuracy on testing data 47.4(474/1000)%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 52.78(5278/10000)%\n",
            "Accuracy on testing data 35.8(358/1000)%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 49.84(4984/10000)%\n",
            "Accuracy on testing data 31.1(311/1000)%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 10.17(1017/10000)%\n",
            "Accuracy on testing data 9.2(92/1000)%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 10.11(1011/10000)%\n",
            "Accuracy on testing data 9.3(93/1000)%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 10.79(1079/10000)%\n",
            "Accuracy on testing data 9.4(94/1000)%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 10.91(1091/10000)%\n",
            "Accuracy on testing data 9.1(91/1000)%\n",
            "Added record to eval DF. Total records so far: 1\n",
            "   dataset epochs  ... avg_accuracy avg_time_taken\n",
            "0  CIFAR10     20  ...    33.728333    1222.037093\n",
            "\n",
            "[1 rows x 15 columns]\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 16.0(1600/10000)%\n",
            "Accuracy on testing data 16.9(169/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 23.49(2349/10000)%\n",
            "Accuracy on testing data 22.8(228/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 30.24(3024/10000)%\n",
            "Accuracy on testing data 28.8(288/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 32.71(3271/10000)%\n",
            "Accuracy on testing data 30.3(303/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 34.89(3489/10000)%\n",
            "Accuracy on testing data 30.8(308/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 40.42(4042/10000)%\n",
            "Accuracy on testing data 33.6(336/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 45.4(4540/10000)%\n",
            "Accuracy on testing data 37.3(373/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 47.78(4778/10000)%\n",
            "Accuracy on testing data 38.8(388/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 49.22(4922/10000)%\n",
            "Accuracy on testing data 37.1(371/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 48.68(4868/10000)%\n",
            "Accuracy on testing data 36.4(364/1000)%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 56.72(5672/10000)%\n",
            "Accuracy on testing data 39.9(399/1000)%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 63.2(6320/10000)%\n",
            "Accuracy on testing data 43.9(439/1000)%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 61.07(6107/10000)%\n",
            "Accuracy on testing data 40.9(409/1000)%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 53.89(5389/10000)%\n",
            "Accuracy on testing data 35.5(355/1000)%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 52.02(5202/10000)%\n",
            "Accuracy on testing data 35.1(351/1000)%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 52.07(5207/10000)%\n",
            "Accuracy on testing data 34.0(340/1000)%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 48.58(4858/10000)%\n",
            "Accuracy on testing data 33.5(335/1000)%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 10.21(1021/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 46.96(4696/10000)%\n",
            "Accuracy on testing data 33.1(331/1000)%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 24.11(2411/10000)%\n",
            "Accuracy on testing data 20.1(201/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 15.35(1535/10000)%\n",
            "Accuracy on testing data 15.3(153/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 14.45(1445/10000)%\n",
            "Accuracy on testing data 13.2(132/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 14.24(1424/10000)%\n",
            "Accuracy on testing data 13.3(133/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 14.73(1473/10000)%\n",
            "Accuracy on testing data 13.9(139/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 13.3(1330/10000)%\n",
            "Accuracy on testing data 12.4(124/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 14.85(1485/10000)%\n",
            "Accuracy on testing data 14.4(144/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 14.41(1441/10000)%\n",
            "Accuracy on testing data 12.9(129/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 14.56(1456/10000)%\n",
            "Accuracy on testing data 13.6(136/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 15.6(1560/10000)%\n",
            "Accuracy on testing data 14.4(144/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 16.11(1611/10000)%\n",
            "Accuracy on testing data 14.7(147/1000)%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 16.31(1631/10000)%\n",
            "Accuracy on testing data 15.1(151/1000)%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 15.7(1570/10000)%\n",
            "Accuracy on testing data 14.5(145/1000)%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 15.87(1587/10000)%\n",
            "Accuracy on testing data 14.5(145/1000)%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 16.58(1658/10000)%\n",
            "Accuracy on testing data 14.2(142/1000)%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 18.25(1825/10000)%\n",
            "Accuracy on testing data 15.8(158/1000)%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 19.27(1927/10000)%\n",
            "Accuracy on testing data 17.0(170/1000)%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 25.87(2587/10000)%\n",
            "Accuracy on testing data 22.2(222/1000)%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 25.92(2592/10000)%\n",
            "Accuracy on testing data 20.0(200/1000)%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 32.84(3284/10000)%\n",
            "Accuracy on testing data 24.7(247/1000)%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 35.32(3532/10000)%\n",
            "Accuracy on testing data 26.9(269/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 14.59(1459/10000)%\n",
            "Accuracy on testing data 14.5(145/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 15.12(1512/10000)%\n",
            "Accuracy on testing data 15.0(150/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 14.58(1458/10000)%\n",
            "Accuracy on testing data 15.2(152/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 13.7(1370/10000)%\n",
            "Accuracy on testing data 13.6(136/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 17.54(1754/10000)%\n",
            "Accuracy on testing data 18.7(187/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 18.67(1867/10000)%\n",
            "Accuracy on testing data 20.2(202/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 17.86(1786/10000)%\n",
            "Accuracy on testing data 17.0(170/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 19.95(1995/10000)%\n",
            "Accuracy on testing data 19.2(192/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 18.68(1868/10000)%\n",
            "Accuracy on testing data 17.7(177/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 21.83(2183/10000)%\n",
            "Accuracy on testing data 18.5(185/1000)%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 22.67(2267/10000)%\n",
            "Accuracy on testing data 18.7(187/1000)%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 26.32(2632/10000)%\n",
            "Accuracy on testing data 23.0(230/1000)%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 29.17(2917/10000)%\n",
            "Accuracy on testing data 22.0(220/1000)%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 32.21(3221/10000)%\n",
            "Accuracy on testing data 23.4(234/1000)%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 43.79(4379/10000)%\n",
            "Accuracy on testing data 30.0(300/1000)%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 47.39(4739/10000)%\n",
            "Accuracy on testing data 33.3(333/1000)%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 54.72(5472/10000)%\n",
            "Accuracy on testing data 39.8(398/1000)%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 57.69(5769/10000)%\n",
            "Accuracy on testing data 35.3(353/1000)%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 61.05(6105/10000)%\n",
            "Accuracy on testing data 42.5(425/1000)%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 66.49(6649/10000)%\n",
            "Accuracy on testing data 46.2(462/1000)%\n",
            "Added record to eval DF. Total records so far: 2\n",
            "   dataset epochs  ... avg_accuracy avg_time_taken\n",
            "0  CIFAR10     20  ...    33.728333    1222.037093\n",
            "1  CIFAR10     20  ...    24.110000    1214.860022\n",
            "\n",
            "[2 rows x 15 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "SM-fHDTZg3T5",
        "outputId": "9e615607-b5f8-4374-9ed6-7726d262ef6e"
      },
      "source": [
        "eval_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>best_accuracy</th>\n",
              "      <th>avg_accuracy</th>\n",
              "      <th>avg_time_taken</th>\n",
              "      <th>dataset</th>\n",
              "      <th>epochs</th>\n",
              "      <th>nn_stack</th>\n",
              "      <th>loss_func</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>momentum</th>\n",
              "      <th>testing_dataset_type</th>\n",
              "      <th>training_size</th>\n",
              "      <th>testing_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>54.7</td>\n",
              "      <td>33.728333</td>\n",
              "      <td>1222.037093</td>\n",
              "      <td>CIFAR10</td>\n",
              "      <td>20</td>\n",
              "      <td>[Conv2d(3, 20, kernel_size=(5, 5), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>46.2</td>\n",
              "      <td>24.110000</td>\n",
              "      <td>1214.860022</td>\n",
              "      <td>CIFAR10</td>\n",
              "      <td>20</td>\n",
              "      <td>[Conv2d(3, 20, kernel_size=(5, 5), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   best_accuracy  avg_accuracy  ...  training_size testing_size\n",
              "0           54.7     33.728333  ...          10000         1000\n",
              "1           46.2     24.110000  ...          10000         1000\n",
              "\n",
              "[2 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgCATAsQ8ziX",
        "outputId": "af252881-5359-43ea-c094-2c9ae053c956"
      },
      "source": [
        "eval_data['nn_stack'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Conv2d(3, 20, kernel_size=(5, 5), stride=(1, 1)),\n",
              " ReLU(),\n",
              " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
              " Dropout(p=0.0, inplace=False),\n",
              " Conv2d(20, 40, kernel_size=(5, 5), stride=(1, 1)),\n",
              " ReLU(),\n",
              " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
              " Dropout(p=0.0, inplace=False),\n",
              " Flatten(start_dim=1, end_dim=-1),\n",
              " Linear(in_features=1000, out_features=5000, bias=True),\n",
              " ReLU(),\n",
              " Dropout(p=0.0, inplace=False),\n",
              " Linear(in_features=5000, out_features=10, bias=True),\n",
              " ReLU()]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djnSTky57HzM"
      },
      "source": [
        "No dropout works better as of now. Maybe because of lower epochs. <br>Try different learning rates; `[5, 1, 1e-1, 1e-2]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CYYIlC0BBjh",
        "outputId": "d6ba60c0-4385-47ff-fbe0-31745670d22f"
      },
      "source": [
        "class TestingConfig:\n",
        "    torch.manual_seed(21)\n",
        "    base_architectures = [[nn.Conv2d(in_channels=3, out_channels=20, kernel_size=5, stride=1),\n",
        "                            nn.ReLU(),\n",
        "                            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                            nn.Dropout(0.0),\n",
        "                            nn.Conv2d(in_channels=20, out_channels=40, kernel_size=5, stride=1),\n",
        "                            nn.ReLU(),\n",
        "                            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                            nn.Dropout(0.0),\n",
        "                            nn.Flatten(),\n",
        "                            nn.Linear(40 * 5 * 5, 40 * 5 * 5 * 2),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Dropout(0.0),\n",
        "                            nn.Linear(40 * 5 * 5 * 2, 10),\n",
        "                            nn.ReLU()]]\n",
        "    CONFIG = {\n",
        "        \"dataset\": [\"CIFAR10\"],\n",
        "        \"epochs\": [10],\n",
        "        \"nn_stack\": _get_nn_stacks_with_dropouts(base_architectures, dropout_options=[0.0]),\n",
        "        \"loss_func\": [\"CrossEntropyLoss\"],\n",
        "        \"optimizer\": [\"SGD\"],\n",
        "        \"learning_rate\": [5, 1, 1e-1, 1e-2],\n",
        "        \"weight_decay\": [1e-4],\n",
        "        \"batch_size\": [10],\n",
        "        \"testing_dataset_type\": [\"validation\"],\n",
        "        \"training_size\": [10000],\n",
        "        \"testing_size\": [1000],\n",
        "        \"momentum\": [0.9]\n",
        "    }\n",
        "\n",
        "\n",
        "eval_data = HyperTuner().tune(TestingConfig.CONFIG, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total combinations for exp: 4\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Added record to eval DF. Total records so far: 1\n",
            "   dataset epochs  ... avg_accuracy avg_time_taken\n",
            "0  CIFAR10     10  ...         10.2     360.559661\n",
            "\n",
            "[1 rows x 15 columns]\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Added record to eval DF. Total records so far: 2\n",
            "   dataset epochs  ... avg_accuracy avg_time_taken\n",
            "0  CIFAR10     10  ...         10.2     360.559661\n",
            "1  CIFAR10     10  ...         10.2     358.672987\n",
            "\n",
            "[2 rows x 15 columns]\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 10.12(1012/10000)%\n",
            "Accuracy on testing data 11.0(110/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 10.56(1056/10000)%\n",
            "Accuracy on testing data 10.6(106/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 9.87(987/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Added record to eval DF. Total records so far: 3\n",
            "   dataset epochs  ... avg_accuracy avg_time_taken\n",
            "0  CIFAR10     10  ...         10.2     360.559661\n",
            "1  CIFAR10     10  ...         10.2     358.672987\n",
            "2  CIFAR10     10  ...         10.2     357.240163\n",
            "\n",
            "[3 rows x 15 columns]\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 30.84(3084/10000)%\n",
            "Accuracy on testing data 31.8(318/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 40.38(4038/10000)%\n",
            "Accuracy on testing data 39.0(390/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 53.99(5399/10000)%\n",
            "Accuracy on testing data 51.3(513/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 58.68(5868/10000)%\n",
            "Accuracy on testing data 50.2(502/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 63.73(6373/10000)%\n",
            "Accuracy on testing data 50.2(502/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 61.83(6183/10000)%\n",
            "Accuracy on testing data 48.1(481/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 67.4(6740/10000)%\n",
            "Accuracy on testing data 50.3(503/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 73.45(7345/10000)%\n",
            "Accuracy on testing data 51.2(512/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 77.2(7720/10000)%\n",
            "Accuracy on testing data 53.5(535/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 75.2(7520/10000)%\n",
            "Accuracy on testing data 52.6(526/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 11.55(1155/10000)%\n",
            "Accuracy on testing data 11.3(113/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 21.36(2136/10000)%\n",
            "Accuracy on testing data 20.7(207/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 37.59(3759/10000)%\n",
            "Accuracy on testing data 36.6(366/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 45.83(4583/10000)%\n",
            "Accuracy on testing data 42.2(422/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 56.4(5640/10000)%\n",
            "Accuracy on testing data 48.3(483/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 60.91(6091/10000)%\n",
            "Accuracy on testing data 51.0(510/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 62.85(6285/10000)%\n",
            "Accuracy on testing data 51.1(511/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 62.79(6279/10000)%\n",
            "Accuracy on testing data 46.6(466/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 68.23(6823/10000)%\n",
            "Accuracy on testing data 50.0(500/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 67.82(6782/10000)%\n",
            "Accuracy on testing data 47.7(477/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 26.57(2657/10000)%\n",
            "Accuracy on testing data 27.8(278/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 45.37(4537/10000)%\n",
            "Accuracy on testing data 42.5(425/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 48.83(4883/10000)%\n",
            "Accuracy on testing data 43.6(436/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 56.76(5676/10000)%\n",
            "Accuracy on testing data 48.9(489/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 63.32(6332/10000)%\n",
            "Accuracy on testing data 50.0(500/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 62.06(6206/10000)%\n",
            "Accuracy on testing data 46.5(465/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 68.47(6847/10000)%\n",
            "Accuracy on testing data 52.1(521/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 71.02(7102/10000)%\n",
            "Accuracy on testing data 52.7(527/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 76.5(7650/10000)%\n",
            "Accuracy on testing data 52.5(525/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 73.09(7309/10000)%\n",
            "Accuracy on testing data 51.0(510/1000)%\n",
            "Added record to eval DF. Total records so far: 4\n",
            "   dataset epochs  ... avg_accuracy avg_time_taken\n",
            "3  CIFAR10     10  ...    45.043333     350.749481\n",
            "0  CIFAR10     10  ...    10.200000     360.559661\n",
            "1  CIFAR10     10  ...    10.200000     358.672987\n",
            "2  CIFAR10     10  ...    10.200000     357.240163\n",
            "\n",
            "[4 rows x 15 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "6MbIDDMEmlOb",
        "outputId": "509dc304-ca15-47eb-803e-30f41e056137"
      },
      "source": [
        "eval_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>best_accuracy</th>\n",
              "      <th>avg_accuracy</th>\n",
              "      <th>avg_time_taken</th>\n",
              "      <th>dataset</th>\n",
              "      <th>epochs</th>\n",
              "      <th>nn_stack</th>\n",
              "      <th>loss_func</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>momentum</th>\n",
              "      <th>testing_dataset_type</th>\n",
              "      <th>training_size</th>\n",
              "      <th>testing_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53.5</td>\n",
              "      <td>45.043333</td>\n",
              "      <td>350.749481</td>\n",
              "      <td>CIFAR10</td>\n",
              "      <td>10</td>\n",
              "      <td>[Conv2d(3, 20, kernel_size=(5, 5), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11.0</td>\n",
              "      <td>10.200000</td>\n",
              "      <td>360.559661</td>\n",
              "      <td>CIFAR10</td>\n",
              "      <td>10</td>\n",
              "      <td>[Conv2d(3, 20, kernel_size=(5, 5), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11.0</td>\n",
              "      <td>10.200000</td>\n",
              "      <td>358.672987</td>\n",
              "      <td>CIFAR10</td>\n",
              "      <td>10</td>\n",
              "      <td>[Conv2d(3, 20, kernel_size=(5, 5), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11.0</td>\n",
              "      <td>10.200000</td>\n",
              "      <td>357.240163</td>\n",
              "      <td>CIFAR10</td>\n",
              "      <td>10</td>\n",
              "      <td>[Conv2d(3, 20, kernel_size=(5, 5), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   best_accuracy  avg_accuracy  ...  training_size testing_size\n",
              "3           53.5     45.043333  ...          10000         1000\n",
              "0           11.0     10.200000  ...          10000         1000\n",
              "1           11.0     10.200000  ...          10000         1000\n",
              "2           11.0     10.200000  ...          10000         1000\n",
              "\n",
              "[4 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhx9W3bOmtwM",
        "outputId": "a3a34525-3807-4060-ee5e-74ef3c8ca226"
      },
      "source": [
        "eval_data['nn_stack'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Conv2d(3, 20, kernel_size=(5, 5), stride=(1, 1)),\n",
              " ReLU(),\n",
              " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
              " Dropout(p=0.0, inplace=False),\n",
              " Conv2d(20, 40, kernel_size=(5, 5), stride=(1, 1)),\n",
              " ReLU(),\n",
              " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
              " Dropout(p=0.0, inplace=False),\n",
              " Flatten(start_dim=1, end_dim=-1),\n",
              " Linear(in_features=1000, out_features=2000, bias=True),\n",
              " ReLU(),\n",
              " Dropout(p=0.0, inplace=False),\n",
              " Linear(in_features=2000, out_features=10, bias=True),\n",
              " ReLU()]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRamwyIp7U47"
      },
      "source": [
        "The lower, the better performance.\n",
        "Try more combinations with lower learning rates `[1e-3, 1e-4, 1e-5]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad2v39Exm51q",
        "outputId": "1364cc04-cd2a-49e0-b382-5269a9bd3bd6"
      },
      "source": [
        "class TestingConfig:\n",
        "    torch.manual_seed(21)\n",
        "    base_architectures = [[nn.Conv2d(in_channels=3, out_channels=20, kernel_size=5, stride=1),\n",
        "                            nn.ReLU(),\n",
        "                            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                            nn.Dropout(0.0),\n",
        "                            nn.Conv2d(in_channels=20, out_channels=40, kernel_size=5, stride=1),\n",
        "                            nn.ReLU(),\n",
        "                            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                            nn.Dropout(0.0),\n",
        "                            nn.Flatten(),\n",
        "                            nn.Linear(40 * 5 * 5, 40 * 5 * 5 * 2),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Dropout(0.0),\n",
        "                            nn.Linear(40 * 5 * 5 * 2, 10),\n",
        "                            nn.ReLU()]]\n",
        "    CONFIG = {\n",
        "        \"dataset\": [\"CIFAR10\"],\n",
        "        \"epochs\": [10],\n",
        "        \"nn_stack\": _get_nn_stacks_with_dropouts(base_architectures, dropout_options=[0.0]),\n",
        "        \"loss_func\": [\"CrossEntropyLoss\"],\n",
        "        \"optimizer\": [\"SGD\"],\n",
        "        \"learning_rate\": [1e-3, 1e-4, 1e-5],\n",
        "        \"weight_decay\": [1e-4],\n",
        "        \"batch_size\": [10],\n",
        "        \"testing_dataset_type\": [\"validation\"],\n",
        "        \"training_size\": [10000],\n",
        "        \"testing_size\": [1000],\n",
        "        \"momentum\": [0.9]\n",
        "    }\n",
        "\n",
        "\n",
        "eval_data = HyperTuner().tune(TestingConfig.CONFIG, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total combinations for exp: 3\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 23.95(2395/10000)%\n",
            "Accuracy on testing data 24.3(243/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 35.05(3505/10000)%\n",
            "Accuracy on testing data 34.6(346/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 45.03(4503/10000)%\n",
            "Accuracy on testing data 47.2(472/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 51.15(5115/10000)%\n",
            "Accuracy on testing data 52.5(525/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 55.21(5521/10000)%\n",
            "Accuracy on testing data 55.3(553/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 59.22(5922/10000)%\n",
            "Accuracy on testing data 58.1(581/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 62.71(6271/10000)%\n",
            "Accuracy on testing data 58.3(583/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 66.52(6652/10000)%\n",
            "Accuracy on testing data 59.5(595/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 70.09(7009/10000)%\n",
            "Accuracy on testing data 61.8(618/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 73.69(7369/10000)%\n",
            "Accuracy on testing data 62.1(621/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 23.6(2360/10000)%\n",
            "Accuracy on testing data 23.6(236/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 26.86(2686/10000)%\n",
            "Accuracy on testing data 27.0(270/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 29.23(2923/10000)%\n",
            "Accuracy on testing data 28.6(286/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 30.13(3013/10000)%\n",
            "Accuracy on testing data 30.3(303/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 33.55(3355/10000)%\n",
            "Accuracy on testing data 33.9(339/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 37.89(3789/10000)%\n",
            "Accuracy on testing data 37.1(371/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 39.73(3973/10000)%\n",
            "Accuracy on testing data 38.5(385/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 46.01(4601/10000)%\n",
            "Accuracy on testing data 44.4(444/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 48.29(4829/10000)%\n",
            "Accuracy on testing data 45.2(452/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 50.45(5045/10000)%\n",
            "Accuracy on testing data 45.9(459/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 32.86(3286/10000)%\n",
            "Accuracy on testing data 32.7(327/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 43.06(4306/10000)%\n",
            "Accuracy on testing data 42.5(425/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 49.07(4907/10000)%\n",
            "Accuracy on testing data 47.8(478/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 53.68(5368/10000)%\n",
            "Accuracy on testing data 50.8(508/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 57.39(5739/10000)%\n",
            "Accuracy on testing data 53.9(539/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 61.91(6191/10000)%\n",
            "Accuracy on testing data 55.0(550/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 66.39(6639/10000)%\n",
            "Accuracy on testing data 57.4(574/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 70.52(7052/10000)%\n",
            "Accuracy on testing data 59.2(592/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 74.39(7439/10000)%\n",
            "Accuracy on testing data 60.5(605/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 77.69(7769/10000)%\n",
            "Accuracy on testing data 61.3(613/1000)%\n",
            "Added record to eval DF. Total records so far: 1\n",
            "   dataset epochs  ... avg_accuracy avg_time_taken\n",
            "0  CIFAR10     10  ...        46.31     347.395857\n",
            "\n",
            "[1 rows x 15 columns]\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 16.47(1647/10000)%\n",
            "Accuracy on testing data 16.1(161/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 21.81(2181/10000)%\n",
            "Accuracy on testing data 23.5(235/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 24.07(2407/10000)%\n",
            "Accuracy on testing data 26.6(266/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 26.21(2621/10000)%\n",
            "Accuracy on testing data 29.0(290/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 27.66(2766/10000)%\n",
            "Accuracy on testing data 29.7(297/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 28.81(2881/10000)%\n",
            "Accuracy on testing data 30.8(308/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 29.89(2989/10000)%\n",
            "Accuracy on testing data 31.3(313/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 30.71(3071/10000)%\n",
            "Accuracy on testing data 32.6(326/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 31.7(3170/10000)%\n",
            "Accuracy on testing data 33.9(339/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 32.36(3236/10000)%\n",
            "Accuracy on testing data 35.0(350/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 14.95(1495/10000)%\n",
            "Accuracy on testing data 15.4(154/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 17.54(1754/10000)%\n",
            "Accuracy on testing data 18.5(185/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 18.94(1894/10000)%\n",
            "Accuracy on testing data 19.5(195/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 19.77(1977/10000)%\n",
            "Accuracy on testing data 20.8(208/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 21.43(2143/10000)%\n",
            "Accuracy on testing data 21.9(219/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 22.08(2208/10000)%\n",
            "Accuracy on testing data 22.4(224/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 22.8(2280/10000)%\n",
            "Accuracy on testing data 23.1(231/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 23.13(2313/10000)%\n",
            "Accuracy on testing data 23.4(234/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 23.62(2362/10000)%\n",
            "Accuracy on testing data 24.4(244/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 24.18(2418/10000)%\n",
            "Accuracy on testing data 25.2(252/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 13.49(1349/10000)%\n",
            "Accuracy on testing data 12.3(123/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 18.73(1873/10000)%\n",
            "Accuracy on testing data 17.6(176/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 25.33(2533/10000)%\n",
            "Accuracy on testing data 25.2(252/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 26.98(2698/10000)%\n",
            "Accuracy on testing data 27.4(274/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 29.1(2910/10000)%\n",
            "Accuracy on testing data 28.8(288/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 31.47(3147/10000)%\n",
            "Accuracy on testing data 31.8(318/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 33.32(3332/10000)%\n",
            "Accuracy on testing data 32.7(327/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 34.97(3497/10000)%\n",
            "Accuracy on testing data 34.0(340/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 36.84(3684/10000)%\n",
            "Accuracy on testing data 35.6(356/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 38.49(3849/10000)%\n",
            "Accuracy on testing data 37.9(379/1000)%\n",
            "Added record to eval DF. Total records so far: 2\n",
            "   dataset epochs  ... avg_accuracy avg_time_taken\n",
            "0  CIFAR10     10  ...    46.310000     347.395857\n",
            "1  CIFAR10     10  ...    26.213333     353.097072\n",
            "\n",
            "[2 rows x 15 columns]\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 9.86(986/10000)%\n",
            "Accuracy on testing data 9.0(90/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 10.75(1075/10000)%\n",
            "Accuracy on testing data 9.5(95/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 11.38(1138/10000)%\n",
            "Accuracy on testing data 10.4(104/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 11.92(1192/10000)%\n",
            "Accuracy on testing data 11.4(114/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 12.7(1270/10000)%\n",
            "Accuracy on testing data 11.8(118/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 13.53(1353/10000)%\n",
            "Accuracy on testing data 12.8(128/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 14.49(1449/10000)%\n",
            "Accuracy on testing data 14.1(141/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 15.35(1535/10000)%\n",
            "Accuracy on testing data 14.9(149/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 16.14(1614/10000)%\n",
            "Accuracy on testing data 15.9(159/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 17.09(1709/10000)%\n",
            "Accuracy on testing data 17.2(172/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 11.25(1125/10000)%\n",
            "Accuracy on testing data 10.3(103/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 14.22(1422/10000)%\n",
            "Accuracy on testing data 12.8(128/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 14.93(1493/10000)%\n",
            "Accuracy on testing data 14.4(144/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 14.91(1491/10000)%\n",
            "Accuracy on testing data 14.8(148/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 14.85(1485/10000)%\n",
            "Accuracy on testing data 15.2(152/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 15.04(1504/10000)%\n",
            "Accuracy on testing data 15.1(151/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 15.17(1517/10000)%\n",
            "Accuracy on testing data 15.2(152/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 15.38(1538/10000)%\n",
            "Accuracy on testing data 15.3(153/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 15.51(1551/10000)%\n",
            "Accuracy on testing data 15.8(158/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 15.69(1569/10000)%\n",
            "Accuracy on testing data 15.7(157/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 11.22(1122/10000)%\n",
            "Accuracy on testing data 12.7(127/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 12.25(1225/10000)%\n",
            "Accuracy on testing data 12.7(127/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 12.97(1297/10000)%\n",
            "Accuracy on testing data 13.9(139/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 13.8(1380/10000)%\n",
            "Accuracy on testing data 14.1(141/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 13.76(1376/10000)%\n",
            "Accuracy on testing data 13.0(130/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 13.51(1351/10000)%\n",
            "Accuracy on testing data 12.8(128/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 12.95(1295/10000)%\n",
            "Accuracy on testing data 12.1(121/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 12.86(1286/10000)%\n",
            "Accuracy on testing data 12.1(121/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 12.78(1278/10000)%\n",
            "Accuracy on testing data 12.4(124/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 12.86(1286/10000)%\n",
            "Accuracy on testing data 12.3(123/1000)%\n",
            "Added record to eval DF. Total records so far: 3\n",
            "   dataset epochs  ... avg_accuracy avg_time_taken\n",
            "0  CIFAR10     10  ...    46.310000     347.395857\n",
            "1  CIFAR10     10  ...    26.213333     353.097072\n",
            "2  CIFAR10     10  ...    13.323333     348.533622\n",
            "\n",
            "[3 rows x 15 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "XC1MsE6nzG9R",
        "outputId": "7339e2df-df5e-4629-a534-c5b2406bd056"
      },
      "source": [
        "eval_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>best_accuracy</th>\n",
              "      <th>avg_accuracy</th>\n",
              "      <th>avg_time_taken</th>\n",
              "      <th>dataset</th>\n",
              "      <th>epochs</th>\n",
              "      <th>nn_stack</th>\n",
              "      <th>loss_func</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>momentum</th>\n",
              "      <th>testing_dataset_type</th>\n",
              "      <th>training_size</th>\n",
              "      <th>testing_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>62.1</td>\n",
              "      <td>46.310000</td>\n",
              "      <td>347.395857</td>\n",
              "      <td>CIFAR10</td>\n",
              "      <td>10</td>\n",
              "      <td>[Conv2d(3, 20, kernel_size=(5, 5), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.00100</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37.9</td>\n",
              "      <td>26.213333</td>\n",
              "      <td>353.097072</td>\n",
              "      <td>CIFAR10</td>\n",
              "      <td>10</td>\n",
              "      <td>[Conv2d(3, 20, kernel_size=(5, 5), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17.2</td>\n",
              "      <td>13.323333</td>\n",
              "      <td>348.533622</td>\n",
              "      <td>CIFAR10</td>\n",
              "      <td>10</td>\n",
              "      <td>[Conv2d(3, 20, kernel_size=(5, 5), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   best_accuracy  avg_accuracy  ...  training_size testing_size\n",
              "0           62.1     46.310000  ...          10000         1000\n",
              "1           37.9     26.213333  ...          10000         1000\n",
              "2           17.2     13.323333  ...          10000         1000\n",
              "\n",
              "[3 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC4_Hy_n7dK9"
      },
      "source": [
        "Learning rate of `1e-3` seems to work best. Try different batch sizes `[10, 100, 250]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQomdZ0PzKwS",
        "outputId": "a170c8be-2d81-4336-b153-dcf8340dd4a8"
      },
      "source": [
        "class TestingConfig:\n",
        "    torch.manual_seed(21)\n",
        "    base_architectures = [[nn.Conv2d(in_channels=3, out_channels=20, kernel_size=5, stride=1),\n",
        "                            nn.ReLU(),\n",
        "                            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                            nn.Dropout(0.0),\n",
        "                            nn.Conv2d(in_channels=20, out_channels=40, kernel_size=5, stride=1),\n",
        "                            nn.ReLU(),\n",
        "                            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                            nn.Dropout(0.0),\n",
        "                            nn.Flatten(),\n",
        "                            nn.Linear(40 * 5 * 5, 40 * 5 * 5 * 2),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Dropout(0.0),\n",
        "                            nn.Linear(40 * 5 * 5 * 2, 10),\n",
        "                            nn.ReLU()]]\n",
        "    CONFIG = {\n",
        "        \"dataset\": [\"CIFAR10\"],\n",
        "        \"epochs\": [10],\n",
        "        \"nn_stack\": _get_nn_stacks_with_dropouts(base_architectures, dropout_options=[0.0]),\n",
        "        \"loss_func\": [\"CrossEntropyLoss\"],\n",
        "        \"optimizer\": [\"SGD\"],\n",
        "        \"learning_rate\": [1e-3],\n",
        "        \"weight_decay\": [1e-4],\n",
        "        \"batch_size\": [10, 100, 250],\n",
        "        \"testing_dataset_type\": [\"validation\"],\n",
        "        \"training_size\": [10000],\n",
        "        \"testing_size\": [1000],\n",
        "        \"momentum\": [0.9]\n",
        "    }\n",
        "\n",
        "\n",
        "eval_data = HyperTuner().tune(TestingConfig.CONFIG, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total combinations for exp: 3\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 23.95(2395/10000)%\n",
            "Accuracy on testing data 24.3(243/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 35.05(3505/10000)%\n",
            "Accuracy on testing data 34.6(346/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 45.03(4503/10000)%\n",
            "Accuracy on testing data 47.2(472/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 51.15(5115/10000)%\n",
            "Accuracy on testing data 52.5(525/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 55.21(5521/10000)%\n",
            "Accuracy on testing data 55.3(553/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 59.22(5922/10000)%\n",
            "Accuracy on testing data 58.1(581/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 62.71(6271/10000)%\n",
            "Accuracy on testing data 58.3(583/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 66.52(6652/10000)%\n",
            "Accuracy on testing data 59.5(595/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 70.09(7009/10000)%\n",
            "Accuracy on testing data 61.8(618/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 73.69(7369/10000)%\n",
            "Accuracy on testing data 62.1(621/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 23.6(2360/10000)%\n",
            "Accuracy on testing data 23.6(236/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 26.86(2686/10000)%\n",
            "Accuracy on testing data 27.0(270/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 29.23(2923/10000)%\n",
            "Accuracy on testing data 28.6(286/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 30.13(3013/10000)%\n",
            "Accuracy on testing data 30.3(303/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 33.55(3355/10000)%\n",
            "Accuracy on testing data 33.9(339/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 37.89(3789/10000)%\n",
            "Accuracy on testing data 37.1(371/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 39.73(3973/10000)%\n",
            "Accuracy on testing data 38.5(385/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 46.01(4601/10000)%\n",
            "Accuracy on testing data 44.4(444/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 48.29(4829/10000)%\n",
            "Accuracy on testing data 45.2(452/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 50.45(5045/10000)%\n",
            "Accuracy on testing data 45.9(459/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 32.86(3286/10000)%\n",
            "Accuracy on testing data 32.7(327/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 43.06(4306/10000)%\n",
            "Accuracy on testing data 42.5(425/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 49.07(4907/10000)%\n",
            "Accuracy on testing data 47.8(478/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 53.68(5368/10000)%\n",
            "Accuracy on testing data 50.8(508/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 57.39(5739/10000)%\n",
            "Accuracy on testing data 53.9(539/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 61.91(6191/10000)%\n",
            "Accuracy on testing data 55.0(550/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 66.39(6639/10000)%\n",
            "Accuracy on testing data 57.4(574/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 70.52(7052/10000)%\n",
            "Accuracy on testing data 59.2(592/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 74.39(7439/10000)%\n",
            "Accuracy on testing data 60.5(605/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 77.69(7769/10000)%\n",
            "Accuracy on testing data 61.3(613/1000)%\n",
            "Added record to eval DF. Total records so far: 1\n",
            "   dataset epochs  ... avg_accuracy avg_time_taken\n",
            "0  CIFAR10     10  ...        46.31     341.212751\n",
            "\n",
            "[1 rows x 15 columns]\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 15.2(1520/10000)%\n",
            "Accuracy on testing data 14.2(142/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 21.2(2120/10000)%\n",
            "Accuracy on testing data 23.3(233/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 23.41(2341/10000)%\n",
            "Accuracy on testing data 25.6(256/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 25.42(2542/10000)%\n",
            "Accuracy on testing data 27.5(275/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 27.11(2711/10000)%\n",
            "Accuracy on testing data 28.5(285/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 28.33(2833/10000)%\n",
            "Accuracy on testing data 30.0(300/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 29.47(2947/10000)%\n",
            "Accuracy on testing data 30.0(300/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 30.58(3058/10000)%\n",
            "Accuracy on testing data 30.8(308/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 31.64(3164/10000)%\n",
            "Accuracy on testing data 32.2(322/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 32.29(3229/10000)%\n",
            "Accuracy on testing data 32.6(326/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 14.6(1460/10000)%\n",
            "Accuracy on testing data 15.3(153/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 16.96(1696/10000)%\n",
            "Accuracy on testing data 17.7(177/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 18.65(1865/10000)%\n",
            "Accuracy on testing data 19.0(190/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 19.37(1937/10000)%\n",
            "Accuracy on testing data 20.3(203/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 20.77(2077/10000)%\n",
            "Accuracy on testing data 21.3(213/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 21.82(2182/10000)%\n",
            "Accuracy on testing data 22.0(220/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 22.61(2261/10000)%\n",
            "Accuracy on testing data 22.8(228/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 22.87(2287/10000)%\n",
            "Accuracy on testing data 23.6(236/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 23.42(2342/10000)%\n",
            "Accuracy on testing data 24.0(240/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 23.93(2393/10000)%\n",
            "Accuracy on testing data 24.7(247/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 12.3(1230/10000)%\n",
            "Accuracy on testing data 11.1(111/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 15.32(1532/10000)%\n",
            "Accuracy on testing data 14.4(144/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 24.11(2411/10000)%\n",
            "Accuracy on testing data 23.7(237/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 26.69(2669/10000)%\n",
            "Accuracy on testing data 27.0(270/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 27.7(2770/10000)%\n",
            "Accuracy on testing data 27.5(275/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 31.52(3152/10000)%\n",
            "Accuracy on testing data 31.8(318/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 33.64(3364/10000)%\n",
            "Accuracy on testing data 33.6(336/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 35.05(3505/10000)%\n",
            "Accuracy on testing data 34.8(348/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 36.73(3673/10000)%\n",
            "Accuracy on testing data 36.2(362/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 38.48(3848/10000)%\n",
            "Accuracy on testing data 37.0(370/1000)%\n",
            "Added record to eval DF. Total records so far: 2\n",
            "   dataset epochs  ... avg_accuracy avg_time_taken\n",
            "0  CIFAR10     10  ...    46.310000     341.212751\n",
            "1  CIFAR10     10  ...    25.416667     198.163208\n",
            "\n",
            "[2 rows x 15 columns]\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 11.2(1120/10000)%\n",
            "Accuracy on testing data 10.3(103/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 14.05(1405/10000)%\n",
            "Accuracy on testing data 13.5(135/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 17.54(1754/10000)%\n",
            "Accuracy on testing data 17.6(176/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 19.97(1997/10000)%\n",
            "Accuracy on testing data 21.5(215/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 21.18(2118/10000)%\n",
            "Accuracy on testing data 23.1(231/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 22.08(2208/10000)%\n",
            "Accuracy on testing data 24.7(247/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 22.82(2282/10000)%\n",
            "Accuracy on testing data 25.2(252/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 23.67(2367/10000)%\n",
            "Accuracy on testing data 26.2(262/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 24.62(2462/10000)%\n",
            "Accuracy on testing data 27.8(278/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 25.36(2536/10000)%\n",
            "Accuracy on testing data 29.0(290/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 14.55(1455/10000)%\n",
            "Accuracy on testing data 14.5(145/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 14.63(1463/10000)%\n",
            "Accuracy on testing data 15.4(154/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 15.44(1544/10000)%\n",
            "Accuracy on testing data 15.8(158/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 16.47(1647/10000)%\n",
            "Accuracy on testing data 17.2(172/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 17.45(1745/10000)%\n",
            "Accuracy on testing data 18.3(183/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 18.31(1831/10000)%\n",
            "Accuracy on testing data 18.9(189/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 19.03(1903/10000)%\n",
            "Accuracy on testing data 19.6(196/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 19.08(1908/10000)%\n",
            "Accuracy on testing data 19.8(198/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 19.34(1934/10000)%\n",
            "Accuracy on testing data 20.2(202/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 19.83(1983/10000)%\n",
            "Accuracy on testing data 21.1(211/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 12.97(1297/10000)%\n",
            "Accuracy on testing data 13.4(134/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 12.31(1231/10000)%\n",
            "Accuracy on testing data 11.3(113/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 12.19(1219/10000)%\n",
            "Accuracy on testing data 11.3(113/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 13.44(1344/10000)%\n",
            "Accuracy on testing data 12.2(122/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 15.86(1586/10000)%\n",
            "Accuracy on testing data 15.5(155/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 19.3(1930/10000)%\n",
            "Accuracy on testing data 18.9(189/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 22.91(2291/10000)%\n",
            "Accuracy on testing data 21.8(218/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 25.27(2527/10000)%\n",
            "Accuracy on testing data 25.3(253/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 26.4(2640/10000)%\n",
            "Accuracy on testing data 26.0(260/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 26.84(2684/10000)%\n",
            "Accuracy on testing data 27.0(270/1000)%\n",
            "Added record to eval DF. Total records so far: 3\n",
            "   dataset epochs  ... avg_accuracy avg_time_taken\n",
            "0  CIFAR10     10  ...    46.310000     341.212751\n",
            "1  CIFAR10     10  ...    25.416667     198.163208\n",
            "2  CIFAR10     10  ...    19.413333     180.172441\n",
            "\n",
            "[3 rows x 15 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "y2amH2n9zZGd",
        "outputId": "ee9545b1-67c5-4d25-8368-b3fd50842920"
      },
      "source": [
        "eval_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>best_accuracy</th>\n",
              "      <th>avg_accuracy</th>\n",
              "      <th>avg_time_taken</th>\n",
              "      <th>dataset</th>\n",
              "      <th>epochs</th>\n",
              "      <th>nn_stack</th>\n",
              "      <th>loss_func</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>momentum</th>\n",
              "      <th>testing_dataset_type</th>\n",
              "      <th>training_size</th>\n",
              "      <th>testing_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>62.1</td>\n",
              "      <td>46.310000</td>\n",
              "      <td>341.212751</td>\n",
              "      <td>CIFAR10</td>\n",
              "      <td>10</td>\n",
              "      <td>[Conv2d(3, 20, kernel_size=(5, 5), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37.0</td>\n",
              "      <td>25.416667</td>\n",
              "      <td>198.163208</td>\n",
              "      <td>CIFAR10</td>\n",
              "      <td>10</td>\n",
              "      <td>[Conv2d(3, 20, kernel_size=(5, 5), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29.0</td>\n",
              "      <td>19.413333</td>\n",
              "      <td>180.172441</td>\n",
              "      <td>CIFAR10</td>\n",
              "      <td>10</td>\n",
              "      <td>[Conv2d(3, 20, kernel_size=(5, 5), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>250</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   best_accuracy  avg_accuracy  ...  training_size testing_size\n",
              "0           62.1     46.310000  ...          10000         1000\n",
              "1           37.0     25.416667  ...          10000         1000\n",
              "2           29.0     19.413333  ...          10000         1000\n",
              "\n",
              "[3 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUchVidD7mzS"
      },
      "source": [
        "Lowest batch size worked best. Try with batch sizes 5 as well(1 is too slow)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itfRqYTp5m0H",
        "outputId": "ddb2226a-bd65-49b8-f162-3588d59898e1"
      },
      "source": [
        "class TestingConfig:\n",
        "    torch.manual_seed(21)\n",
        "    base_architectures = [\n",
        "                          [nn.Conv2d(in_channels=3, out_channels=20, kernel_size=5, stride=1),\n",
        "                            nn.ReLU(),\n",
        "                            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                            nn.Dropout(0.0),\n",
        "                            nn.Conv2d(in_channels=20, out_channels=40, kernel_size=5, stride=1),\n",
        "                            nn.ReLU(),\n",
        "                            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                            nn.Dropout(0.0),\n",
        "                            nn.Flatten(),\n",
        "                            nn.Linear(40 * 5 * 5, 40 * 5 * 5 * 2),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Dropout(0.0),\n",
        "                            nn.Linear(40 * 5 * 5 * 2, 10),\n",
        "                            nn.ReLU()]]\n",
        "    CONFIG = {\n",
        "        \"dataset\": [\"CIFAR10\"],\n",
        "        \"epochs\": [10],\n",
        "        \"nn_stack\": _get_nn_stacks_with_dropouts(base_architectures, dropout_options=[0.0]),\n",
        "        \"loss_func\": [\"CrossEntropyLoss\"],\n",
        "        \"optimizer\": [\"SGD\"],\n",
        "        \"learning_rate\": [1e-3],\n",
        "        \"weight_decay\": [1e-4],\n",
        "        \"batch_size\": [5],\n",
        "        \"testing_dataset_type\": [\"validation\"],\n",
        "        \"training_size\": [10000],\n",
        "        \"testing_size\": [1000],\n",
        "        \"momentum\": [0.9]\n",
        "    }\n",
        "\n",
        "\n",
        "eval_data = HyperTuner().tune(TestingConfig.CONFIG, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total combinations for exp: 1\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 29.69(2969/10000)%\n",
            "Accuracy on testing data 30.2(302/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 45.39(4539/10000)%\n",
            "Accuracy on testing data 48.3(483/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 52.84(5284/10000)%\n",
            "Accuracy on testing data 52.8(528/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 58.16(5816/10000)%\n",
            "Accuracy on testing data 54.3(543/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 62.9(6290/10000)%\n",
            "Accuracy on testing data 56.8(568/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 67.63(6763/10000)%\n",
            "Accuracy on testing data 57.8(578/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 72.32(7232/10000)%\n",
            "Accuracy on testing data 59.0(590/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 77.7(7770/10000)%\n",
            "Accuracy on testing data 60.5(605/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 83.61(8361/10000)%\n",
            "Accuracy on testing data 63.4(634/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 83.67(8367/10000)%\n",
            "Accuracy on testing data 61.5(615/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 27.31(2731/10000)%\n",
            "Accuracy on testing data 27.0(270/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 37.4(3740/10000)%\n",
            "Accuracy on testing data 37.6(376/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 49.19(4919/10000)%\n",
            "Accuracy on testing data 47.0(470/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 54.6(5460/10000)%\n",
            "Accuracy on testing data 49.5(495/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 57.86(5786/10000)%\n",
            "Accuracy on testing data 49.4(494/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 61.81(6181/10000)%\n",
            "Accuracy on testing data 51.1(511/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 69.32(6932/10000)%\n",
            "Accuracy on testing data 55.9(559/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 72.41(7241/10000)%\n",
            "Accuracy on testing data 56.4(564/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 75.44(7544/10000)%\n",
            "Accuracy on testing data 56.6(566/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 78.46(7846/10000)%\n",
            "Accuracy on testing data 56.5(565/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 36.69(3669/10000)%\n",
            "Accuracy on testing data 36.3(363/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 46.18(4618/10000)%\n",
            "Accuracy on testing data 46.4(464/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 53.94(5394/10000)%\n",
            "Accuracy on testing data 52.1(521/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 60.89(6089/10000)%\n",
            "Accuracy on testing data 55.7(557/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 66.83(6683/10000)%\n",
            "Accuracy on testing data 57.4(574/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 71.9(7190/10000)%\n",
            "Accuracy on testing data 59.5(595/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 74.74(7474/10000)%\n",
            "Accuracy on testing data 60.2(602/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 79.81(7981/10000)%\n",
            "Accuracy on testing data 60.6(606/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 85.15(8515/10000)%\n",
            "Accuracy on testing data 62.3(623/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 86.79(8679/10000)%\n",
            "Accuracy on testing data 61.8(618/1000)%\n",
            "Added record to eval DF. Total records so far: 1\n",
            "   dataset epochs  ... avg_accuracy avg_time_taken\n",
            "0  CIFAR10     10  ...    52.796667     513.717378\n",
            "\n",
            "[1 rows x 15 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "4xOa6wH4AA8M",
        "outputId": "2d35b9a4-3648-4357-f3a8-3fae4a66cc8f"
      },
      "source": [
        "eval_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>best_accuracy</th>\n",
              "      <th>avg_accuracy</th>\n",
              "      <th>avg_time_taken</th>\n",
              "      <th>dataset</th>\n",
              "      <th>epochs</th>\n",
              "      <th>nn_stack</th>\n",
              "      <th>loss_func</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>momentum</th>\n",
              "      <th>testing_dataset_type</th>\n",
              "      <th>training_size</th>\n",
              "      <th>testing_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63.4</td>\n",
              "      <td>52.796667</td>\n",
              "      <td>513.717378</td>\n",
              "      <td>CIFAR10</td>\n",
              "      <td>10</td>\n",
              "      <td>[Conv2d(3, 20, kernel_size=(5, 5), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>5</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   best_accuracy  avg_accuracy  ...  training_size testing_size\n",
              "0           63.4     52.796667  ...          10000         1000\n",
              "\n",
              "[1 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlRLz3BV9pi2"
      },
      "source": [
        "Batch size of 5 seems to work best, albeit slower.\n",
        "\n",
        "---\n",
        "Try adding one more hidden Linear Layer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBDLZZMq-IFd",
        "outputId": "722933df-788a-4cb0-a186-2b539df19ee5"
      },
      "source": [
        "class TestingConfig:\n",
        "    torch.manual_seed(21)\n",
        "    base_architectures = [\n",
        "            # more linear layers\n",
        "            [nn.Conv2d(in_channels=3, out_channels=20, kernel_size=5, stride=1),\n",
        "             nn.ReLU(),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Conv2d(in_channels=20, out_channels=40, kernel_size=5, stride=1),\n",
        "             nn.ReLU(),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Flatten(),\n",
        "             nn.Linear(40 * 5 * 5, 40 * 5 * 5 * 2),\n",
        "             nn.ReLU(),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Linear(40 * 5 * 5 * 2, 1000),\n",
        "             nn.ReLU(),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Linear(1000, 10),\n",
        "             nn.ReLU()],\n",
        "        ]\n",
        "    CONFIG = {\n",
        "        \"dataset\": [\"CIFAR10\"],\n",
        "        \"epochs\": [10],\n",
        "        \"nn_stack\": _get_nn_stacks_with_dropouts(base_architectures, dropout_options=[0.0]),\n",
        "        \"loss_func\": [\"CrossEntropyLoss\"],\n",
        "        \"optimizer\": [\"SGD\"],\n",
        "        \"learning_rate\": [1e-3],\n",
        "        \"weight_decay\": [1e-4],\n",
        "        \"batch_size\": [5],\n",
        "        \"testing_dataset_type\": [\"validation\"],\n",
        "        \"training_size\": [10000],\n",
        "        \"testing_size\": [1000],\n",
        "        \"momentum\": [0.9]\n",
        "    }\n",
        "\n",
        "\n",
        "eval_data = HyperTuner().tune(TestingConfig.CONFIG, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total combinations for exp: 1\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 31.34(3134/10000)%\n",
            "Accuracy on testing data 32.4(324/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 38.73(3873/10000)%\n",
            "Accuracy on testing data 39.4(394/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 44.95(4495/10000)%\n",
            "Accuracy on testing data 44.8(448/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 50.15(5015/10000)%\n",
            "Accuracy on testing data 50.0(500/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 54.69(5469/10000)%\n",
            "Accuracy on testing data 51.8(518/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 59.38(5938/10000)%\n",
            "Accuracy on testing data 52.9(529/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 63.17(6317/10000)%\n",
            "Accuracy on testing data 55.0(550/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 67.31(6731/10000)%\n",
            "Accuracy on testing data 55.6(556/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 72.8(7280/10000)%\n",
            "Accuracy on testing data 58.4(584/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 75.6(7560/10000)%\n",
            "Accuracy on testing data 58.6(586/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 23.03(2303/10000)%\n",
            "Accuracy on testing data 23.6(236/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 28.83(2883/10000)%\n",
            "Accuracy on testing data 26.9(269/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 31.98(3198/10000)%\n",
            "Accuracy on testing data 29.5(295/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 34.85(3485/10000)%\n",
            "Accuracy on testing data 32.5(325/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 39.47(3947/10000)%\n",
            "Accuracy on testing data 36.9(369/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 42.56(4256/10000)%\n",
            "Accuracy on testing data 40.1(401/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 54.21(5421/10000)%\n",
            "Accuracy on testing data 47.7(477/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 57.5(5750/10000)%\n",
            "Accuracy on testing data 48.4(484/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 62.45(6245/10000)%\n",
            "Accuracy on testing data 50.5(505/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 65.23(6523/10000)%\n",
            "Accuracy on testing data 50.5(505/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 24.59(2459/10000)%\n",
            "Accuracy on testing data 24.6(246/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 35.77(3577/10000)%\n",
            "Accuracy on testing data 35.6(356/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 40.99(4099/10000)%\n",
            "Accuracy on testing data 40.1(401/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 45.13(4513/10000)%\n",
            "Accuracy on testing data 42.0(420/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 48.57(4857/10000)%\n",
            "Accuracy on testing data 43.2(432/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 56.29(5629/10000)%\n",
            "Accuracy on testing data 49.8(498/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 61.26(6126/10000)%\n",
            "Accuracy on testing data 51.7(517/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 66.07(6607/10000)%\n",
            "Accuracy on testing data 54.1(541/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 68.7(6870/10000)%\n",
            "Accuracy on testing data 53.4(534/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 78.25(7825/10000)%\n",
            "Accuracy on testing data 60.0(600/1000)%\n",
            "Added record to eval DF. Total records so far: 1\n",
            "   dataset epochs  ... avg_accuracy avg_time_taken\n",
            "0  CIFAR10     10  ...    44.666667     807.469093\n",
            "\n",
            "[1 rows x 15 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "D-Uf3tD6JITT",
        "outputId": "7f0c2594-226e-4636-b491-e2eb6a74a883"
      },
      "source": [
        "eval_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>best_accuracy</th>\n",
              "      <th>avg_accuracy</th>\n",
              "      <th>avg_time_taken</th>\n",
              "      <th>dataset</th>\n",
              "      <th>epochs</th>\n",
              "      <th>nn_stack</th>\n",
              "      <th>loss_func</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>momentum</th>\n",
              "      <th>testing_dataset_type</th>\n",
              "      <th>training_size</th>\n",
              "      <th>testing_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60.0</td>\n",
              "      <td>44.666667</td>\n",
              "      <td>807.469093</td>\n",
              "      <td>CIFAR10</td>\n",
              "      <td>10</td>\n",
              "      <td>[Conv2d(3, 20, kernel_size=(5, 5), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>5</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   best_accuracy  avg_accuracy  ...  training_size testing_size\n",
              "0           60.0     44.666667  ...          10000         1000\n",
              "\n",
              "[1 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBI8hrdnxdrR"
      },
      "source": [
        "Does not seem to improve the accuracy.\n",
        "<br> Try a full run using previous config on training/testing datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XXRwsdsddMUu",
        "outputId": "2294b8ef-e10c-4d11-e442-a49239d9a51a"
      },
      "source": [
        "model = TorchCNN(\n",
        "    loss_func=\"CrossEntropyLoss\",\n",
        "    optimizer=\"SGD\",\n",
        "    learning_rate=1e-3,\n",
        "    lmda_wt_decay=1e-4,\n",
        "    batch_size=5,\n",
        "    training_size=50000,\n",
        "    testing_size=10000,\n",
        "    seed=35,\n",
        "    momentum=0.9,\n",
        "    nn_stack=[  nn.Conv2d(in_channels=3, out_channels=20, kernel_size=5, stride=1),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                nn.Dropout(0.0),\n",
        "                nn.Conv2d(in_channels=20, out_channels=40, kernel_size=5, stride=1),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                nn.Dropout(0.0),\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(40 * 5 * 5, 40 * 5 * 5 * 2),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(0.0),\n",
        "                nn.Linear(40 * 5 * 5 * 2, 10),\n",
        "                nn.ReLU()]\n",
        ").to(device)\n",
        "train_data = CIFAR10(root='cifar10', train=True, download=True, transform=cifar_transform)\n",
        "test_data = CIFAR10(root='cifar10', train=False, download=True, transform=cifar_transform)\n",
        "torch.manual_seed(35)\n",
        "training_loader = DataLoader(train_data, batch_size=5, shuffle=True)\n",
        "testing_loader = DataLoader(test_data, batch_size=5, shuffle=True)\n",
        "accuracies = []\n",
        "for epoch in range(25):\n",
        "    print(f\"Training for epoch: {epoch}\")\n",
        "    model.train_model(training_loader)\n",
        "    accuracies.append(model.evaluate(testing_loader, model.testing_size, \"testing\"))\n",
        "print(max(accuracies))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 46.14(23071/50000)%\n",
            "Accuracy on testing data 44.79(4479/10000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 63.77(31885/50000)%\n",
            "Accuracy on testing data 60.96(6096/10000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 71.92(35959/50000)%\n",
            "Accuracy on testing data 65.95(6595/10000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 76.65(38326/50000)%\n",
            "Accuracy on testing data 67.28(6728/10000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 81.17(40583/50000)%\n",
            "Accuracy on testing data 67.73(6773/10000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 84.92(42461/50000)%\n",
            "Accuracy on testing data 68.27(6827/10000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 87.29(43646/50000)%\n",
            "Accuracy on testing data 67.93(6793/10000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 89.86(44929/50000)%\n",
            "Accuracy on testing data 68.6(6860/10000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 91.36(45681/50000)%\n",
            "Accuracy on testing data 67.86(6786/10000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 94.42(47210/50000)%\n",
            "Accuracy on testing data 69.92(6992/10000)%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 94.89(47446/50000)%\n",
            "Accuracy on testing data 69.79(6979/10000)%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 95.18(47591/50000)%\n",
            "Accuracy on testing data 68.66(6866/10000)%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 95.86(47929/50000)%\n",
            "Accuracy on testing data 68.77(6877/10000)%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 96.16(48080/50000)%\n",
            "Accuracy on testing data 69.87(6987/10000)%\n",
            "Training for epoch: 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-b2b6b8e47efa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training for epoch: {epoch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"testing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-35077d3df823>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, training_loader, verbose)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \"\"\"\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mmode_to_nptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'I'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'I;16'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     img = torch.from_numpy(\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_to_nptype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     )\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'Image'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD_J0YkFw_zw"
      },
      "source": [
        "Reaches around 68-69% on CIFAR10 testing dataset. Stopping the execution manually."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwGfOiU7sCKf",
        "outputId": "ba28237d-5ced-41d1-b55e-adaa23f66ae0"
      },
      "source": [
        "class TestingConfig:\n",
        "    torch.manual_seed(21)\n",
        "    base_architectures = [\n",
        "            # more conv layers\n",
        "            [nn.Conv2d(in_channels=3, out_channels=20, kernel_size=3, stride=1, padding=1),\n",
        "             nn.ReLU(),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Conv2d(in_channels=20, out_channels=40, kernel_size=3, stride=1, padding=1),\n",
        "             nn.ReLU(),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Conv2d(in_channels=40, out_channels=60, kernel_size=3, stride=1, padding=1),\n",
        "             nn.ReLU(),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Flatten(),\n",
        "             nn.Linear(60 * 4 * 4, 1000),\n",
        "             nn.ReLU(),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Linear(1000, 10),\n",
        "             nn.ReLU()],\n",
        "        ]\n",
        "    CONFIG = {\n",
        "        \"dataset\": [\"CIFAR10\"],\n",
        "        \"epochs\": [10],\n",
        "        \"nn_stack\": _get_nn_stacks_with_dropouts(base_architectures, dropout_options=[0.00]),\n",
        "        \"loss_func\": [\"CrossEntropyLoss\"],\n",
        "        \"optimizer\": [\"SGD\"],\n",
        "        \"learning_rate\": [1e-3],\n",
        "        \"weight_decay\": [1e-4],\n",
        "        \"batch_size\": [5],\n",
        "        \"testing_dataset_type\": [\"validation\"],\n",
        "        \"training_size\": [10000],\n",
        "        \"testing_size\": [1000],\n",
        "        \"momentum\": [0.9]\n",
        "    }\n",
        "\n",
        "\n",
        "eval_data = HyperTuner().tune(TestingConfig.CONFIG, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total combinations for exp: 1\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 24.79(2479/10000)%\n",
            "Accuracy on testing data 26.6(266/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 36.79(3679/10000)%\n",
            "Accuracy on testing data 38.9(389/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 46.85(4685/10000)%\n",
            "Accuracy on testing data 47.6(476/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 52.54(5254/10000)%\n",
            "Accuracy on testing data 51.6(516/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 58.33(5833/10000)%\n",
            "Accuracy on testing data 56.5(565/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 62.71(6271/10000)%\n",
            "Accuracy on testing data 58.3(583/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 66.46(6646/10000)%\n",
            "Accuracy on testing data 59.8(598/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 70.06(7006/10000)%\n",
            "Accuracy on testing data 60.2(602/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 73.43(7343/10000)%\n",
            "Accuracy on testing data 62.0(620/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 77.4(7740/10000)%\n",
            "Accuracy on testing data 62.9(629/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 21.26(2126/10000)%\n",
            "Accuracy on testing data 22.3(223/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 34.43(3443/10000)%\n",
            "Accuracy on testing data 34.3(343/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 43.8(4380/10000)%\n",
            "Accuracy on testing data 43.0(430/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 50.04(5004/10000)%\n",
            "Accuracy on testing data 45.9(459/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 55.07(5507/10000)%\n",
            "Accuracy on testing data 49.6(496/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 58.18(5818/10000)%\n",
            "Accuracy on testing data 50.6(506/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 61.51(6151/10000)%\n",
            "Accuracy on testing data 54.1(541/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 65.28(6528/10000)%\n",
            "Accuracy on testing data 55.4(554/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 70.25(7025/10000)%\n",
            "Accuracy on testing data 58.6(586/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 71.0(7100/10000)%\n",
            "Accuracy on testing data 57.8(578/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 23.89(2389/10000)%\n",
            "Accuracy on testing data 22.9(229/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 36.27(3627/10000)%\n",
            "Accuracy on testing data 36.9(369/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 44.3(4430/10000)%\n",
            "Accuracy on testing data 41.9(419/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 51.26(5126/10000)%\n",
            "Accuracy on testing data 48.6(486/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 57.54(5754/10000)%\n",
            "Accuracy on testing data 54.2(542/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 62.3(6230/10000)%\n",
            "Accuracy on testing data 58.5(585/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 67.07(6707/10000)%\n",
            "Accuracy on testing data 61.2(612/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 72.13(7213/10000)%\n",
            "Accuracy on testing data 63.2(632/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 76.44(7644/10000)%\n",
            "Accuracy on testing data 64.0(640/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 79.95(7995/10000)%\n",
            "Accuracy on testing data 63.9(639/1000)%\n",
            "Added record to eval DF. Total records so far: 1\n",
            "   dataset epochs  ... avg_accuracy avg_time_taken\n",
            "0  CIFAR10     10  ...    50.376667     464.986883\n",
            "\n",
            "[1 rows x 15 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "1frA3qV1G3MZ",
        "outputId": "b5c986fa-7977-4c61-87c9-ffb2e50f037b"
      },
      "source": [
        "eval_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>best_accuracy</th>\n",
              "      <th>avg_accuracy</th>\n",
              "      <th>avg_time_taken</th>\n",
              "      <th>dataset</th>\n",
              "      <th>epochs</th>\n",
              "      <th>nn_stack</th>\n",
              "      <th>loss_func</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>momentum</th>\n",
              "      <th>testing_dataset_type</th>\n",
              "      <th>training_size</th>\n",
              "      <th>testing_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>64.0</td>\n",
              "      <td>50.376667</td>\n",
              "      <td>464.986883</td>\n",
              "      <td>CIFAR10</td>\n",
              "      <td>10</td>\n",
              "      <td>[Conv2d(3, 20, kernel_size=(3, 3), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>5</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   best_accuracy  avg_accuracy  ...  training_size testing_size\n",
              "0           64.0     50.376667  ...          10000         1000\n",
              "\n",
              "[1 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zspvYsWJK-n",
        "outputId": "30f3bed4-8030-4cff-bed1-81ac956e1e1f"
      },
      "source": [
        "class TestingConfig:\n",
        "    torch.manual_seed(21)\n",
        "    base_architectures = [\n",
        "            # more conv layers\n",
        "            [nn.Conv2d(in_channels=3, out_channels=20, kernel_size=3, stride=1, padding=1),\n",
        "             nn.ReLU(),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Conv2d(in_channels=20, out_channels=40, kernel_size=3, stride=1, padding=1),\n",
        "             nn.ReLU(),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Conv2d(in_channels=40, out_channels=60, kernel_size=3, stride=1, padding=1),\n",
        "             nn.ReLU(),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Conv2d(in_channels=60, out_channels=80, kernel_size=3, stride=1, padding=1),\n",
        "             nn.ReLU(),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Flatten(),\n",
        "             nn.Linear(80 * 2 * 2, 80 * 2 * 2 * 2),\n",
        "             nn.ReLU(),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Linear(80 * 2 * 2 * 2, 10),\n",
        "             nn.ReLU()],\n",
        "        ]\n",
        "    CONFIG = {\n",
        "        \"dataset\": [\"CIFAR10\"],\n",
        "        \"epochs\": [10],\n",
        "        \"nn_stack\": _get_nn_stacks_with_dropouts(base_architectures, dropout_options=[0.00]),\n",
        "        \"loss_func\": [\"CrossEntropyLoss\"],\n",
        "        \"optimizer\": [\"SGD\"],\n",
        "        \"learning_rate\": [1e-3],\n",
        "        \"weight_decay\": [1e-4],\n",
        "        \"batch_size\": [5],\n",
        "        \"testing_dataset_type\": [\"validation\"],\n",
        "        \"training_size\": [10000],\n",
        "        \"testing_size\": [1000],\n",
        "        \"momentum\": [0.9]\n",
        "    }\n",
        "\n",
        "\n",
        "eval_data = HyperTuner().tune(TestingConfig.CONFIG, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total combinations for exp: 1\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 18.29(1829/10000)%\n",
            "Accuracy on testing data 18.7(187/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 30.3(3030/10000)%\n",
            "Accuracy on testing data 31.2(312/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 38.82(3882/10000)%\n",
            "Accuracy on testing data 40.7(407/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 42.73(4273/10000)%\n",
            "Accuracy on testing data 45.3(453/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 46.47(4647/10000)%\n",
            "Accuracy on testing data 47.9(479/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 50.73(5073/10000)%\n",
            "Accuracy on testing data 50.3(503/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 54.27(5427/10000)%\n",
            "Accuracy on testing data 53.0(530/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 57.62(5762/10000)%\n",
            "Accuracy on testing data 55.9(559/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 59.93(5993/10000)%\n",
            "Accuracy on testing data 56.7(567/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 62.85(6285/10000)%\n",
            "Accuracy on testing data 58.0(580/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 10.19(1019/10000)%\n",
            "Accuracy on testing data 10.8(108/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 18.9(1890/10000)%\n",
            "Accuracy on testing data 19.5(195/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 34.32(3432/10000)%\n",
            "Accuracy on testing data 34.5(345/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 41.02(4102/10000)%\n",
            "Accuracy on testing data 41.6(416/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 47.94(4794/10000)%\n",
            "Accuracy on testing data 47.2(472/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 53.22(5322/10000)%\n",
            "Accuracy on testing data 51.6(516/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 57.58(5758/10000)%\n",
            "Accuracy on testing data 55.8(558/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 62.41(6241/10000)%\n",
            "Accuracy on testing data 57.7(577/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 64.56(6456/10000)%\n",
            "Accuracy on testing data 59.4(594/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 67.34(6734/10000)%\n",
            "Accuracy on testing data 60.8(608/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 18.57(1857/10000)%\n",
            "Accuracy on testing data 19.2(192/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 23.28(2328/10000)%\n",
            "Accuracy on testing data 23.5(235/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 29.32(2932/10000)%\n",
            "Accuracy on testing data 29.2(292/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 33.92(3392/10000)%\n",
            "Accuracy on testing data 32.5(325/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 36.93(3693/10000)%\n",
            "Accuracy on testing data 35.9(359/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 39.28(3928/10000)%\n",
            "Accuracy on testing data 37.3(373/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 43.74(4374/10000)%\n",
            "Accuracy on testing data 40.9(409/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 54.66(5466/10000)%\n",
            "Accuracy on testing data 50.6(506/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 59.36(5936/10000)%\n",
            "Accuracy on testing data 53.6(536/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 63.09(6309/10000)%\n",
            "Accuracy on testing data 56.7(567/1000)%\n",
            "Added record to eval DF. Total records so far: 1\n",
            "   dataset epochs  ... avg_accuracy avg_time_taken\n",
            "0  CIFAR10     10  ...    42.533333     359.428771\n",
            "\n",
            "[1 rows x 15 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "QOeS5f_7NI0c",
        "outputId": "59d9cacf-4b8b-41f3-ad6c-88081d04f58d"
      },
      "source": [
        "eval_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>best_accuracy</th>\n",
              "      <th>avg_accuracy</th>\n",
              "      <th>avg_time_taken</th>\n",
              "      <th>dataset</th>\n",
              "      <th>epochs</th>\n",
              "      <th>nn_stack</th>\n",
              "      <th>loss_func</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>momentum</th>\n",
              "      <th>testing_dataset_type</th>\n",
              "      <th>training_size</th>\n",
              "      <th>testing_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60.8</td>\n",
              "      <td>42.533333</td>\n",
              "      <td>359.428771</td>\n",
              "      <td>CIFAR10</td>\n",
              "      <td>10</td>\n",
              "      <td>[Conv2d(3, 20, kernel_size=(3, 3), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>5</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   best_accuracy  avg_accuracy  ...  training_size testing_size\n",
              "0           60.8     42.533333  ...          10000         1000\n",
              "\n",
              "[1 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSGqcUdTNl_2",
        "outputId": "16c1c9e4-eaec-4353-b49d-9a34673d3b40"
      },
      "source": [
        "class TestingConfig:\n",
        "    torch.manual_seed(21)\n",
        "    base_architectures = [\n",
        "            # more conv layers\n",
        "            [nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
        "             nn.ReLU(),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "             nn.ReLU(),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "             nn.ReLU(),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Flatten(),\n",
        "             nn.Linear(64 * 4 * 4, 64 * 4 * 4 * 2),\n",
        "             nn.ReLU(),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Linear(64 * 4 * 4 * 2, 10),\n",
        "             nn.ReLU()],\n",
        "        ]\n",
        "    CONFIG = {\n",
        "        \"dataset\": [\"CIFAR10\"],\n",
        "        \"epochs\": [10],\n",
        "        \"nn_stack\": _get_nn_stacks_with_dropouts(base_architectures, dropout_options=[0.00]),\n",
        "        \"loss_func\": [\"CrossEntropyLoss\"],\n",
        "        \"optimizer\": [\"SGD\"],\n",
        "        \"learning_rate\": [1e-3],\n",
        "        \"weight_decay\": [1e-4],\n",
        "        \"batch_size\": [5],\n",
        "        \"testing_dataset_type\": [\"validation\"],\n",
        "        \"training_size\": [10000],\n",
        "        \"testing_size\": [1000],\n",
        "        \"momentum\": [0.9]\n",
        "    }\n",
        "\n",
        "\n",
        "eval_data = HyperTuner().tune(TestingConfig.CONFIG, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total combinations for exp: 1\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 22.43(2243/10000)%\n",
            "Accuracy on testing data 23.5(235/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 37.0(3700/10000)%\n",
            "Accuracy on testing data 38.6(386/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 44.91(4491/10000)%\n",
            "Accuracy on testing data 45.5(455/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 51.45(5145/10000)%\n",
            "Accuracy on testing data 52.0(520/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 56.82(5682/10000)%\n",
            "Accuracy on testing data 55.9(559/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 61.4(6140/10000)%\n",
            "Accuracy on testing data 57.8(578/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 65.83(6583/10000)%\n",
            "Accuracy on testing data 58.4(584/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 70.25(7025/10000)%\n",
            "Accuracy on testing data 60.3(603/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 74.83(7483/10000)%\n",
            "Accuracy on testing data 61.1(611/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 78.92(7892/10000)%\n",
            "Accuracy on testing data 63.4(634/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 25.02(2502/10000)%\n",
            "Accuracy on testing data 24.5(245/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 38.89(3889/10000)%\n",
            "Accuracy on testing data 38.8(388/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 48.17(4817/10000)%\n",
            "Accuracy on testing data 48.9(489/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 54.95(5495/10000)%\n",
            "Accuracy on testing data 51.1(511/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 60.06(6006/10000)%\n",
            "Accuracy on testing data 54.3(543/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 64.44(6444/10000)%\n",
            "Accuracy on testing data 57.0(570/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 68.33(6833/10000)%\n",
            "Accuracy on testing data 57.5(575/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 72.28(7228/10000)%\n",
            "Accuracy on testing data 59.2(592/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 75.96(7596/10000)%\n",
            "Accuracy on testing data 61.4(614/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 80.51(8051/10000)%\n",
            "Accuracy on testing data 61.5(615/1000)%\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 25.59(2559/10000)%\n",
            "Accuracy on testing data 25.1(251/1000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 33.5(3350/10000)%\n",
            "Accuracy on testing data 33.7(337/1000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 41.23(4123/10000)%\n",
            "Accuracy on testing data 39.3(393/1000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 44.76(4476/10000)%\n",
            "Accuracy on testing data 42.8(428/1000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 48.51(4851/10000)%\n",
            "Accuracy on testing data 45.0(450/1000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 57.12(5712/10000)%\n",
            "Accuracy on testing data 53.0(530/1000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 61.85(6185/10000)%\n",
            "Accuracy on testing data 56.2(562/1000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 71.29(7129/10000)%\n",
            "Accuracy on testing data 60.9(609/1000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 75.91(7591/10000)%\n",
            "Accuracy on testing data 62.2(622/1000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 79.45(7945/10000)%\n",
            "Accuracy on testing data 63.6(636/1000)%\n",
            "Added record to eval DF. Total records so far: 1\n",
            "   dataset epochs  ... avg_accuracy avg_time_taken\n",
            "0  CIFAR10     10  ...    50.416667     572.154505\n",
            "\n",
            "[1 rows x 15 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "kIaPXmrZTt6a",
        "outputId": "6e357e2f-897e-4113-8b3b-14c0963c92e9"
      },
      "source": [
        "eval_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>best_accuracy</th>\n",
              "      <th>avg_accuracy</th>\n",
              "      <th>avg_time_taken</th>\n",
              "      <th>dataset</th>\n",
              "      <th>epochs</th>\n",
              "      <th>nn_stack</th>\n",
              "      <th>loss_func</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>momentum</th>\n",
              "      <th>testing_dataset_type</th>\n",
              "      <th>training_size</th>\n",
              "      <th>testing_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63.6</td>\n",
              "      <td>50.416667</td>\n",
              "      <td>572.154505</td>\n",
              "      <td>CIFAR10</td>\n",
              "      <td>10</td>\n",
              "      <td>[Conv2d(3, 16, kernel_size=(3, 3), stride=(1, ...</td>\n",
              "      <td>CrossEntropyLoss</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>5</td>\n",
              "      <td>0.9</td>\n",
              "      <td>validation</td>\n",
              "      <td>10000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   best_accuracy  avg_accuracy  ...  training_size testing_size\n",
              "0           63.6     50.416667  ...          10000         1000\n",
              "\n",
              "[1 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rccAT5itWHpB",
        "outputId": "72d4037c-8672-4c37-c3e4-e2441a3f9a05"
      },
      "source": [
        "model = TorchCNN(\n",
        "    loss_func=\"CrossEntropyLoss\",\n",
        "    optimizer=\"SGD\",\n",
        "    learning_rate=1e-3,\n",
        "    lmda_wt_decay=1e-4,\n",
        "    batch_size=5,\n",
        "    training_size=50000,\n",
        "    testing_size=10000,\n",
        "    seed=35,\n",
        "    momentum=0.9,\n",
        "    nn_stack=[nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
        "             nn.ReLU(),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "             nn.ReLU(),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "             nn.ReLU(),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Flatten(),\n",
        "             nn.Linear(64 * 4 * 4, 64 * 4 * 4 * 2),\n",
        "             nn.ReLU(),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Linear(64 * 4 * 4 * 2, 10),\n",
        "             nn.ReLU()]\n",
        ").to(device)\n",
        "train_data = CIFAR10(root='cifar10', train=True, download=True, transform=cifar_transform)\n",
        "test_data = CIFAR10(root='cifar10', train=False, download=True, transform=cifar_transform)\n",
        "torch.manual_seed(35)\n",
        "training_loader = DataLoader(train_data, batch_size=5, shuffle=True)\n",
        "testing_loader = DataLoader(test_data, batch_size=5, shuffle=True)\n",
        "accuracies = []\n",
        "for epoch in range(25):\n",
        "    print(f\"Training for epoch: {epoch}\")\n",
        "    model.train_model(training_loader)\n",
        "    accuracies.append(model.evaluate(testing_loader, model.testing_size, \"testing\"))\n",
        "print(max(accuracies))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 51.75(25873/50000)%\n",
            "Accuracy on testing data 50.7(5070/10000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 65.94(32968/50000)%\n",
            "Accuracy on testing data 62.95(6295/10000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 72.72(36362/50000)%\n",
            "Accuracy on testing data 67.26(6726/10000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 77.63(38814/50000)%\n",
            "Accuracy on testing data 69.51(6951/10000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 80.9(40451/50000)%\n",
            "Accuracy on testing data 69.83(6983/10000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 83.74(41872/50000)%\n",
            "Accuracy on testing data 69.92(6992/10000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 85.12(42558/50000)%\n",
            "Accuracy on testing data 68.77(6877/10000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 89.2(44600/50000)%\n",
            "Accuracy on testing data 70.03(7003/10000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 90.94(45469/50000)%\n",
            "Accuracy on testing data 70.8(7080/10000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 92.34(46169/50000)%\n",
            "Accuracy on testing data 70.81(7081/10000)%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 93.05(46526/50000)%\n",
            "Accuracy on testing data 70.47(7047/10000)%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 92.77(46386/50000)%\n",
            "Accuracy on testing data 70.5(7050/10000)%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 93.42(46710/50000)%\n",
            "Accuracy on testing data 69.5(6950/10000)%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 96.18(48088/50000)%\n",
            "Accuracy on testing data 71.35(7135/10000)%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 95.63(47815/50000)%\n",
            "Accuracy on testing data 71.36(7136/10000)%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 97.18(48591/50000)%\n",
            "Accuracy on testing data 71.81(7181/10000)%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 97.75(48875/50000)%\n",
            "Accuracy on testing data 73.06(7306/10000)%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 98.17(49084/50000)%\n",
            "Accuracy on testing data 72.84(7284/10000)%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 97.67(48835/50000)%\n",
            "Accuracy on testing data 72.49(7249/10000)%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 97.52(48762/50000)%\n",
            "Accuracy on testing data 71.38(7138/10000)%\n",
            "Training for epoch: 20\n",
            "Accuracy on training data 97.76(48880/50000)%\n",
            "Accuracy on testing data 72.18(7218/10000)%\n",
            "Training for epoch: 21\n",
            "Accuracy on training data 98.54(49268/50000)%\n",
            "Accuracy on testing data 72.58(7258/10000)%\n",
            "Training for epoch: 22\n",
            "Accuracy on training data 98.46(49232/50000)%\n",
            "Accuracy on testing data 72.29(7229/10000)%\n",
            "Training for epoch: 23\n",
            "Accuracy on training data 98.26(49132/50000)%\n",
            "Accuracy on testing data 73.08(7308/10000)%\n",
            "Training for epoch: 24\n",
            "Accuracy on training data 99.47(49736/50000)%\n",
            "Accuracy on testing data 73.62(7362/10000)%\n",
            "73.62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isk9riCZY_Dw"
      },
      "source": [
        "Max observation of **73.62**. Try increasing epochs to 40."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f4e9bf4861f2417e92648d12b9e95f64",
            "7ed9879a9c844876929fd9ad435d507e",
            "2f713587305445d6a340cb1cb892b2d2",
            "0d1dab47c60547da9f1cc4bfcbc94dab",
            "f8895d34319e446ea16f48c6fc1c16bd",
            "27141384478a48599ee16450a5aebea2",
            "31f7b0429ce1466b846cef64c6c81def",
            "a9ad583b38464c26935e968bbcc458b6"
          ]
        },
        "id": "-0UScmwyYRj4",
        "outputId": "f6e57e52-5bb2-4137-ca3b-0f1690c6ff58"
      },
      "source": [
        "model = TorchCNN(\n",
        "    loss_func=\"CrossEntropyLoss\",\n",
        "    optimizer=\"SGD\",\n",
        "    learning_rate=1e-3,\n",
        "    lmda_wt_decay=1e-4,\n",
        "    batch_size=5,\n",
        "    training_size=50000,\n",
        "    testing_size=10000,\n",
        "    seed=35,\n",
        "    momentum=0.9,\n",
        "    nn_stack=[nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
        "             nn.ReLU(),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "             nn.ReLU(),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "             nn.ReLU(),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Flatten(),\n",
        "             nn.Linear(64 * 4 * 4, 64 * 4 * 4 * 2),\n",
        "             nn.ReLU(),\n",
        "             nn.Dropout(0.0),\n",
        "             nn.Linear(64 * 4 * 4 * 2, 10),\n",
        "             nn.ReLU()]\n",
        ").to(device)\n",
        "train_data = CIFAR10(root='cifar10', train=True, download=True, transform=cifar_transform)\n",
        "test_data = CIFAR10(root='cifar10', train=False, download=True, transform=cifar_transform)\n",
        "torch.manual_seed(35)\n",
        "training_loader = DataLoader(train_data, batch_size=5, shuffle=True)\n",
        "testing_loader = DataLoader(test_data, batch_size=5, shuffle=True)\n",
        "accuracies = []\n",
        "for epoch in range(40):\n",
        "    print(f\"Training for epoch: {epoch}\")\n",
        "    model.train_model(training_loader)\n",
        "    accuracies.append(model.evaluate(testing_loader, model.testing_size, \"testing\"))\n",
        "print(max(accuracies))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to cifar10/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4e9bf4861f2417e92648d12b9e95f64",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting cifar10/cifar-10-python.tar.gz to cifar10\n",
            "Files already downloaded and verified\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 51.62(25808/50000)%\n",
            "Accuracy on testing data 50.52(5052/10000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 64.86(32429/50000)%\n",
            "Accuracy on testing data 62.55(6255/10000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 71.66(35832/50000)%\n",
            "Accuracy on testing data 66.83(6683/10000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 74.95(37475/50000)%\n",
            "Accuracy on testing data 67.58(6758/10000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 76.94(38469/50000)%\n",
            "Accuracy on testing data 67.62(6762/10000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 80.54(40268/50000)%\n",
            "Accuracy on testing data 68.22(6822/10000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 83.44(41718/50000)%\n",
            "Accuracy on testing data 68.78(6878/10000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 84.54(42270/50000)%\n",
            "Accuracy on testing data 68.56(6856/10000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 86.91(43454/50000)%\n",
            "Accuracy on testing data 68.85(6885/10000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 91.11(45555/50000)%\n",
            "Accuracy on testing data 71.0(7100/10000)%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 92.59(46297/50000)%\n",
            "Accuracy on testing data 71.07(7107/10000)%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 93.9(46952/50000)%\n",
            "Accuracy on testing data 71.83(7183/10000)%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 95.04(47520/50000)%\n",
            "Accuracy on testing data 71.92(7192/10000)%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 95.85(47924/50000)%\n",
            "Accuracy on testing data 72.43(7243/10000)%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 96.15(48077/50000)%\n",
            "Accuracy on testing data 72.07(7207/10000)%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 95.2(47599/50000)%\n",
            "Accuracy on testing data 71.2(7120/10000)%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 97.82(48911/50000)%\n",
            "Accuracy on testing data 73.3(7330/10000)%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 97.21(48607/50000)%\n",
            "Accuracy on testing data 73.0(7300/10000)%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 97.24(48621/50000)%\n",
            "Accuracy on testing data 72.54(7254/10000)%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 98.54(49269/50000)%\n",
            "Accuracy on testing data 72.99(7299/10000)%\n",
            "Training for epoch: 20\n",
            "Accuracy on training data 97.65(48826/50000)%\n",
            "Accuracy on testing data 72.54(7254/10000)%\n",
            "Training for epoch: 21\n",
            "Accuracy on training data 98.01(49004/50000)%\n",
            "Accuracy on testing data 73.38(7338/10000)%\n",
            "Training for epoch: 22\n",
            "Accuracy on training data 98.41(49206/50000)%\n",
            "Accuracy on testing data 73.16(7316/10000)%\n",
            "Training for epoch: 23\n",
            "Accuracy on training data 99.07(49534/50000)%\n",
            "Accuracy on testing data 74.1(7410/10000)%\n",
            "Training for epoch: 24\n",
            "Accuracy on training data 98.29(49145/50000)%\n",
            "Accuracy on testing data 72.79(7279/10000)%\n",
            "Training for epoch: 25\n",
            "Accuracy on training data 97.68(48841/50000)%\n",
            "Accuracy on testing data 72.14(7214/10000)%\n",
            "Training for epoch: 26\n",
            "Accuracy on training data 99.29(49644/50000)%\n",
            "Accuracy on testing data 73.26(7326/10000)%\n",
            "Training for epoch: 27\n",
            "Accuracy on training data 99.33(49665/50000)%\n",
            "Accuracy on testing data 73.61(7361/10000)%\n",
            "Training for epoch: 28\n",
            "Accuracy on training data 99.5(49750/50000)%\n",
            "Accuracy on testing data 74.94(7494/10000)%\n",
            "Training for epoch: 29\n",
            "Accuracy on training data 99.7(49851/50000)%\n",
            "Accuracy on testing data 74.45(7445/10000)%\n",
            "Training for epoch: 30\n",
            "Accuracy on training data 99.62(49810/50000)%\n",
            "Accuracy on testing data 74.17(7417/10000)%\n",
            "Training for epoch: 31\n",
            "Accuracy on training data 99.96(49980/50000)%\n",
            "Accuracy on testing data 75.7(7570/10000)%\n",
            "Training for epoch: 32\n",
            "Accuracy on training data 100.0(50000/50000)%\n",
            "Accuracy on testing data 75.97(7597/10000)%\n",
            "Training for epoch: 33\n",
            "Accuracy on training data 100.0(50000/50000)%\n",
            "Accuracy on testing data 75.87(7587/10000)%\n",
            "Training for epoch: 34\n",
            "Accuracy on training data 100.0(50000/50000)%\n",
            "Accuracy on testing data 75.94(7594/10000)%\n",
            "Training for epoch: 35\n",
            "Accuracy on training data 100.0(50000/50000)%\n",
            "Accuracy on testing data 75.94(7594/10000)%\n",
            "Training for epoch: 36\n",
            "Accuracy on training data 100.0(50000/50000)%\n",
            "Accuracy on testing data 76.01(7601/10000)%\n",
            "Training for epoch: 37\n",
            "Accuracy on training data 100.0(50000/50000)%\n",
            "Accuracy on testing data 76.08(7608/10000)%\n",
            "Training for epoch: 38\n",
            "Accuracy on training data 100.0(50000/50000)%\n",
            "Accuracy on testing data 76.19(7619/10000)%\n",
            "Training for epoch: 39\n",
            "Accuracy on training data 100.0(50000/50000)%\n",
            "Accuracy on testing data 76.3(7630/10000)%\n",
            "76.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7fcd5d3611e047f89ab526d5654d2df5",
            "d4a69b1954ef4edaa2a5eef06c203866",
            "73a21ba9f47d4843820626bacad1e099",
            "539446b036404120bb9d917b09c734fc",
            "e6ae83fda4e74be083c7107f7ea91763",
            "a8bf7edaa4a748978fa3d4e560fd96d4",
            "c8cbd5689f5b4d6cb582a55680844f96",
            "f63e9e511a144e4eb0f837834359933f"
          ]
        },
        "id": "5D1xPjG_BrQY",
        "outputId": "0e6a8548-f118-499d-bc68-68b3cef8bda0"
      },
      "source": [
        "model = TorchCNN(\n",
        "    loss_func=\"CrossEntropyLoss\",\n",
        "    optimizer=\"SGD\",\n",
        "    learning_rate=1e-3,\n",
        "    lmda_wt_decay=1e-4,\n",
        "    batch_size=5,\n",
        "    training_size=50000,\n",
        "    testing_size=10000,\n",
        "    seed=35,\n",
        "    momentum=0.9,\n",
        "    nn_stack=[nn.Conv2d(in_channels=3, out_channels=20, kernel_size=3, stride=1, padding=1),\n",
        "             nn.ReLU(),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "             nn.Dropout(0.00),\n",
        "             nn.Conv2d(in_channels=20, out_channels=40, kernel_size=3, stride=1, padding=1),\n",
        "             nn.ReLU(),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "             nn.Dropout(0.00),\n",
        "             nn.Conv2d(in_channels=40, out_channels=60, kernel_size=3, stride=1, padding=1),\n",
        "             nn.ReLU(),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "             nn.Dropout(0.00),\n",
        "             nn.Flatten(),\n",
        "             nn.Linear(60 * 4 * 4, 60 * 4 * 4 * 2),\n",
        "             nn.ReLU(),\n",
        "             nn.Dropout(0.00),\n",
        "             nn.Linear(60 * 4 * 4 * 2, 10),\n",
        "             nn.ReLU()]\n",
        ").to(device)\n",
        "train_data = CIFAR10(root='cifar10', train=True, download=True, transform=cifar_transform)\n",
        "test_data = CIFAR10(root='cifar10', train=False, download=True, transform=cifar_transform)\n",
        "torch.manual_seed(35)\n",
        "training_loader = DataLoader(train_data, batch_size=5, shuffle=True)\n",
        "testing_loader = DataLoader(test_data, batch_size=5, shuffle=True)\n",
        "accuracies = []\n",
        "for epoch in range(100):\n",
        "    print(f\"Training for epoch: {epoch}\")\n",
        "    model.train_model(training_loader)\n",
        "    accuracies.append(model.evaluate(testing_loader, model.testing_size, \"testing\"))\n",
        "print(max(accuracies))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to cifar10/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7fcd5d3611e047f89ab526d5654d2df5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting cifar10/cifar-10-python.tar.gz to cifar10\n",
            "Files already downloaded and verified\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 46.17(23084/50000)%\n",
            "Accuracy on testing data 45.28(4528/10000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 65.56(32779/50000)%\n",
            "Accuracy on testing data 62.78(6278/10000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 72.79(36393/50000)%\n",
            "Accuracy on testing data 67.89(6789/10000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 76.72(38359/50000)%\n",
            "Accuracy on testing data 69.12(6912/10000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 78.43(39216/50000)%\n",
            "Accuracy on testing data 68.97(6897/10000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 81.6(40801/50000)%\n",
            "Accuracy on testing data 69.43(6943/10000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 84.94(42471/50000)%\n",
            "Accuracy on testing data 70.14(7014/10000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 82.66(41331/50000)%\n",
            "Accuracy on testing data 67.62(6762/10000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 87.79(43896/50000)%\n",
            "Accuracy on testing data 69.83(6983/10000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 91.75(45877/50000)%\n",
            "Accuracy on testing data 71.59(7159/10000)%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 92.66(46331/50000)%\n",
            "Accuracy on testing data 71.24(7124/10000)%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 92.34(46170/50000)%\n",
            "Accuracy on testing data 70.58(7058/10000)%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 92.44(46222/50000)%\n",
            "Accuracy on testing data 69.93(6993/10000)%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 96.34(48169/50000)%\n",
            "Accuracy on testing data 72.44(7244/10000)%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 96.45(48224/50000)%\n",
            "Accuracy on testing data 72.3(7230/10000)%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 96.6(48301/50000)%\n",
            "Accuracy on testing data 72.83(7283/10000)%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 96.97(48486/50000)%\n",
            "Accuracy on testing data 72.49(7249/10000)%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 97.15(48574/50000)%\n",
            "Accuracy on testing data 73.21(7321/10000)%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 97.78(48892/50000)%\n",
            "Accuracy on testing data 72.74(7274/10000)%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 98.29(49147/50000)%\n",
            "Accuracy on testing data 73.24(7324/10000)%\n",
            "Training for epoch: 20\n",
            "Accuracy on training data 98.65(49327/50000)%\n",
            "Accuracy on testing data 73.81(7381/10000)%\n",
            "Training for epoch: 21\n",
            "Accuracy on training data 98.21(49107/50000)%\n",
            "Accuracy on testing data 73.48(7348/10000)%\n",
            "Training for epoch: 22\n",
            "Accuracy on training data 97.66(48828/50000)%\n",
            "Accuracy on testing data 73.05(7305/10000)%\n",
            "Training for epoch: 23\n",
            "Accuracy on training data 98.62(49311/50000)%\n",
            "Accuracy on testing data 73.85(7385/10000)%\n",
            "Training for epoch: 24\n",
            "Accuracy on training data 99.18(49588/50000)%\n",
            "Accuracy on testing data 74.17(7417/10000)%\n",
            "Training for epoch: 25\n",
            "Accuracy on training data 97.55(48775/50000)%\n",
            "Accuracy on testing data 72.48(7248/10000)%\n",
            "Training for epoch: 26\n",
            "Accuracy on training data 99.41(49704/50000)%\n",
            "Accuracy on testing data 74.25(7425/10000)%\n",
            "Training for epoch: 27\n",
            "Accuracy on training data 98.99(49496/50000)%\n",
            "Accuracy on testing data 73.91(7391/10000)%\n",
            "Training for epoch: 28\n",
            "Accuracy on training data 99.14(49568/50000)%\n",
            "Accuracy on testing data 73.49(7349/10000)%\n",
            "Training for epoch: 29\n",
            "Accuracy on training data 99.48(49738/50000)%\n",
            "Accuracy on testing data 74.43(7443/10000)%\n",
            "Training for epoch: 30\n",
            "Accuracy on training data 99.91(49953/50000)%\n",
            "Accuracy on testing data 75.24(7524/10000)%\n",
            "Training for epoch: 31\n",
            "Accuracy on training data 99.96(49980/50000)%\n",
            "Accuracy on testing data 75.27(7527/10000)%\n",
            "Training for epoch: 32\n",
            "Accuracy on training data 100.0(49999/50000)%\n",
            "Accuracy on testing data 75.21(7521/10000)%\n",
            "Training for epoch: 33\n",
            "Accuracy on training data 100.0(50000/50000)%\n",
            "Accuracy on testing data 75.42(7542/10000)%\n",
            "Training for epoch: 34\n",
            "Accuracy on training data 100.0(50000/50000)%\n",
            "Accuracy on testing data 75.54(7554/10000)%\n",
            "Training for epoch: 35\n",
            "Accuracy on training data 100.0(50000/50000)%\n",
            "Accuracy on testing data 75.59(7559/10000)%\n",
            "Training for epoch: 36\n",
            "Accuracy on training data 100.0(50000/50000)%\n",
            "Accuracy on testing data 75.56(7556/10000)%\n",
            "Training for epoch: 37\n",
            "Accuracy on training data 100.0(50000/50000)%\n",
            "Accuracy on testing data 75.62(7562/10000)%\n",
            "Training for epoch: 38\n",
            "Accuracy on training data 100.0(50000/50000)%\n",
            "Accuracy on testing data 75.69(7569/10000)%\n",
            "Training for epoch: 39\n",
            "Accuracy on training data 100.0(50000/50000)%\n",
            "Accuracy on testing data 75.79(7579/10000)%\n",
            "Training for epoch: 40\n",
            "Accuracy on training data 100.0(50000/50000)%\n",
            "Accuracy on testing data 75.89(7589/10000)%\n",
            "Training for epoch: 41\n",
            "Accuracy on training data 100.0(50000/50000)%\n",
            "Accuracy on testing data 75.95(7595/10000)%\n",
            "Training for epoch: 42\n",
            "Accuracy on training data 100.0(50000/50000)%\n",
            "Accuracy on testing data 76.01(7601/10000)%\n",
            "Training for epoch: 43\n",
            "Accuracy on training data 100.0(50000/50000)%\n",
            "Accuracy on testing data 76.12(7612/10000)%\n",
            "Training for epoch: 44\n",
            "Accuracy on training data 100.0(50000/50000)%\n",
            "Accuracy on testing data 76.19(7619/10000)%\n",
            "Training for epoch: 45\n",
            "Accuracy on training data 100.0(50000/50000)%\n",
            "Accuracy on testing data 76.32(7632/10000)%\n",
            "Training for epoch: 46\n",
            "Accuracy on training data 100.0(50000/50000)%\n",
            "Accuracy on testing data 76.39(7639/10000)%\n",
            "Training for epoch: 47\n",
            "Accuracy on training data 100.0(50000/50000)%\n",
            "Accuracy on testing data 76.37(7637/10000)%\n",
            "Training for epoch: 48\n",
            "Accuracy on training data 100.0(50000/50000)%\n",
            "Accuracy on testing data 76.39(7639/10000)%\n",
            "Training for epoch: 49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLM0MpT7pebQ"
      },
      "source": [
        "# CIFAR100 Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PCLa8v8pi7n"
      },
      "source": [
        "Try the same architecture on CIFAR100, but will 100 logics instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zixt9lhsphAs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "766dbaa71dcc4fb5ad10e8666cc33bcb",
            "e09481dd406440dcbb8013a2df87f24b",
            "b1986ce8ab41486686c1db9637f2bdf9",
            "574fa2e2c427415fa24a2e0e52c6a66a",
            "39746bde3c72407982f3c45df4ab573c",
            "6d18f8a3cb21447a8c12f447f64b9928",
            "84a4d44ec1674bca9631c3de2888a8af",
            "b3aeaa0c3a3f4e86b8b2d0a1042ca765",
            "696fd21a8ac64ca1bef46f495476e766",
            "2fb0f73d2afc43f9a78d28c137673bad",
            "a898220c0661475b923ab0ada603c8e2",
            "4bea1562d3204a39bfc1644dbe9ba0f4",
            "1186dade88b645fc8b13a4d12c571176",
            "b0f994b4c0d140bea15c5248ed500343",
            "d405f2b340e14e89ad97573956f9d05c",
            "f5976811a85043d8aea1fce70732fb78"
          ]
        },
        "outputId": "9487cc7d-1bcd-4209-e825-34b2eff72703"
      },
      "source": [
        "device=\"cuda\"\n",
        "model = TorchCNN(\n",
        "    loss_func=\"CrossEntropyLoss\",\n",
        "    optimizer=\"SGD\",\n",
        "    learning_rate=1e-3,\n",
        "    lmda_wt_decay=1e-4,\n",
        "    batch_size=5,\n",
        "    training_size=50000,\n",
        "    testing_size=10000,\n",
        "    seed=35,\n",
        "    momentum=0.9,\n",
        "    nn_stack=[nn.Conv2d(in_channels=3, out_channels=20, kernel_size=3, stride=1, padding=1),\n",
        "             nn.ReLU(),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "             nn.Dropout(0.00),\n",
        "             nn.Conv2d(in_channels=20, out_channels=40, kernel_size=3, stride=1, padding=1),\n",
        "             nn.ReLU(),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "             nn.Dropout(0.00),\n",
        "             nn.Conv2d(in_channels=40, out_channels=60, kernel_size=3, stride=1, padding=1),\n",
        "             nn.ReLU(),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "             nn.Dropout(0.00),\n",
        "             nn.Flatten(),\n",
        "             nn.Linear(60 * 4 * 4, 60 * 4 * 4 * 2),\n",
        "             nn.ReLU(),\n",
        "             nn.Dropout(0.00),\n",
        "             nn.Linear(60 * 4 * 4 * 2, 100),\n",
        "             nn.ReLU()]\n",
        ").to(device)\n",
        "train_data = CIFAR100(root='cifar10', train=True, download=True, transform=cifar_transform)\n",
        "test_data = CIFAR100(root='cifar100', train=False, download=True, transform=cifar_transform)\n",
        "torch.manual_seed(35)\n",
        "training_loader = DataLoader(train_data, batch_size=5, shuffle=True)\n",
        "testing_loader = DataLoader(test_data, batch_size=5, shuffle=True)\n",
        "accuracies = []\n",
        "for epoch in range(25):\n",
        "    print(f\"Training for epoch: {epoch}\")\n",
        "    model.train_model(training_loader)\n",
        "    accuracies.append(model.evaluate(testing_loader, model.testing_size, \"testing\"))\n",
        "print(max(accuracies))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to cifar10/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "766dbaa71dcc4fb5ad10e8666cc33bcb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=169001437.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting cifar10/cifar-100-python.tar.gz to cifar10\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to cifar100/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "696fd21a8ac64ca1bef46f495476e766",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=169001437.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting cifar100/cifar-100-python.tar.gz to cifar100\n",
            "Training for epoch: 0\n",
            "Accuracy on training data 11.04(5518/50000)%\n",
            "Accuracy on testing data 10.6(1060/10000)%\n",
            "Training for epoch: 1\n",
            "Accuracy on training data 25.31(12656/50000)%\n",
            "Accuracy on testing data 23.14(2314/10000)%\n",
            "Training for epoch: 2\n",
            "Accuracy on training data 35.75(17873/50000)%\n",
            "Accuracy on testing data 29.97(2997/10000)%\n",
            "Training for epoch: 3\n",
            "Accuracy on training data 44.65(22324/50000)%\n",
            "Accuracy on testing data 33.98(3398/10000)%\n",
            "Training for epoch: 4\n",
            "Accuracy on training data 52.8(26400/50000)%\n",
            "Accuracy on testing data 34.78(3478/10000)%\n",
            "Training for epoch: 5\n",
            "Accuracy on training data 60.41(30203/50000)%\n",
            "Accuracy on testing data 35.07(3507/10000)%\n",
            "Training for epoch: 6\n",
            "Accuracy on training data 62.45(31227/50000)%\n",
            "Accuracy on testing data 32.77(3277/10000)%\n",
            "Training for epoch: 7\n",
            "Accuracy on training data 63.32(31662/50000)%\n",
            "Accuracy on testing data 30.8(3080/10000)%\n",
            "Training for epoch: 8\n",
            "Accuracy on training data 69.33(34664/50000)%\n",
            "Accuracy on testing data 31.31(3131/10000)%\n",
            "Training for epoch: 9\n",
            "Accuracy on training data 73.84(36921/50000)%\n",
            "Accuracy on testing data 32.27(3227/10000)%\n",
            "Training for epoch: 10\n",
            "Accuracy on training data 75.61(37807/50000)%\n",
            "Accuracy on testing data 31.62(3162/10000)%\n",
            "Training for epoch: 11\n",
            "Accuracy on training data 79.54(39771/50000)%\n",
            "Accuracy on testing data 33.19(3319/10000)%\n",
            "Training for epoch: 12\n",
            "Accuracy on training data 81.42(40712/50000)%\n",
            "Accuracy on testing data 32.86(3286/10000)%\n",
            "Training for epoch: 13\n",
            "Accuracy on training data 84.29(42147/50000)%\n",
            "Accuracy on testing data 33.59(3359/10000)%\n",
            "Training for epoch: 14\n",
            "Accuracy on training data 85.43(42716/50000)%\n",
            "Accuracy on testing data 33.21(3321/10000)%\n",
            "Training for epoch: 15\n",
            "Accuracy on training data 87.86(43928/50000)%\n",
            "Accuracy on testing data 33.07(3307/10000)%\n",
            "Training for epoch: 16\n",
            "Accuracy on training data 87.43(43713/50000)%\n",
            "Accuracy on testing data 33.59(3359/10000)%\n",
            "Training for epoch: 17\n",
            "Accuracy on training data 88.63(44317/50000)%\n",
            "Accuracy on testing data 33.4(3340/10000)%\n",
            "Training for epoch: 18\n",
            "Accuracy on training data 90.19(45093/50000)%\n",
            "Accuracy on testing data 34.11(3411/10000)%\n",
            "Training for epoch: 19\n",
            "Accuracy on training data 90.98(45489/50000)%\n",
            "Accuracy on testing data 33.79(3379/10000)%\n",
            "Training for epoch: 20\n",
            "Accuracy on training data 91.2(45600/50000)%\n",
            "Accuracy on testing data 34.36(3436/10000)%\n",
            "Training for epoch: 21\n",
            "Accuracy on training data 89.2(44602/50000)%\n",
            "Accuracy on testing data 33.23(3323/10000)%\n",
            "Training for epoch: 22\n",
            "Accuracy on training data 93.37(46687/50000)%\n",
            "Accuracy on testing data 35.1(3510/10000)%\n",
            "Training for epoch: 23\n",
            "Accuracy on training data 91.77(45885/50000)%\n",
            "Accuracy on testing data 33.98(3398/10000)%\n",
            "Training for epoch: 24\n",
            "Accuracy on training data 93.49(46743/50000)%\n",
            "Accuracy on testing data 35.0(3500/10000)%\n",
            "35.1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}