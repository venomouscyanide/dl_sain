## Week 2
### The second project
This project consists of a few mini projects:
- Rewrite the previous project in PyTorch in Colab. Your code should  classify the handwritten digits (e.g., 0,1,..,9) with accuracy of 95%.
- Change your code to use Relu activation function, softmax, and cross entropy loss. Which accuracy can you get now?
- Now try to add extra layers of hidden layers. Can you get better results?
- Now try to do proper hypertuning and regularization. What's the best result that you can get by feedforward networks?
### Resources
#### Readings
- Chapter 3 and 4: http://neuralnetworksanddeeplearning.com/
#### Online Lectures
- All the 4 weeks lectures of this course: https://www.coursera.org/learn/deep-neural-network?specialization=deep-learning
### Project
#### Dataset
MNIST
#### Deadline
 Share you code via Colab by Thursday 27th noon to everyone else, we meet on Friday 28th. The invitation for meeting will be sent to those registered for the course.
#### Advice
 Don't underestimate how much materials you need to read and listen to full do this project.  If you don't have a good background on ML, I think you need to spend 5-6 hours per day in next 10 days to do this project and understand what you have done! Good luck! and remember to ask the question from your peers.